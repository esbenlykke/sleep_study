{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "# import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "# import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "from tqdm import tqdm  # progress bar\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train = pq.read_table(\"/home/esbenlykke/projects/sleep_study/data/data_for_modelling/chained_classifiers/30_sec_training_data.parquet\")\n",
    "test = pq.read_table(\"/home/esbenlykke/projects/sleep_study/data/data_for_modelling/chained_classifiers/30_sec_testing_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month   day   age       incl      theta         x         y         z   \n",
      "0         2.0  17.0   6.0  15.798665  -5.310628 -0.166543  0.736582 -0.088525  \\\n",
      "1         2.0  17.0   6.0  20.806454  -8.427656 -0.354135  0.928025 -0.206452   \n",
      "2         2.0  17.0   6.0  15.256819  -0.600693 -0.268185  0.905933 -0.058268   \n",
      "3         2.0  17.0   6.0   7.902555  -2.452577 -0.064138  0.966516  0.006280   \n",
      "4         2.0  17.0   6.0   5.761677   5.070190 -0.092652  0.922352  0.120019   \n",
      "...       ...   ...   ...        ...        ...       ...       ...       ...   \n",
      "411961    9.0  30.0  12.0  89.056083 -74.467833  0.235170  0.027814 -0.903933   \n",
      "411962    9.0  30.0  12.0  88.180862 -81.183678  0.214830  0.017471 -0.983853   \n",
      "411963    9.0  30.0  12.0  84.408979 -83.088712  0.036370  0.075359 -1.005727   \n",
      "411964    9.0  30.0  12.0  83.469627 -83.435066 -0.010326  0.138011 -1.000573   \n",
      "411965    9.0  30.0  12.0  88.157199 -80.687190  0.135086 -0.003870 -0.985143   \n",
      "\n",
      "             temp    x_mean  ...  z_sd_lead_5min  z_sd_lead_30min  time_day   \n",
      "0       29.885731 -0.234994  ...        0.113797         0.507397  0.000150  \\\n",
      "1       30.471726 -0.309378  ...        0.146960         0.209449  0.000602   \n",
      "2       30.471726 -0.246230  ...        0.058443         0.389224  0.001053   \n",
      "3       30.471726 -0.107140  ...        0.095613         0.297843  0.001505   \n",
      "4       30.471726 -0.027531  ...        0.191604         0.412440  0.001956   \n",
      "...           ...       ...  ...             ...              ...       ...   \n",
      "411961  32.229710  0.228229  ...        0.009534         0.056694  0.998487   \n",
      "411962  32.229710  0.132464  ...        0.001792         0.056694  0.998836   \n",
      "411963  32.229710  0.041031  ...        0.026192         0.056694  0.999185   \n",
      "411964  32.229710 -0.011215  ...        0.039258         0.056694  0.999535   \n",
      "411965  32.229710  0.127592  ...        0.056694         0.056694  0.999884   \n",
      "\n",
      "        weekday  score  in_bed  in_bed_median5  sleep  sleep_median5   \n",
      "0           0.0    1.0     0.0             0.0    0.0            0.0  \\\n",
      "1           0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "2           0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "3           0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "4           0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "...         ...    ...     ...             ...    ...            ...   \n",
      "411961      0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "411962      0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "411963      0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "411964      0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "411965      0.0    1.0     0.0             0.0    0.0            0.0   \n",
      "\n",
      "        sleep_median10  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n",
      "...                ...  \n",
      "411961             0.0  \n",
      "411962             0.0  \n",
      "411963             0.0  \n",
      "411964             0.0  \n",
      "411965             0.0  \n",
      "\n",
      "[411966 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = train.to_pandas()\n",
    "test_df = test.to_pandas()\n",
    "# Remove the specified columns\n",
    "columns_to_remove = [\"id\", \"datetime\", \"unix_time\", \"noon_day\"]\n",
    "train_df = train_df.drop(columns=columns_to_remove)\n",
    "test_df = test_df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "numeric_columns = train_df.select_dtypes(include='number').columns\n",
    "\n",
    "# Normalize the numeric columns using pandas\n",
    "train_df[numeric_columns] = (train_df[numeric_columns] - train_df[numeric_columns].mean()) / train_df[numeric_columns].std()\n",
    "test_df[numeric_columns] = (test_df[numeric_columns] - test_df[numeric_columns].mean()) / test_df[numeric_columns].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41195, 20, 68])\n",
      "torch.Size([41195])\n",
      "torch.Size([122749, 20, 68])\n",
      "torch.Size([122749])\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(df, target_column, sequence_length, step_size):\n",
    "    # Convert DataFrame to numpy array\n",
    "    data_array = df.to_numpy()\n",
    "\n",
    "    # Create sequences and labels\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(data_array) - sequence_length, step_size):\n",
    "        seq = data_array[i:i+sequence_length]\n",
    "        label = data_array[i+sequence_length, df.columns.get_loc(target_column)]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Convert sequences and labels to PyTorch tensors\n",
    "    data_sequences = torch.Tensor(sequences)\n",
    "    data_labels = torch.Tensor(labels)\n",
    "\n",
    "    return data_sequences, data_labels\n",
    "\n",
    "# Assuming you have train and test DataFrames named 'train_df' and 'test_df'\n",
    "train_sequences, train_labels = create_sequences(train_df, \"score\", 20, 10)\n",
    "test_sequences, test_labels = create_sequences(test_df, \"score\", 20, 10)\n",
    "\n",
    "print(train_sequences.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_sequences.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train tensors\n",
    "torch.save(train_sequences, \"/home/esbenlykke/projects/sleep_study/data/data_for_modelling/lstm/train_predictors.pt\")\n",
    "torch.save(train_labels, \"/home/esbenlykke/projects/sleep_study/data/data_for_modelling/lstm/train_labels.pt\")\n",
    "\n",
    "# Save test tensors\n",
    "torch.save(test_sequences, \"/home/esbenlykke/projects/sleep_study/data/data_for_modelling/lstm/test_predictors.pt\")\n",
    "torch.save(test_labels, \"/home/esbenlykke/projects/sleep_study/data/data_for_modelling/lstm/test_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/esbenlykke/projects/sleep_study/code/create_models/lstm'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
