<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Esben Høegholm Lykke">
<meta name="author" content="Jan Christian Brønd">
<meta name="dcterms.date" content="2023-07-12">
<meta name="keywords" content="Sleep, Accelerometry, EEG, Machine learning, Sleep quality">

<title>Improving Sleep Quality Estimation: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="manuscript_files/libs/clipboard/clipboard.min.js"></script>
<script src="manuscript_files/libs/quarto-html/quarto.js"></script>
<script src="manuscript_files/libs/quarto-html/popper.min.js"></script>
<script src="manuscript_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="manuscript_files/libs/quarto-html/anchor.min.js"></script>
<link href="manuscript_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="manuscript_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="manuscript_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="manuscript_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="manuscript_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="manuscript.pdf"><i class="bi bi-file-pdf"></i>PDF (elsevier)</a></li><li><a href="manuscript.pdf"><i class="bi bi-file-pdf"></i>PDF (simple-article)</a></li><li><a href="manuscript.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Improving Sleep Quality Estimation: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Esben Høegholm Lykke </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Southern Denmark
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Jan Christian Brønd </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Southern Denmark
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 12, 2023</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    LÆS IKKE! Det er volapyk på latin. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse vitae dictum eros, ullamcorper elementum orci. Sed laoreet nulla neque, pulvinar fermentum mi iaculis at. Nulla ultricies nibh sit amet vestibulum rutrum. Nam pharetra nisl sed ipsum maximus suscipit. Duis metus nunc, ullamcorper eu mi rutrum, tempus ultricies ante. Nunc vitae lectus nisi. Aliquam efficitur ut eros ut pellentesque. Aenean blandit, nisl nec efficitur interdum, nisi ipsum fermentum dolor, at tempus sem turpis in lacus. Curabitur sollicitudin lectus sit amet velit pellentesque laoreet. Ut posuere diam lobortis nisi eleifend tincidunt. Ut at euismod sem, sed dignissim ligula. Aliquam lacinia massa libero, id eleifend velit pulvinar ac. Fusce volutpat elit eu nulla viverra, nec tempus orci pellentesque.
  </div>
</div>

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>A vast body of research highlights the critical role of sleep in maintaining both mental and physical health<span class="citation" data-cites="ma2017 meyer2022 kpavlova2019 difrancesco2019">(<a href="#ref-ma2017" role="doc-biblioref">Ma 2017</a>; <a href="#ref-meyer2022" role="doc-biblioref">Meyer et al. 2022</a>; <a href="#ref-kpavlova2019" role="doc-biblioref">K Pavlova and Latreille 2019</a>; <a href="#ref-difrancesco2019" role="doc-biblioref">Difrancesco et al. 2019</a>)</span>. Consequently, accurate sleep assessment methods are crucial for tracking sleep patterns and improving our understanding of the sleep-health relationship. Furthermore, the ease of use and high acceptability of these methods are essential to facilitate large-scale, longitudinal studies.</p>
<p>While laboratory-based polysomnography (PSG) is typically considered the gold standard for objective sleep measurement, its practicality in large-scale epidemiological studies is hindered due to high costs, the necessity for professional administration, and it is also subject to potential rater bias<span class="citation" data-cites="vandewater2011 lee2022">(<a href="#ref-vandewater2011" role="doc-biblioref">Van De Water, Holmes, and Hurley 2011</a>; <a href="#ref-lee2022" role="doc-biblioref">Lee et al. 2022</a>)</span>. As an alternative, diaries are commonly employed as cost-effective and low-tech methods for sleep assessment in population research. However, reliance on diary-based methods may lead to recall bias and other limitations<span class="citation" data-cites="moore2015">(<a href="#ref-moore2015" role="doc-biblioref">Moore, Schmiege, and Matthews 2015</a>)</span>. A more feasible approach in large-scale epidemiological studies is to use device-based measurement methods that can estimate sleep duration. This approach offers the advantage of being less burdensome for participants and eliminates potential biases associated with recall.</p>
<p>Body-worn accelerometers have emerged as an effective and affordable alternative for objectively assessing sleep patterns at home over extended periods. These devices gather continuous, high-resolution data for several weeks without the need for recharging, thus reducing participant burden. Initial applications of accelerometry for sleep and wake stage classification were based on wrist movements, starting with an algorithm developed in 1982 and validated with PSG <span class="citation" data-cites="webster1982">(<a href="#ref-webster1982" role="doc-biblioref">Webster et al. 1982</a>)</span>. This model was later refined in 1992 <span class="citation" data-cites="cole1992">(<a href="#ref-cole1992" role="doc-biblioref">Cole et al. 1992</a>)</span>, giving rise to the widely used Cole-Kripke model. As the field advanced, an array of techniques, including heuristic algorithms, machine learning models, regression, and deep learning, were employed to analyze wrist-worn accelerometer data<span class="citation" data-cites="palotti2019 cole1992 sazonov2004 sadeh1994 hees2015 sundararajan2021">(<a href="#ref-palotti2019" role="doc-biblioref">Palotti et al. 2019</a>; <a href="#ref-cole1992" role="doc-biblioref">Cole et al. 1992</a>; <a href="#ref-sazonov2004" role="doc-biblioref">Sazonov et al. 2004</a>; <a href="#ref-sadeh1994" role="doc-biblioref">Sadeh, Sharkey, and Carskadon 1994</a>; <a href="#ref-hees2015" role="doc-biblioref">Hees et al. 2015</a>; <a href="#ref-sundararajan2021" role="doc-biblioref">Sundararajan et al. 2021</a>)</span>.</p>
<p>While wrist and hip-worn devices have benefited from extensive methodological development, thigh-worn accelerometers have not seen the same level of advancement. Existing studies mainly focus on distinguishing sleep from wakefulness, with emphasis on defining ‘waking time’ and ‘bedtime’ <span class="citation" data-cites="carlson2021 inan-eroglu2021 vanderberg2016 winkler2016">(<a href="#ref-carlson2021" role="doc-biblioref">Carlson et al. 2021</a>; <a href="#ref-inan-eroglu2021" role="doc-biblioref">Inan-Eroglu et al. 2021</a>; <a href="#ref-vanderberg2016" role="doc-biblioref">Berg et al. 2016</a>; <a href="#ref-winkler2016" role="doc-biblioref">Winkler et al. 2016</a>)</span>. Recent strides in estimating sleep duration using these devices have been made, including the introduction of a promising algorithm and its comparison against PSG<span class="citation" data-cites="johansson_development_2023">(<a href="#ref-johansson_development_2023" role="doc-biblioref">Johansson et al. 2023</a>)</span>. Despite these advancements, the application of machine learning techniques in this area is still relatively unexplored. Considering the potential of thigh-worn accelerometers for accurate physical behavior assessment<span class="citation" data-cites="skotte_detection_2014 arvidsson2019">(<a href="#ref-skotte_detection_2014" role="doc-biblioref">Skotte et al. 2014</a>; <a href="#ref-arvidsson2019" role="doc-biblioref">Arvidsson et al. 2019</a>)</span>, there is a significant research gap. Therefore, future studies need to develop techniques similar to those used for wrist and hip-worn accelerometers, with the ultimate goal of establishing a more holistic, accurate, and user-friendly method of sleep and physical activity tracking.</p>
<p>The Zmachine®️ Insight+ (ZM) emerges as a valuable tool within this landscape. Favorably validated against PSG<span class="citation" data-cites="kaplan2014 wang2015">(<a href="#ref-kaplan2014" role="doc-biblioref">Kaplan et al. 2014</a>; <a href="#ref-wang2015" role="doc-biblioref">Wang et al. 2015</a>)</span>, the ZM provides comparable data without the high costs or the need for professional monitoring typically associated with PSG. Crucially, the ZM facilitates multi-night analysis in free-living conditions due to its ease of use<span class="citation" data-cites="pedersen2021">(<a href="#ref-pedersen2021" role="doc-biblioref">Pedersen et al. 2021</a>)</span>, capturing the natural variations in sleep patterns. This makes it advantageous over single-night PSG, particularly as a gold standard data source in machine learning tasks, as it provides multiple nights of measurements without inter-rater bias. Despite these benefits, the ZM, like PSG, still poses a significant participant burden and cost, reinforcing the need for more accessible alternatives like accelerometers.</p>
<p>Our primary objective in this study was to evaluate a range of machine learning and deep learning models, utilizing the raw data collected from a tri-axial thigh-worn accelerometer to estimate in-bed and sleep time. To ensure the reliability and effectiveness of our models, we compared their outputs with an EEG-based sleep tracking device, which we considered the gold standard for measuring sleep. Furthermore, our secondary goal was to assess the developed models’ performance in evaluating important sleep quality parameters, including sleep period time (SPT), total sleep time (TST), sleep efficiency (SE), latency until persistent sleep (LPS), and wake after sleep onset (WASO).</p>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<section id="dataset-and-participants" class="level2">
<h2 class="anchored" data-anchor-id="dataset-and-participants">Dataset and participants</h2>
<p>The current study leverages data from the SCREENS project<span class="citation" data-cites="rasmussen2020">(<a href="#ref-rasmussen2020" role="doc-biblioref">Rasmussen et al. 2020</a>)</span>, a study conducted from October 2018 to March 2019 in Middelfart, Southern Denmark, that evaluated the impact of screen media usage on Danish families. For our analysis, we focused on data from child participants aged between 6 and 10 years within the SCREENS cohort. Our primary sources of data were accelerometer readings from Axivity AX3 devices attached to the children’s thighs, and electroencephalography (EEG) data derived from the ZM device. The Axivity AX3, an unobtrusive 3-axis accelerometer, was positioned midway between the hip and knee on the right anterior thigh, recording participant movement data.</p>
<p>Sleep state information was extracted using the ZM, a product of General Sleep Corporation. The ZM, which utilizes advanced EEG hardware and signal processing algorithms, employs three self-adhesive, disposable sensors placed outside the hairline for reliable EEG signal acquisition. The ZM uses two proprietary algorithms: Z-ALG and Z-PLUS. The Z-ALG is utilized for accurate sleep detection, showcasing its suitability for in-home monitoring<span class="citation" data-cites="kaplan2014">(<a href="#ref-kaplan2014" role="doc-biblioref">Kaplan et al. 2014</a>)</span>, while the Z-PLUS effectively differentiates sleep stages, as evidenced by its alignment with expert evaluations using PSG data<span class="citation" data-cites="wang2015">(<a href="#ref-wang2015" role="doc-biblioref">Wang et al. 2015</a>)</span>. In the current study, we treated all sleep stages as a single category effectively deducing the output of the ZM to “awake” and “asleep” as the ability to distinguish sleep stages are not a necessity to derive sleep quality parameters of interest and to simplify the learning process of the models.</p>
<p><a href="#fig-flow">Figure&nbsp;1</a> illustrates the selection criteria applied to the children’s recordings from the SCREENS study. We included only ZM recordings that were accompanied by complete accelerometer data and lasted between 7 and 14 hours. Any night when the ZM reported sensor issues was excluded. The children whose recordings were considered had an average age of 9.4 years, with a standard deviation of 2.1. In their raw form, the ZM predictions encompassed 696,779 epochs, each 30 seconds long. Notably, approximately 84% of the total ZM recording duration was classified as sleep, resulting in an imbalance of the dataset.</p>
<div id="fig-flow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/flowchart_of_elligible_nights.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Flowchart of eligible ZM recording nights included in the study</figcaption>
</figure>
</div>
<p>Finally, we affirm that the SCREENS study received approval from the Regional Scientific Committee of Southern Denmark, and all data handling processes complied with the General Data Protection Regulation (GDPR), ensuring the ethical and secure management of participant information.</p>
</section>
<section id="data-preprocessing-and-feature-extraction" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing-and-feature-extraction">Data Preprocessing and Feature Extraction</h2>
<p>In this study, data processing of the raw accelerometer data began with a low-pass filtration step using a 4th order Butterworth filter with a 5 Hz cut-off frequency to eliminate high-frequency noise. Following filtration, data were partitioned into overlapping 2-second intervals, each successive interval sharing a 50% overlap with the previous one similar to methods described by Skotte et al.<span class="citation" data-cites="skotte_detection_2014">(<a href="#ref-skotte_detection_2014" role="doc-biblioref">Skotte et al. 2014</a>)</span>. Any non-wear data was remove using previously described methods<span class="citation" data-cites="skovgaard2023">(<a href="#ref-skovgaard2023" role="doc-biblioref">Skovgaard et al. 2023</a>)</span> and data was resampled to 30-second epochs so every sample classified by the algorithms corresponds to a 30-second epoch scored during the ZM recordings. Subsequently, we performed a feature extraction process that yielded a set of 88 features, providing a robust characterization of the data. Extracted from accelerometer and temperature signals, these features include temporal elements that use both lag and lead values, capturing dynamic data trends by incorporating measurements from preceding and upcoming intervals. Furthermore, inspired by Walch et al.<span class="citation" data-cites="walch2019">(<a href="#ref-walch2019" role="doc-biblioref">Walch et al. 2019</a>)</span>, we incorporated sensor-independent features to encapsulate circadian rhythms. These features offer unique insights not directly discernible from sensor outputs and are meant to approximate the changing drive of the circadian clock to sleep over the course of the night (see <a href="#fig-sensor-independent">Figure&nbsp;2</a>). Furthermore, the feature set was enriched by including signal characteristics, which encompass vector magnitude, mean crossing rate, skewness, and kurtosis for each of the x, y, and z dimensions. All features are summarized in table ??? <strong>in the supplementary matrials</strong>. Subsequently, we merged the ZM and corresponding accelerometer recordings. Any overlapping time between the ZM and accelerometer data was treated as ‘in-bed’ time, with the remaining time considered ‘out-of-bed’. This process yielded a dataset providing a around the clock temporal view of each participant’s activity and sleep patterns.</p>
<div id="fig-sensor-independent" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/sensor_independent.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Sensor-independent features of circadian rhythms across two consecutive nights. A) cosinus feature, B) linear feature.</figcaption>
</figure>
</div>
<p>In addition to the engineered features, we chose to incorporate the median-filtered raw predictions from the ZM device into our modeling process. This decision stemmed from the understanding that children typically undergo around five to eight sleep cycles per night, with awakenings most likely occurring at the end of each cycle<span class="citation" data-cites="galland_normal_2012">(<a href="#ref-galland_normal_2012" role="doc-biblioref">Galland et al. 2012</a>)</span>. Upon examining the raw ZM predictions, we noted a significant overestimation in the number of awakenings per night for the children in our study, exceeding what would be expected based on typical sleep cycle patterns. In particular, many of these brief awakenings could be considered as noise, which when present in the data, can potentially hinder the learning process of machine learning models by obscuring the underlying patterns that the models are trying to learn, leading to less accurate predictions. Consequently, we elected to train and evaluate our models using not only the raw ZM output, but also versions that were subjected to 5-minute and 10-minute median filters. This approach, by mitigating this noise, resulted in an anticipated, more age-appropriate count of awakenings per night, providing a more accurate depiction of children’s sleep patterns (see <a href="#fig-zm-median">Figure&nbsp;3</a>).</p>
<div id="fig-zm-median" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/zm_raw_vs_filtered.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;3: The difference in number of awakenings between the raw ZM predictions vs.&nbsp;5-minute, and 10-minute median filtered predictions for a random night. Grey line is the raw predictions, black line is the median filtered predictions. A: 5-minute median filter on raw ZM predictions, B: 10-minute median filter on raw ZM predictions.</figcaption>
</figure>
</div>
</section>
<section id="algorithms-training-and-validation" class="level2">
<h2 class="anchored" data-anchor-id="algorithms-training-and-validation">Algorithms, Training and Validation</h2>
<p>In this study, we employed two distinct modeling strategies to analyze sleep patterns from thigh-mounted accelerometer data. We used a sequential strategy, comprising an ensemble of four pairs of models, each pair featuring the same algorithm. This strategy aimed to make the prediction task more manageable for the algorithms by breaking it down into a sequence of two binary classifications: first predicting ‘in-bed’ time, then ‘sleep’ time. Simultaneously, we also used a multiclass approach utilizing a bidirectional Long Short-Term Memory (biLSTM)<span class="citation" data-cites="hochreiter1997">(<a href="#ref-hochreiter1997" role="doc-biblioref">Hochreiter and Schmidhuber 1997</a>)</span> neural network.</p>
<section id="models-in-sequence" class="level3">
<h3 class="anchored" data-anchor-id="models-in-sequence">Models in Sequence</h3>
<p>To predict in-bed time and sleep time accurately, we employed an ensemble learning strategy based on sequential binary classification models. This approach involved constructing a sequence of models using multiple machine learning algorithms to improve predictive accuracy. The process began with an initial model predicting in-bed time, followed by a second model that utilized the output of the initial model to predict sleep time. This sequential approach was applied across all four algorithms detailed below, with each subsequent model leveraging the outputs of the previous models for improved predictions.</p>
<ol type="1">
<li><p>Logistic Regression (LREG): Logistic regression served as a simple and fast baseline model. However, due to its linear nature, it may struggle with capturing complex relationships and non-linear patterns present in the accelerometer data.</p></li>
<li><p>Decision Tree (TREE): Decision trees are capable of handling non-linear patterns and are easily interpretable. However, they are prone to overfitting, particularly when dealing with complex patterns that require simultaneous consideration of multiple features.</p></li>
<li><p>Single-layer Feed-forward Neural Network (SNN): Single-layer feed-forward neural networks can effectively capture non-linear relationships, even with their relatively simple structure. However, they tend to be more challenging to interpret compared to simpler models. Additionally, careful tuning of the network’s architecture and training process is required to mitigate the risk of overfitting.</p></li>
<li><p>XGBoost (XGB): XGBoost is a powerful algorithm known for its ability to provide highly accurate predictions and handle complex, non-linear patterns in the data. It also incorporates built-in methods to prevent overfitting. However, training XGBoost models can be computationally intensive, and interpreting the predictions it generates can pose challenges.</p></li>
</ol>
</section>
<section id="multiclass-model" class="level3">
<h3 class="anchored" data-anchor-id="multiclass-model">Multiclass Model</h3>
<p>We also employed a biLSTM, a multiclass classifier, to predict three distinct states: out-of-bed-awake, in-bed-awake, and in-bed-asleep. The architecture of the biLSTM was set up with four layers, each equipped with 128 hidden units. This configuration was intentionally chosen to balance between model complexity and training efficiency: it provided the depth necessary for learning intricate patterns while remaining feasible for timely training. The bidirectional design of the LSTM served to enhance data interpretation and mitigate overfitting by doubling the hidden units at each time step. For input, we used tensors shaped as sequences, with each sequence spanning 10 minutes and a step size of one.This approach follows in the footsteps of previous studies that utilized LSTM models for sleep detection. These studies showcased the promising potential of LSTMs in capturing complex temporal patterns. Particularly, the works of Sano et al. <span class="citation" data-cites="sano2019">(<a href="#ref-sano2019" role="doc-biblioref">Sano et al. 2019</a>)</span> and Chen et al. <span class="citation" data-cites="chen2021">(<a href="#ref-chen2021" role="doc-biblioref">Chen et al. 2021</a>)</span> demonstrated the effectiveness of LSTM models in improving sleep detection using accelerometer data, underscoring the value of this modeling approach.</p>
</section>
<section id="model-training" class="level3">
<h3 class="anchored" data-anchor-id="model-training">Model Training</h3>
<p>For the models in sequence, we trained four pairs of classification models. Each pair was designed to distinguish between in-bed/out-of-bed and asleep/awake states, respectively. The dataset was randomly split into a training set and a testing set, each containing approximately 50% of the subjects. This division ensured that samples from the same night were never simultaneously present in both sets. To optimize hyperparameters, we performed a 10-fold Monte Carlo cross-validation on a regular grid, comprising 20 different combinations of hyperparameters. The F1 score served as the optimization metric. The best-performing set of hyperparameters was then used to fit the models to the full training dataset. This approach allowed us to maximize performance by leveraging all available data. Moreover, after extracting the in-bed time from the initial sequential models, the imbalance on the resulting dataset could cause biases during model training, as models may favor predicting the majority class. To rectify this, we employed the Synthetic Minority Over-sampling Technique (SMOTE)<span class="citation" data-cites="chawla2002">(<a href="#ref-chawla2002" role="doc-biblioref">Chawla et al. 2002</a>)</span>. SMOTE generates new samples by interpolating random samples with their nearest neighbors. We utilized the themis R package<span class="citation" data-cites="themis">(<a href="#ref-themis" role="doc-biblioref">Hvitfeldt 2023</a>)</span> to implement SMOTE, resulting in a balanced distribution of training samples across both classes.</p>
<p>The biLSTM model was trained to differentiate between three states: out-of-bed-awake, in-bed-awake, and in-bed-asleep. The data used for training the biLSTM was randomly divided into training, validation, and test sets, based on a 50/25/25 split. We ensured that data from the same night was not present across different sets. The model was trained using the Adam optimizer, selected for its computational efficiency and adaptability of the learning rate during training. Given the multiclass classification task with mutually exclusive classes, we employed the cross-entropy loss function. To obtain a probability distribution over the classes, the softmax activation function was applied at the output layer. We evaluated the model’s performance using the F1 score on both the training and validation sets. We implemented early stopping with a patience of 3 epochs, halting the training process if there was no improvement in the validation loss over three consecutive epochs.</p>
</section>
<section id="model-validation" class="level3">
<h3 class="anchored" data-anchor-id="model-validation">Model Validation</h3>
<p>In our study, we utilized standard evaluation metrics to assess the performance of each model on an epoch-to-epoch basis. These include accuracy (<span class="math inline">\(accuracy = \frac{TP+TN}{TP+TN+FP+FN}\)</span>), sensitivity (<span class="math inline">\(sensitivity = \frac{TP}{TP+FN}\)</span>), specificity (<span class="math inline">\(specificity = \frac{TN}{TN+FP}\)</span>), precision (<span class="math inline">\(precision = \frac{TP}{TP+FP}\)</span>), negative predictive value (NPV, <span class="math inline">\(NPV = \frac{TN}{TN + FN}\)</span>), and F1 score (<span class="math inline">\(F_1 = 2 * \frac{precision * sensitivity}{precision + sensitivity}\)</span>).</p>
<p>In the context of our sequential learning strategy, the initial models were tasked with the binary classification of in-bed vs.&nbsp;out-of-bed. For this task, we assessed performance using the F1-score, accuracy, sensitivity, specificity, and precision metrics. The second models in our sequential learning strategy focused on the binary classification of asleep vs.&nbsp;awake. For these models, we considered the same metrics, in addition to the negative predictive rate. The class imbalance in this case led us to compute the F1 score as an unweighted macro-average. Additionally, we evaluated the multiclass classifier, biLSTM, using the same metrics. To do this, we considered the multiclass output as to binary classifications, where the first was out-of-bed vs the rest and the second binary classification as in-bed-awake vs in-bed-asleep. To further illustrate model performance, we provide confusion matrices for the full dataset, encompassing both in-bed and out-of-bed data. These matrices report relative counts, column percentages (the proportion of the true class accurately predicted), and row percentages (the proportion of predictions correctly classified). We considered both the in-bed/out-of-bed and awake/asleep scoring tasks as binary classification problems, designating in-bed and asleep as the positive labels and out-of-bed and awake as the negative labels in accordance with previous research<span class="citation" data-cites="hjorth2012 kushida2001">(<a href="#ref-hjorth2012" role="doc-biblioref">Hjorth et al. 2012</a>; <a href="#ref-kushida2001" role="doc-biblioref">Kushida et al. 2001</a>)</span>.</p>
<p>To assess the performance of our models in deriving sleep quality parameters, we utilized Bland-Altman plots and Pearson correlations. The Bland-Altman method was employed specifically to determine the level of agreement between two measurement techniques. Considering our dataset contained multiple observations per subject, we integrated a bootstrap procedure to address this extra source of variability. We calculated the mean difference (bias) and defined the LOA as the mean difference plus or minus 1.96 times the standard deviation of these differences. To ensure our measurements were robust and accounted for intra-subject variability, we estimated the 95% confidence intervals for both the bias and the LOA using a bias-corrected and accelerated bootstrap method, utilizing 10,000 bootstrap replicates. The sleep quality parameteres included are defined as follews in accordance with the ZM definitions:</p>
<ol type="1">
<li><p>Sleep Period Time (SPT) - This refers to the total duration of the sleep period, which is defined as the time from the start to the end of the ZM recording.</p></li>
<li><p>Total Sleep Time (TST) - This is the time spent asleep within the SPT.</p></li>
<li><p>Sleep Efficiency (SE) - This is the ratio between TST and SPT, representing the proportion of the sleep period that was actually spent asleep.</p></li>
<li><p>Latency Until Persistent Sleep (LPS) - This metric represents the time it takes to transition from wakefulness to sustained sleep. It is calculated as the time from the beginning of the ZM recording until the first period when 10 out of 12 minutes are scored as sleep.</p></li>
<li><p>Wake After Sleep Onset (WASO) - This refers to the time spent awake after initially falling asleep and before the final awakening. In our analysis, a period is counted as ‘awake’ only if it consists of 3 or more contiguous 30-second epochs which is also how the ZM summarizes WASO.</p></li>
</ol>
<p>R version 4.3.0 (2023-04-21)<span class="citation" data-cites="R-lang">(<a href="#ref-R-lang" role="doc-biblioref">R Core Team 2023</a>)</span> and the Tidymodels<span class="citation" data-cites="tidymodels">(<a href="#ref-tidymodels" role="doc-biblioref">Kuhn and Wickham 2020</a>)</span> and Tidyverse<span class="citation" data-cites="tidyverse">(<a href="#ref-tidyverse" role="doc-biblioref">Wickham et al. 2019</a>)</span> suite of packages were used as the core tools for model development and analyses. Python version 3.10.6<span class="citation" data-cites="10.5555/1593511">(<a href="#ref-10.5555/1593511" role="doc-biblioref">Van Rossum and Drake 2009</a>)</span> and PyTorch<span class="citation" data-cites="NEURIPS2019_9015">(<a href="#ref-NEURIPS2019_9015" role="doc-biblioref">Paszke et al. 2019</a>)</span> were used to implement the biLSTM model. All code used to perform the analysis and generate the figures in this paper are available in <a href="https://github.com/esbenlykke/sleep_study">this repository</a>.</p>
</section>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>As reported in <a href="#tbl-zm_overview">Table&nbsp;1</a> the sleep quality parameters derived from ZM predictions were modified by the implementation of 5-minute and 10-minute median filters. SPT were consistent across raw and filtered datasets (mean: 9.2 ± 2.1 hours), corresponding to the length of the ZM recording. TST and SE increased in the filtered data, implying the filters categorize some wakefulness as sleep. Specifically, TST increased from a raw mean of 7.7 ± 1.9 hours to 8.1 ± 2.0 hours (5-minute filter) and 8.2 ± 2.1 hours (10-minute filter), while SE rose from 82.6 ± 12.0% to 86.4 ± 12.7% and 87.5 ± 12.9% respectively. LPS also elevated, suggesting the filter smooths out brief awakenings at sleep onset, leading to a prolonged time to persistent sleep. A significant change was seen in WASO, which dropped from 39.0 ± 33.6 minutes in raw data to 30.6 ± 46.8 minutes and 22.3 ± 55.4 minutes in the 5-minute and 10-minute filtered data, respectively. The number of awakenings was also considerably reduced with the application of filters. In the raw data, the average number of awakenings was 34.46 ± 11.33 per night, which reduced to 4.43 ± 3.26 and 1.95 ± 2.01 for the 5-minute and 10-minute filtered data sets respectively.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-zm_overview" class="anchored">

<div id="iqhdfajsjb" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#iqhdfajsjb table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#iqhdfajsjb thead, #iqhdfajsjb tbody, #iqhdfajsjb tfoot, #iqhdfajsjb tr, #iqhdfajsjb td, #iqhdfajsjb th {
  border-style: none;
}

#iqhdfajsjb p {
  margin: 0;
  padding: 0;
}

#iqhdfajsjb .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#iqhdfajsjb .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#iqhdfajsjb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#iqhdfajsjb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#iqhdfajsjb .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iqhdfajsjb .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iqhdfajsjb .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#iqhdfajsjb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#iqhdfajsjb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#iqhdfajsjb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#iqhdfajsjb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#iqhdfajsjb .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#iqhdfajsjb .gt_spanner_row {
  border-bottom-style: hidden;
}

#iqhdfajsjb .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#iqhdfajsjb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#iqhdfajsjb .gt_from_md > :first-child {
  margin-top: 0;
}

#iqhdfajsjb .gt_from_md > :last-child {
  margin-bottom: 0;
}

#iqhdfajsjb .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#iqhdfajsjb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#iqhdfajsjb .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#iqhdfajsjb .gt_row_group_first td {
  border-top-width: 2px;
}

#iqhdfajsjb .gt_row_group_first th {
  border-top-width: 2px;
}

#iqhdfajsjb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iqhdfajsjb .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#iqhdfajsjb .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#iqhdfajsjb .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iqhdfajsjb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#iqhdfajsjb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#iqhdfajsjb .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#iqhdfajsjb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#iqhdfajsjb .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#iqhdfajsjb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iqhdfajsjb .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#iqhdfajsjb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#iqhdfajsjb .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#iqhdfajsjb .gt_left {
  text-align: left;
}

#iqhdfajsjb .gt_center {
  text-align: center;
}

#iqhdfajsjb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#iqhdfajsjb .gt_font_normal {
  font-weight: normal;
}

#iqhdfajsjb .gt_font_bold {
  font-weight: bold;
}

#iqhdfajsjb .gt_font_italic {
  font-style: italic;
}

#iqhdfajsjb .gt_super {
  font-size: 65%;
}

#iqhdfajsjb .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#iqhdfajsjb .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#iqhdfajsjb .gt_indent_1 {
  text-indent: 5px;
}

#iqhdfajsjb .gt_indent_2 {
  text-indent: 10px;
}

#iqhdfajsjb .gt_indent_3 {
  text-indent: 15px;
}

#iqhdfajsjb .gt_indent_4 {
  text-indent: 20px;
}

#iqhdfajsjb .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;1:  <p>Overview of characteristics of the ZM sleep quality summaries per
night. Values are represented as mean (SD).</p> </caption>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="SPT (hrs)">SPT (hrs)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="TST (hrs)">TST (hrs)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="SE (%)">SE (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="LPS (min)">LPS (min)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="WASO (min)">WASO (min)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Awakenings (N)">Awakenings (N)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="name" class="gt_row gt_left">Raw ZM Predictions</td>
<td headers="spt" class="gt_row gt_right">9.2 (2.1)</td>
<td headers="tst" class="gt_row gt_right">7.7 (1.9)</td>
<td headers="se" class="gt_row gt_right">82.6 (12)</td>
<td headers="lps" class="gt_row gt_right">34.5 (27.9)</td>
<td headers="waso" class="gt_row gt_right">39 (33.6)</td>
<td headers="no" class="gt_row gt_right">34.5 (11.3)</td></tr>
    <tr><td headers="name" class="gt_row gt_left">5-Min Median</td>
<td headers="spt" class="gt_row gt_right">9.2 (2.1)</td>
<td headers="tst" class="gt_row gt_right">8.1 (2)</td>
<td headers="se" class="gt_row gt_right">86.4 (12.7)</td>
<td headers="lps" class="gt_row gt_right">36.3 (39.8)</td>
<td headers="waso" class="gt_row gt_right">30.6 (46.8)</td>
<td headers="no" class="gt_row gt_right">4.4 (3.3)</td></tr>
    <tr><td headers="name" class="gt_row gt_left">10-Min Median</td>
<td headers="spt" class="gt_row gt_right">9.2 (2.1)</td>
<td headers="tst" class="gt_row gt_right">8.2 (2.1)</td>
<td headers="se" class="gt_row gt_right">87.5 (12.9)</td>
<td headers="lps" class="gt_row gt_right">38 (48.7)</td>
<td headers="waso" class="gt_row gt_right">22.3 (55.4)</td>
<td headers="no" class="gt_row gt_right">1.9 (2)</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<section id="performance-on-epoch-to-epoch-basis" class="level2">
<h2 class="anchored" data-anchor-id="performance-on-epoch-to-epoch-basis">Performance on Epoch-to-Epoch Basis</h2>
<p>The epoch-to-epoch evaluation of predicting in-bed time is outlined in <a href="#tbl-in_bed_performance">Table&nbsp;2</a>, and demonstrates practically equivalent performance across all model types. The F1 score ranges from 94.4% (Decision Tree) to 95.4% (XGBoost), while accuracy ranges from 95.3% (Decision Tree) to 96.1% (XGBoost). Sensitivity, Precision, and Specificity also demonstrate consistent results across the models. The XGBoost model, despite recording the highest metrics with an F1 score of 95.4% and accuracy of 96.1%, outpaced the others only marginally.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-in_bed_performance" class="anchored">

<div id="duuntdsdwi" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#duuntdsdwi table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#duuntdsdwi thead, #duuntdsdwi tbody, #duuntdsdwi tfoot, #duuntdsdwi tr, #duuntdsdwi td, #duuntdsdwi th {
  border-style: none;
}

#duuntdsdwi p {
  margin: 0;
  padding: 0;
}

#duuntdsdwi .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#duuntdsdwi .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#duuntdsdwi .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#duuntdsdwi .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#duuntdsdwi .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#duuntdsdwi .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#duuntdsdwi .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#duuntdsdwi .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#duuntdsdwi .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#duuntdsdwi .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#duuntdsdwi .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#duuntdsdwi .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#duuntdsdwi .gt_spanner_row {
  border-bottom-style: hidden;
}

#duuntdsdwi .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#duuntdsdwi .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#duuntdsdwi .gt_from_md > :first-child {
  margin-top: 0;
}

#duuntdsdwi .gt_from_md > :last-child {
  margin-bottom: 0;
}

#duuntdsdwi .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#duuntdsdwi .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#duuntdsdwi .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#duuntdsdwi .gt_row_group_first td {
  border-top-width: 2px;
}

#duuntdsdwi .gt_row_group_first th {
  border-top-width: 2px;
}

#duuntdsdwi .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#duuntdsdwi .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#duuntdsdwi .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#duuntdsdwi .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#duuntdsdwi .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#duuntdsdwi .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#duuntdsdwi .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#duuntdsdwi .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#duuntdsdwi .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#duuntdsdwi .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#duuntdsdwi .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#duuntdsdwi .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#duuntdsdwi .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#duuntdsdwi .gt_left {
  text-align: left;
}

#duuntdsdwi .gt_center {
  text-align: center;
}

#duuntdsdwi .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#duuntdsdwi .gt_font_normal {
  font-weight: normal;
}

#duuntdsdwi .gt_font_bold {
  font-weight: bold;
}

#duuntdsdwi .gt_font_italic {
  font-style: italic;
}

#duuntdsdwi .gt_super {
  font-size: 65%;
}

#duuntdsdwi .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#duuntdsdwi .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#duuntdsdwi .gt_indent_1 {
  text-indent: 5px;
}

#duuntdsdwi .gt_indent_2 {
  text-indent: 10px;
}

#duuntdsdwi .gt_indent_3 {
  text-indent: 15px;
}

#duuntdsdwi .gt_indent_4 {
  text-indent: 20px;
}

#duuntdsdwi .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;2:  <p>In-bed performance metrics</p> </caption>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="F1 Score (%)">F1 Score (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Accuracy (%)">Accuracy (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Sensitivity (%)">Sensitivity (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Precision (%)">Precision (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Specificity (%)">Specificity (%)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="model" class="gt_row gt_left">Decision Tree</td>
<td headers="F1 Score (%)" class="gt_row gt_right">94.4</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.3</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">93.1</td>
<td headers="Precision (%)" class="gt_row gt_right">95.6</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.9</td></tr>
    <tr><td headers="model" class="gt_row gt_left">Logistic Regression</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.0</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.7</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.0</td>
<td headers="Precision (%)" class="gt_row gt_right">94.9</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.3</td></tr>
    <tr><td headers="model" class="gt_row gt_left">Feed-Forward Neural Net</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.0</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.8</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.1</td>
<td headers="Precision (%)" class="gt_row gt_right">95.0</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.3</td></tr>
    <tr><td headers="model" class="gt_row gt_left">XGBoost</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.4</td>
<td headers="Accuracy (%)" class="gt_row gt_right">96.1</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.8</td>
<td headers="Precision (%)" class="gt_row gt_right">94.9</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.2</td></tr>
    <tr><td headers="model" class="gt_row gt_left">biLSTM</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.2</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.3</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.3</td>
<td headers="Precision (%)" class="gt_row gt_right">95.1</td>
<td headers="Specificity (%)" class="gt_row gt_right">95.3</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p><a href="#tbl-sleep_performance">Table&nbsp;3</a> details the performance of all sequential model types on raw and median-filtered (5 and 10 minute) ZM predictions for sleep/wake classification. For raw ZM predictions, the F1 scores, which are unweighted macro averages, range from 65.6% (biLSTM) to 76.2% (XGBoost). All models perform comparably, but the low specificity values (62.5% to 70.9%) suggest difficulty in correctly classifying awake epochs. Applying a 5-minute median filter improves the performance metrics. The XGBoost model tops the charts with an F1 score of 79.2% and NPV of 74.0%. However, specificity still remains low, with values between 54.7% (XGBoost) and 74.8% (Logistic Regression) across all models. With a 10-minute median filter, the metrics improve further. The XGBoost model still leads with an F1 score of 80.9% and an NPV of 75.9%. But, specificity remains low, ranging from 57.5% (Decision Tree) to 76.4% (Logistic Regression) across all models.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-sleep_performance" class="anchored">

<div id="jqcpuuecdz" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>@import url("https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
#jqcpuuecdz table {
  font-family: Montserrat, 'Noto Sans', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji', ibm;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#jqcpuuecdz thead, #jqcpuuecdz tbody, #jqcpuuecdz tfoot, #jqcpuuecdz tr, #jqcpuuecdz td, #jqcpuuecdz th {
  border-style: none;
}

#jqcpuuecdz p {
  margin: 0;
  padding: 0;
}

#jqcpuuecdz .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 12px;
  font-weight: normal;
  font-style: normal;
  background-color: #F6F6F6;
  width: auto;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #40C5FF;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 3px;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#jqcpuuecdz .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#jqcpuuecdz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #F6F6F6;
  border-bottom-width: 0;
}

#jqcpuuecdz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #F6F6F6;
  border-top-width: 0;
}

#jqcpuuecdz .gt_heading {
  background-color: #F6F6F6;
  text-align: left;
  border-bottom-color: #F6F6F6;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#jqcpuuecdz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 0px;
  border-bottom-color: #D3D3D3;
}

#jqcpuuecdz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #40C5FF;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #ECECEC;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#jqcpuuecdz .gt_col_heading {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#jqcpuuecdz .gt_column_spanner_outer {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#jqcpuuecdz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#jqcpuuecdz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#jqcpuuecdz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #ECECEC;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#jqcpuuecdz .gt_spanner_row {
  border-bottom-style: hidden;
}

#jqcpuuecdz .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #BEBEBE;
  border-bottom-style: solid;
  border-bottom-width: 1px;
  border-bottom-color: #BEBEBE;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#jqcpuuecdz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #BEBEBE;
  border-bottom-style: solid;
  border-bottom-width: 1px;
  border-bottom-color: #BEBEBE;
  vertical-align: middle;
}

#jqcpuuecdz .gt_from_md > :first-child {
  margin-top: 0;
}

#jqcpuuecdz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#jqcpuuecdz .gt_row {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: white;
  border-top-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#jqcpuuecdz .gt_stub {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#jqcpuuecdz .gt_stub_row_group {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#jqcpuuecdz .gt_row_group_first td {
  border-top-width: 1px;
}

#jqcpuuecdz .gt_row_group_first th {
  border-top-width: 1px;
}

#jqcpuuecdz .gt_summary_row {
  color: #333333;
  background-color: #F6F6F6;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#jqcpuuecdz .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#jqcpuuecdz .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#jqcpuuecdz .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#jqcpuuecdz .gt_grand_summary_row {
  color: #333333;
  background-color: #F6F6F6;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#jqcpuuecdz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#jqcpuuecdz .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#jqcpuuecdz .gt_striped {
  background-color: #ECECEC;
}

#jqcpuuecdz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 3px;
  border-bottom-color: #FFFFFF;
}

#jqcpuuecdz .gt_footnotes {
  color: #333333;
  background-color: #F6F6F6;
  border-bottom-style: none;
  border-bottom-width: 0px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#jqcpuuecdz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#jqcpuuecdz .gt_sourcenotes {
  color: #333333;
  background-color: #F6F6F6;
  border-bottom-style: none;
  border-bottom-width: 0px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#jqcpuuecdz .gt_sourcenote {
  font-size: 12px;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#jqcpuuecdz .gt_left {
  text-align: left;
}

#jqcpuuecdz .gt_center {
  text-align: center;
}

#jqcpuuecdz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#jqcpuuecdz .gt_font_normal {
  font-weight: normal;
}

#jqcpuuecdz .gt_font_bold {
  font-weight: bold;
}

#jqcpuuecdz .gt_font_italic {
  font-style: italic;
}

#jqcpuuecdz .gt_super {
  font-size: 65%;
}

#jqcpuuecdz .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#jqcpuuecdz .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#jqcpuuecdz .gt_indent_1 {
  text-indent: 5px;
}

#jqcpuuecdz .gt_indent_2 {
  text-indent: 10px;
}

#jqcpuuecdz .gt_indent_3 {
  text-indent: 15px;
}

#jqcpuuecdz .gt_indent_4 {
  text-indent: 20px;
}

#jqcpuuecdz .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" style="table-layout: fixed;; width: 0px" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;3:  <p>Performance of the sleep/wake classification of the sequential
models.</p> </caption>
  <colgroup>
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
  </colgroup>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="F1 Score (%)">F1 Score (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Precision (%)">Precision (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="NPV (%)">NPV (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Sensitivity (%)">Sensitivity (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Specificity (%)">Specificity (%)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr class="gt_group_heading_row">
      <th colspan="6" class="gt_group_heading" scope="colgroup" id="Raw ZM Predictions">Raw ZM Predictions</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="Raw ZM Predictions  model" class="gt_row gt_left" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">Decision Tree</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">72.9</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">93.2</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">48.4</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">86.3</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">67.1</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left gt_striped">Logistic Regression</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right gt_striped">71.0</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right gt_striped">93.7</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right gt_striped">43.9</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right gt_striped">82.7</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right gt_striped">70.9</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left">Neural Network</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right">71.8</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right">93.8</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right">45.1</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right">83.6</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right">70.8</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left gt_striped">XGBoost</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right gt_striped">76.2</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right gt_striped">92.8</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right gt_striped">58.0</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right gt_striped">91.3</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right gt_striped">62.8</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left">biLSTM</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right">65.6</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right">80.6</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right">80.6</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right">62.5</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right">62.5</td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="6" class="gt_group_heading" scope="colgroup" id="5-Min Median">5-Min Median</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median  model" class="gt_row gt_left gt_striped">Decision Tree</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">75.5</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right gt_striped">94.2</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right gt_striped">55.5</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">93.4</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">59.0</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left">Logistic Regression</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right">68.3</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right">95.8</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right">36.0</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right">81.4</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right">74.8</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left gt_striped">Neural Network</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">71.7</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right gt_striped">95.8</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right gt_striped">41.6</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">85.6</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">73.1</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left">XGBoost</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right">79.2</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right">93.9</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right">74.0</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right">97.3</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right">54.7</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left gt_striped">biLSTM</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">70.3</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right gt_striped">84.6</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right gt_striped">84.6</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">66.2</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">66.2</td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="6" class="gt_group_heading" scope="colgroup" id="10-Min Median">10-Min Median</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="10-Min Median  model" class="gt_row gt_left">Decision Tree</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right">76.3</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right">94.7</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right">58.1</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right">94.9</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right">57.5</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left gt_striped">Logistic Regression</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">68.0</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right gt_striped">96.5</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right gt_striped">34.3</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">81.9</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">76.4</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left">Neural Network</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right">71.0</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right">96.1</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right">39.5</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right">86.5</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right">71.4</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left gt_striped">XGBoost</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">80.9</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right gt_striped">94.9</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right gt_striped">75.8</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">97.7</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">57.6</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left">biLSTM</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right">70.9</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right">75.1</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right">75.1</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right">68.5</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right">68.5</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p>A complete set of confusion matrices generated from data both containing the out-of-bed and in-bed time are presented in <a href="#fig-conf_mat">Figure&nbsp;4</a>. The figure shows favorable epoch-to-epoch performance across across all sequential models, however, it is evident that the biLSTM is less successful in classifying the in-bed-awake class which cannot be deduced from the confusion matrices from the sequential models.</p>
<div id="fig-conf_mat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/all_conf_mats.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Confusion matrices for binary sleep prediction. The middle of each tile is the normalized count (overall percentage) and, beneath it, the count. The bottom number is the column percentage (target). At the right side of each tile is the row percentage (prediction). i) decision tree, ii) logistic regression, iii) feed-forward neural net, iv) XGBoost, and v) biLSTM.</figcaption>
</figure>
</div>
</section>
<section id="evaluation-of-sleep-quality-parameters" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-of-sleep-quality-parameters">Evaluation of Sleep Quality Parameters</h2>
<p><a href="#tbl-ba_cor">Table&nbsp;4</a> presents a comparative analysis of the included models used to predict various sleep quality parameters (SPT, TST, SE, LPS, WASO) using the 5-minute median filtered ZM predictions. To see the full table including models developed from raw ZM predictions and 10-minute median filtered ZM predictions, see <strong>[SUPP. MAT.]</strong>. In terms of bias, the decision tree model consistently underestimated SPT, TST, and SE, and overestimated LPS and WASO in comparison to ZM. The logistic regression model had similar trends, with more pronounced underestimation in TST and overestimation in LPS. The eed-forward neural network also exhibited similar bias as the decision tree and the logistic regression models, but with a higher overestimation in WASO. On the other hand, the XGBoost model showed least bias among all, especially in its 5-minute median predictions. Considering LOA, the decision tree had higher variability across different sleep quality parameters and filtering techniques, particularly for LPS and WASO, which indicates lower agreement with ZM. Other models had comparable LOA but with notable exceptions. For example, TST LOA for the logistic regression model was particularly wide in the 5-minute median predictions. Correlation-wise, the pearson coefficient, revealed that the XGBoost model consistently had the highest correlation with ZM across all sleep qualityparameters and filtering methods Notably, the XGBoost’s 5-minute median predictions showed the strongest correlation (0.66) for TST among all models and filtering techniques.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-ba_cor" class="anchored">

<div id="arzstgsbqn" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#arzstgsbqn table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#arzstgsbqn thead, #arzstgsbqn tbody, #arzstgsbqn tfoot, #arzstgsbqn tr, #arzstgsbqn td, #arzstgsbqn th {
  border-style: none;
}

#arzstgsbqn p {
  margin: 0;
  padding: 0;
}

#arzstgsbqn .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#arzstgsbqn .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#arzstgsbqn .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#arzstgsbqn .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#arzstgsbqn .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#arzstgsbqn .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#arzstgsbqn .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#arzstgsbqn .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#arzstgsbqn .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#arzstgsbqn .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#arzstgsbqn .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#arzstgsbqn .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#arzstgsbqn .gt_spanner_row {
  border-bottom-style: hidden;
}

#arzstgsbqn .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#arzstgsbqn .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#arzstgsbqn .gt_from_md > :first-child {
  margin-top: 0;
}

#arzstgsbqn .gt_from_md > :last-child {
  margin-bottom: 0;
}

#arzstgsbqn .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#arzstgsbqn .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#arzstgsbqn .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#arzstgsbqn .gt_row_group_first td {
  border-top-width: 2px;
}

#arzstgsbqn .gt_row_group_first th {
  border-top-width: 2px;
}

#arzstgsbqn .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#arzstgsbqn .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#arzstgsbqn .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#arzstgsbqn .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#arzstgsbqn .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#arzstgsbqn .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#arzstgsbqn .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#arzstgsbqn .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#arzstgsbqn .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#arzstgsbqn .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#arzstgsbqn .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#arzstgsbqn .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#arzstgsbqn .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#arzstgsbqn .gt_left {
  text-align: left;
}

#arzstgsbqn .gt_center {
  text-align: center;
}

#arzstgsbqn .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#arzstgsbqn .gt_font_normal {
  font-weight: normal;
}

#arzstgsbqn .gt_font_bold {
  font-weight: bold;
}

#arzstgsbqn .gt_font_italic {
  font-style: italic;
}

#arzstgsbqn .gt_super {
  font-size: 65%;
}

#arzstgsbqn .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#arzstgsbqn .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#arzstgsbqn .gt_indent_1 {
  text-indent: 5px;
}

#arzstgsbqn .gt_indent_2 {
  text-indent: 10px;
}

#arzstgsbqn .gt_indent_3 {
  text-indent: 15px;
}

#arzstgsbqn .gt_indent_4 {
  text-indent: 20px;
}

#arzstgsbqn .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" style="table-layout: fixed;" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;4:  <p>Summary of Bias, Limits of Agreement, and Pearson Correlation for
various Sleep Parameter Predictions (SPT, TST, SE, LPS, WASO) using
different Machine Learning Models (Decision Tree, Logistic Regression,
Feed-Forward Neural Net, XGBoost) with Raw ZM Predictions, 5-Min and
10-Min Median as predictors. Each value is provided with its 95%
Confidence Interval (CI).</p> </caption>
  <colgroup>
    <col style="width:200px;">
    <col>
    <col>
    <col>
    <col>
  </colgroup>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Bias (95% CI)">Bias (95% CI)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="LOA (95% CI)">LOA (95% CI)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="LOA (95% CI)">LOA (95% CI)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Pearson, <em>r</em> (95% CI)">Pearson, <em>r</em> (95% CI)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - Decision Tree">5-Min Median - Decision Tree</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">-21.6 (-25.6;-17.6)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-117.5 (-125.6;-110.7)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">74.2 (63.9;85.9)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.54 (0.48;0.6)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">-50.5 (-55.2;-46)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-161.4 (-175.8;-151.3)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">60.4 (51.5;71.7)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.48 (0.42;0.54)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">-5.5 (-6.3;-4.7)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-23.9 (-26.4;-22.2)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">12.9 (11.6;14.6)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.22 (0.14;0.29)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">24.6 (19.7;29.1)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-88.8 (-115;-77.3)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">138 (126.2;156.7)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.06 (-0.02;0.14)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">9.9 (6.5;14)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-79.4 (-109;-63.1)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">99.2 (80;136.1)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.15 (0.07;0.22)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - Logistic Regression">5-Min Median - Logistic Regression</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">-3.7 (-8;1)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-112.2 (-120.9;-105.2)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">104.8 (94;117.4)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.38 (0.3;0.44)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">-139.7 (-146.9;-133)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-305.6 (-323.6;-291.8)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">26.2 (16.1;38.6)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.09 (0.01;0.17)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">-23.2 (-24.3;-22.2)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-48.1 (-50.9;-46.1)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">1.7 (0.1;3.8)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.13 (0.05;0.21)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">58.1 (53.4;62.6)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-52.3 (-75;-40.1)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">168.6 (155.9;187.7)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.05 (-0.03;0.13)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">45.4 (41.7;49.7)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-50.7 (-74.4;-38.4)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">141.5 (126.8;173)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.19 (0.11;0.27)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - Feed-Forward Neural Net">5-Min Median - Feed-Forward Neural Net</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">-3.9 (-8.1;0.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-112.7 (-122;-105.2)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">104.9 (94.1;118.4)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.38 (0.3;0.44)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">-126.5 (-132.8;-120.3)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-276.8 (-291.3;-264.7)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">23.9 (14.8;33.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.25 (0.17;0.32)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">-20.9 (-21.9;-19.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-44.3 (-46.3;-42.5)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">2.5 (1.1;4)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.21 (0.13;0.29)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">35.3 (30.7;39.8)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-75.8 (-102.3;-63.4)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">146.5 (134.4;166.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.07 (-0.01;0.15)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">45 (41.2;49.2)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-51.8 (-76.4;-39.1)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">141.7 (125.8;174.1)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.21 (0.14;0.29)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - XGboost">5-Min Median - XGboost</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">0.2 (-3.7;4.5)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-97.4 (-106.2;-90.3)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">97.8 (86.6;111)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.56 (0.5;0.61)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">-7 (-10.8;-3.3)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-95.5 (-105.2;-88)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">81.4 (72.4;92.5)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.66 (0.61;0.7)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">-1.1 (-1.7;-0.5)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-15.6 (-17;-14.4)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">13.3 (12.2;14.7)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.44 (0.38;0.51)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">28.5 (23.9;32.6)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-76.4 (-104.2;-63.3)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">133.4 (120.4;154.2)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.12 (0.04;0.2)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">-0.9 (-3.9;3)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-83.4 (-113.1;-66)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">81.7 (62;119.6)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.26 (0.18;0.33)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - biLSTM">5-Min Median - biLSTM</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">-36.1 (-41.7;-30)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-136.1 (-146.3;-126.9)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">64 (51.1;78.6)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.54 (0.45;0.62)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">12.8 (7.4;18.3)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-80.1 (-89.8;-72.3)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">105.8 (94.3;118.8)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.63 (0.55;0.69)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">8 (7.2;8.8)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-5.1 (-6.8;-3.8)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">21.1 (19.5;23.1)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.16 (0.04;0.27)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">-15.7 (-25.9;-7.5)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-169 (-230.7;-127.9)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">137.6 (101.1;184.9)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.09 (-0.02;0.2)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">-3 (-9.9;7.7)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-144.1 (-197.2;-107.2)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">138.1 (90.8;211.4)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.02 (-0.1;0.13)</p>
</div></td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p><a href="#fig-xgb_ba_cor">Figure&nbsp;5</a> shows the agreement between the XGBoost model, trained on 5-minute median filtered ZM predictions, and the 5-minute median-smoothed ZM-derived sleep quality parameters. The Bland-Altman plot for the SPT reveals a significant level of agreement with the ZM, as evidenced by a positive correlation. However, the presence of extreme outliers widens the limits of agreement (LOA). The scatterplot for SPT also demonstrates a positive trend, indicating a moderate linear correlation between the XGBoost model and the ZM-derived sleep quality parameters.In terms of TST, perfect agreement is not observed for a substantial number of nights, but there is a positive correlation between the XGBoost model and ZM-derived sleep quality parameters. The bias and LOA for TST are comparable to those observed for SPT, indicating a consistent level of agreement between the two methods. The scatterplot for TST also shows a slightly higher correlation, primarily driven by the absence of extreme outliers.Furthermore, the remaining three sleep quality parameters, SE, LPS, and WASO, exhibit heteroscedasticity in contrast to SPT and TST. This outcome is expected as achieving 100% sleep efficiency is relatively rare, resulting in less disagreement between the methods as values approach the upper limit. However, as sleep efficiency decreases, the potential for discrepancies and differing interpretations between the methods increases, leading to greater heteroscedasticity. A moderate linear correlation is observed between the XGBoost model and ZM-derived sleep quality parameters for SE, indicating a positive relationship. However, a poor correlation is observed for LPS and WASO, suggesting less agreement between the two methods for these parameters. Similar plots for all models are available in the supplementary materials.</p>
<div id="fig-xgb_ba_cor" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/median_5_xgboost_ba_cor.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Comparison of sleep quality parameters derived from the XGBoost model trained on the 5-minute smoothed ZM predictions. The left column displays Bland-Altman plots. Dashed lines represent the bias (the average difference between the two measurements) and LOA, with the 95% confidence intervals represented as the grayed areas. The right column displays scatter plots of XGBoost-derived vs ZM-derived sleep quality parameters. The dashed line represents the identity line, while the full-drawn line represents the best linear fit. Pearson’s correlations are annotated in the upper left corner.</figcaption>
</figure>
</div>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>In an effort to mature the methods for estimating sleep from thigh-worn accelerometers, we evaluated various models for predicting in-bed and sleep time and their derived sleep quality parameters. Furthermore, we trained and evaluated the models using raw and median-filtered gold standard predictions from the ZM. In general, all sequential models performed well at predicting in-bed time. More challenging was it to distinguish wake from sleep on the extracted in-bed time, however, the performance of the sequential models were enhanced by the application of median filters. Moreover, even though the multiclass biLSTM showed good performance across F1 score, precision and NPV, the derived sleep quality parameters were not on par with the XGBoost model which demonstrated the highest performance metrics across all evaluations, including epoch-to-epoch prediction and sleep quality parameter derivatives. Despite this, all sequential models showed low specificity values, indicating difficulty in correctly classifying awake epochs during time in bed. The application of 5-minute and 10-minute median filters improved the performance metrics of all models, with the XGBoost model consistently leading. The median filters increased total sleep time and sleep efficiency, while reducing wake after sleep onset and the number of awakenings. The XGBoost model also showed the least bias and highest correlation with ZM across sleep quality parameters.</p>
<p>Limited research exists regarding the epoch-to-epoch effectiveness of classifying in-bed time based on data from thigh-worn accelerometers. Nevertheless, Carlson and colleagues provided compelling insights. They demonstrated that a third-party algorithm, “ProcessingPal,” and a proprietary one, “CREA,” achieved accuracies of 91% and 86% respectively. These algorithms, evaluated against self-reported measures<span class="citation" data-cites="carlson2021">(<a href="#ref-carlson2021" role="doc-biblioref">Carlson et al. 2021</a>)</span>, produced F1 scores as high as 95% and 96%. These figures are consistent with the performance of our sequential models, which also achieved F1 scores and accuracy scores exceeding 95% in identifying in-bed time. In our study, in-bed time is equated with SPT. All models, with the exception of XGBoost, underestimated SPT. The biLSTM model showed the greatest underestimation, with a bias of -36 minutes, reflecting trends observed in previous research. Winkler et al. developed an algorithm that, despite a strong correlation (Pearson correlation coefficient = .67) between their algorithmic results and diary-recorded waking times, overestimated waking wear time by more than 30 minutes, resulting in an underestimation of in-bed time<span class="citation" data-cites="winkler2016">(<a href="#ref-winkler2016" role="doc-biblioref">Winkler et al. 2016</a>)</span>. This trend was further confirmed when Inan-Eroglu et al.&nbsp;examined Winkler et al.’s algorithm, revealing a underestimation of 9.8 minutes in bed time compared to self-reported measures<span class="citation" data-cites="inan-eroglu2021">(<a href="#ref-inan-eroglu2021" role="doc-biblioref">Inan-Eroglu et al. 2021</a>)</span>. In contrast, a study by van der Berg et al. reported a slight underestimation of in-bed time. They employed a unique approach with their algorithm, which relied on quantifying the number and duration of sedentary periods to determine time in bed, and active periods (standing or stepping) to identify wake times<span class="citation" data-cites="vanderberg2016">(<a href="#ref-vanderberg2016" role="doc-biblioref">Berg et al. 2016</a>)</span>. Finally. it is important to note that high predictive performance in determining in-bed time does not necessarily translate to accurate predictions of broader sleep quality parameters. The crucial task of detecting awake periods during in-bed time, a key factor in assessing sleep quality, may not be effectively captured by in-bed time predictions alone. Indeed, underestimating in-bed time could result in overestimating waking time during in-bed time. Furthermore, the distinction between actual sleep and time spent in bed, often overlooked but vital in sleep research, is critical for a comprehensive understanding of sleep quality.</p>
<p>To the best of our knowledge, Johansson and colleagues<span class="citation" data-cites="johansson_development_2023">(<a href="#ref-johansson_development_2023" role="doc-biblioref">Johansson et al. 2023</a>)</span> are the only researchers who have reported epoch-to-epoch performance metrics for sleep scoring using thigh-worn accelerometers, beyond just “waking time” and “in-bed time.” They achieved a mean sensitivity of 0.84, specificity of 0.55, and accuracy of 0.80, using a single-night evaluation dataset of 71 subjects. Despite our models achieving a sensitivity above 97%, they, like Johansson et al.’s algorithm, struggled with detecting in-bed awake epochs. This is reflected in the low specificity scores, ranging from 54.7% to 76.4%, reported in our study. The challenge of low specificity is not unique to methods using data collected from thigh-worn devices. Conley et al.’s meta-analysis<span class="citation" data-cites="conley2019">(<a href="#ref-conley2019" role="doc-biblioref">Conley et al. 2019</a>)</span> reported similar findings when estimating sleep using wrist-worn accelerometers among healthy adults, with a mean sensitivity, accuracy, and specificity of 0.89, 0.88, and 0.53, respectively. Furthermore, Patterson and colleagues<span class="citation" data-cites="patterson_40_2023">(<a href="#ref-patterson_40_2023" role="doc-biblioref">Patterson et al. 2023</a>)</span> recently summarized the performance of various heuristic algorithms, machine learning, and deep learning models used to predict sleep. They found the mean sensitivity and specificity to be 93% (SD = 2.8) and 60% (SD = 11.1) respectively. These findings underscore the challenge of automating the detection of in-bed awake periods. Interestingly, despite low specificity values for most of our models and configurations, we observed an overestimation of LPS and WASO, contrasting with most previous research<span class="citation" data-cites="conley2019 palotti2019">(<a href="#ref-conley2019" role="doc-biblioref">Conley et al. 2019</a>; <a href="#ref-palotti2019" role="doc-biblioref">Palotti et al. 2019</a>)</span>. This overestimation of wake epochs is evident from the low NPV scores, indicating that only a small proportion of the wake predictions are actually correct. This discrepancy may be driven by the SMOTE process used to balance the dataset. If the synthetic “wake” samples created by SMOTE are not representative of the true “wake” data, the models might learn to incorrectly classify certain “sleep” epochs as “wake”. This could lead to an overestimation of LPS and WASO, as the models are incorrectly identifying more periods of wakefulness during the sleep period.</p>
<p>The use of the SMOTE technique likely improved the performance of our models by addressing the class imbalance in our data. However, this technique also introduced synthetic”wake” samples that may not be fully representative of true wake data. This could potentially lead some models to overestimate the wake class. Interestingly, the biLSTM model, which was not trained on SMOTE-processed data, was the only one to overestimate TST and SE. On the other hand, the XGBoost model, which was trained on data subjected to the SMOTE process, was able to handle the synthetic “wake” samples better than the other models, and it did not overestimate TST to the same degree. The Bland-Altman statistics for the XGBoost model trained on the 5-minute median filtered ZM predictions showed a mean difference of -7 minutes for TST and -1.1% for SE, with limits of agreement ranging from -95.5 to 81.4 minutes and from -15.6% to 13.3% respectively. This suggests that the XGBoost model was able to maintain a balance between sensitivity and specificity, and it was not overly influenced by the synthetic “wake” samples. The XGBoost model’s success with the SMOTE dataset may be due to its ability to handle non-representative synthetic samples. XGBoost’s gradient boosting mechanism allows it to iteratively learn from the errors of previous models, which can help it to better distinguish between true wake data and synthetic wake samples created by SMOTE. This iterative learning process could make XGBoost more robust to the inaccuracies introduced by the synthetic samples, leading to better overall performance.</p>
<p>In our evaluation of sleep quality parameters, we found that Latency to Persistent Sleep (LPS) had the largest mean error relative to absolute time allocated to LPS. This suggests that the initial epochs of Sleep Period Time (SPT) are particularly challenging to classify correctly. This is also supported by the poor Pearson correlations between LPS derived from model predictions and the ZM. The XGBoost model, which was the best performer among all models, overestimated LPS by an average of 26.4 minutes for models trained on raw ZM predictions, 28.5 minutes for models trained on 5-minute filtered ZM predictions, and 34.5 minutes for models trained on 10-minute filtered ZM predictions. This level of discrepancy is comparable to the mean error of sleep latency of 23 minutes reported by Johansson et al.<span class="citation" data-cites="johansson_development_2023">(<a href="#ref-johansson_development_2023" role="doc-biblioref">Johansson et al. 2023</a>)</span>. Johansson et al.&nbsp;suggest that the discrepancy with the gold standard is likely due to the multifaceted nature of the sleep state, which is a complex physiological process. Short awakenings or sleep episodes may not necessarily correspond to noticeable changes in thigh movement, making them difficult to detect and accurately classify. These results align with several methods for wrist-worn devices reviewed by Conley and colleagues<span class="citation" data-cites="conley2019">(<a href="#ref-conley2019" role="doc-biblioref">Conley et al. 2019</a>)</span>. They reported correlations between accelerometer and PSG sleep onset latency (equivalent to LPS) from 10 studies with a mean correlation of 0.2 (ranging from -0.69 to 0.69), indicating the inherent difficulty in estimating this parameter using accelerometry alone.</p>
<p>In this study, we used the ZM as the reference method, rather than PSG, which is considered the gold standard for sleep measurement. This choice may contribute to discrepancies between our models and the ZM, as without a true gold standard, it’s difficult to determine the source of disagreement. However, we believe that the use of ZM, which allows for multiple consecutive nights of recording, is valuable. This approach captures intra-individual variances in sleep, which is impractical with PSG. It also enabled us to include more nights in our study typically compared to those relying on PSG. For instance, the widely used Newcastle dataset<span class="citation" data-cites="hees2015">(<a href="#ref-hees2015" role="doc-biblioref">Hees et al. 2015</a>)</span> only contains data from 28 participants. However, upon examining the ZM outputs, we found that the raw predictions were not optimal for developing machine learning models due to a seemingly low signal-to-noise ratio (see <a href="#fig-zm-median">Figure&nbsp;3</a>). The ZM itself mitigates this issue by applying certain filtering processes when generating sleep quality parameters. For example, epochs contributing to WASO must be in contiguous epochs of 3, and sleep only counts towards sleep quality parameters if 10 out of 12 minutes are scored as sleep. To improve the prospect of our machine learning algorithms, we applied median filters to the ZM raw predictions. This did in fact alter the derived sleep quality parameters. Notably, the mean WASO decreased from 39 minutes in the raw predictions to 30.6 minutes in the 5-minute median filtered predictions, and further decreased to 22.3 minutes in the 10-minute filtered predictions. The application of 5-minute and 10-minute median filters also led to increases in TST, SE, and LPS. This suggests that the filters may categorize some instances of wakefulness as sleep and smooth out brief awakenings. Despite these changes, the overall sleep quality profile derived from the median-filtered predictions is still comparable to that from the raw predictions, justifying our approach.</p>
<p>Our study’s XGBoost model demonstrated relatively narrower limits of agreements (LOAs) for TST, SE, and WASO, with ranges of -95.5 to 81.4 min, -15.6 to 13.3%, and -83.4 to 81.7 min, respectively when compared with other models such as the Van Hees algorithm<span class="citation" data-cites="hees2015">(<a href="#ref-hees2015" role="doc-biblioref">Hees et al. 2015</a>)</span>, Oakley rsc (rescored)<span class="citation" data-cites="palotti2019">(<a href="#ref-palotti2019" role="doc-biblioref">Palotti et al. 2019</a>)</span>, and LSTM-50<span class="citation" data-cites="palotti2019">(<a href="#ref-palotti2019" role="doc-biblioref">Palotti et al. 2019</a>)</span> evaluated in the Patterson et al.&nbsp;study<span class="citation" data-cites="patterson_40_2023">(<a href="#ref-patterson_40_2023" role="doc-biblioref">Patterson et al. 2023</a>)</span>. Furthermore, comparing the LOAs between our XGBoost model and the algorithm developed for thigh-worn devices by Johansson et al.&nbsp;study<span class="citation" data-cites="johansson2022">(<a href="#ref-johansson2022" role="doc-biblioref"><strong>johansson2022?</strong></a>)</span>, our XGBoost model showed narrower LOAs for TST , SE, LPS , and WASO, but not SPT. Generally, all methods, both from this study and from the reviewed literature, exibit wide LOAs sugesting that there is high variability in the derevide sleep quality parameters. These findings imply that the current methods, are only reasonbly reliable for assessing sleep quality parameters at a group level. However, caution should be exercised when applying the models and methods to individual-level sleep assessments. Therefore, further improvements and refinements are needed to enhance the precision and reliability of these models for individual sleep assessments.</p>
<p>Typically, sleep detection methods are applied in two contexts: either to night recordings or to 24-hour recordings. In night recordings, it is often possible to derive sleep quality parameters like SE and LPS because the SPT is already known. This knowledge usually comes either from sleep diaries<span class="citation" data-cites="girschik2012">(<a href="#ref-girschik2012" role="doc-biblioref">Girschik et al. 2012</a>)</span> or from the length of the recording itself. On the other hand, when sleep detection methods are applied to 24-hour recordings, most methods do not have the ability to infer the SPT. Consequently, these methods are unable to generate certain sleep quality parameters that rely on the SPT<span class="citation" data-cites="doherty2017 anderson2014">(<a href="#ref-doherty2017" role="doc-biblioref">Doherty et al. 2017</a>; <a href="#ref-anderson2014" role="doc-biblioref">Anderson et al. 2014</a>)</span>.</p>
<p>Strengths and limitations It is not always clear the methods for detecting sleep from accelerometer data is</p>
<p>It is unclear whether Johansson et al.<span class="citation" data-cites="johansson_development_2023">(<a href="#ref-johansson_development_2023" role="doc-biblioref">Johansson et al. 2023</a>)</span> provide a method for detecting the in-bed time which hinders its applicability for researchers that want to …</p>
<p>external validation dataset/generalization</p>
<p>expand the feature set (Palotti)</p>
<p>In conclusion, our study has advanced the methods for estimating sleep from thigh-worn accelerometers by evaluating various models for predicting in-bed and sleep time. Our results indicate that all sequential models and the multiclass model performed well at predicting in-bed time. However, all models showed difficulty in correctly classifying awake epochs during time in bed, highlighting the challenge of automating the detection of in-bed awake periods. The application of median filters improved the performance metrics of all models, suggesting that this approach may be beneficial in future studies. Despite these promising results, our findings also underscore the need for caution when applying these models to individual-level sleep assessments due to the high variability in derived sleep quality parameters. Future research should focus on refining these models to enhance their precision and reliability for individual sleep assessments.</p>
<p>Our open-source algorithm and the inferred sleep parameters will open the door to future studies on sleep and sleep architecture using large-scale accelerometer databases.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-anderson2014" class="csl-entry" role="listitem">
Anderson, Kirstie N., Michael Catt, Joanna Collerton, Karen Davies, Thomas von Zglinicki, Thomas B. L. Kirkwood, and Carol Jagger. 2014. <span>“Assessment of Sleep and Circadian Rhythm Disorders in the Very Old: The Newcastle 85+ Cohort Study.”</span> <em>Age and Ageing</em> 43 (1): 57–63. <a href="https://doi.org/10.1093/ageing/aft153">https://doi.org/10.1093/ageing/aft153</a>.
</div>
<div id="ref-arvidsson2019" class="csl-entry" role="listitem">
Arvidsson, Daniel, Jonatan Fridolfsson, Mats Börjesson, Lars Bo Andersen, Örjan Ekblom, Magnus Dencker, and Jan Christian Brønd. 2019. <span>“Re-examination of accelerometer data processing and calibration for the assessment of physical activity intensity.”</span> <em>Scandinavian Journal of Medicine &amp; Science in Sports</em> 29 (10): 1442–52. <a href="https://doi.org/10.1111/sms.13470">https://doi.org/10.1111/sms.13470</a>.
</div>
<div id="ref-vanderberg2016" class="csl-entry" role="listitem">
Berg, Julianne D. van der, Paul J. B. Willems, Jeroen H. P. M. van der Velde, Hans H. C. M. Savelberg, Nicolaas C. Schaper, Miranda T. Schram, Simone J. S. Sep, et al. 2016. <span>“Identifying Waking Time in 24-h Accelerometry Data in Adults Using an Automated Algorithm.”</span> <em>Journal of Sports Sciences</em> 34 (19): 1867–73. <a href="https://doi.org/10.1080/02640414.2016.1140908">https://doi.org/10.1080/02640414.2016.1140908</a>.
</div>
<div id="ref-carlson2021" class="csl-entry" role="listitem">
Carlson, Jordan A., Fatima Tuz-Zahra, John Bellettiere, Nicola D. Ridgers, Chelsea Steel, Carolina Bejarano, Andrea Z. LaCroix, et al. 2021. <span>“Validity of Two Awake Wear-Time Classification Algorithms for activPAL in Youth, Adults, and Older Adults.”</span> <em>Journal for the Measurement of Physical Behaviour</em> 4 (2): 151–62. <a href="https://doi.org/10.1123/jmpb.2020-0045">https://doi.org/10.1123/jmpb.2020-0045</a>.
</div>
<div id="ref-chawla2002" class="csl-entry" role="listitem">
Chawla, N. V., K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. 2002. <span>“SMOTE: Synthetic Minority Over-Sampling Technique.”</span> <em>Journal of Artificial Intelligence Research</em> 16 (June): 321–57. <a href="https://doi.org/10.1613/jair.953">https://doi.org/10.1613/jair.953</a>.
</div>
<div id="ref-chen2021" class="csl-entry" role="listitem">
Chen, Zhenghua, Min Wu, Wei Cui, Chengyu Liu, and Xiaoli Li. 2021. <span>“An Attention Based CNN-LSTM Approach for Sleep-Wake Detection With Heterogeneous Sensors.”</span> <em>IEEE journal of biomedical and health informatics</em> 25 (9): 3270–77. <a href="https://doi.org/10.1109/JBHI.2020.3006145">https://doi.org/10.1109/JBHI.2020.3006145</a>.
</div>
<div id="ref-cole1992" class="csl-entry" role="listitem">
Cole, R. J., D. F. Kripke, W. Gruen, D. J. Mullaney, and J. C. Gillin. 1992. <span>“Automatic sleep/wake identification from wrist activity.”</span> <em>Sleep</em> 15 (5): 461–69. <a href="https://doi.org/10.1093/sleep/15.5.461">https://doi.org/10.1093/sleep/15.5.461</a>.
</div>
<div id="ref-conley2019" class="csl-entry" role="listitem">
Conley, Samantha, Andrea Knies, Janene Batten, Garrett Ash, Brienne Miner, Youri Hwang, Sangchoon Jeon, and Nancy S. Redeker. 2019. <span>“Agreement Between Actigraphic and Polysomnographic Measures of Sleep in Adults with and Without Chronic Conditions: A Systematic Review and Meta-Analysis.”</span> <em>Sleep Medicine Reviews</em> 46 (August): 151–60. <a href="https://doi.org/10.1016/j.smrv.2019.05.001">https://doi.org/10.1016/j.smrv.2019.05.001</a>.
</div>
<div id="ref-difrancesco2019" class="csl-entry" role="listitem">
Difrancesco, Sonia, Femke Lamers, Harriëtte Riese, Kathleen R. Merikangas, Aartjan T. F. Beekman, Albert M. van Hemert, Robert A. Schoevers, and Brenda W. J. H. Penninx. 2019. <span>“Sleep, Circadian Rhythm, and Physical Activity Patterns in Depressive and Anxiety Disorders: A 2-Week Ambulatory Assessment Study.”</span> <em>Depression and Anxiety</em> 36 (10): 975–86. <a href="https://doi.org/10.1002/da.22949">https://doi.org/10.1002/da.22949</a>.
</div>
<div id="ref-doherty2017" class="csl-entry" role="listitem">
Doherty, Aiden, Dan Jackson, Nils Hammerla, Thomas Plötz, Patrick Olivier, Malcolm H. Granat, Tom White, et al. 2017. <span>“Large Scale Population Assessment of Physical Activity Using Wrist Worn Accelerometers: The UK Biobank Study.”</span> <em>PLOS ONE</em> 12 (2): e0169649. <a href="https://doi.org/10.1371/journal.pone.0169649">https://doi.org/10.1371/journal.pone.0169649</a>.
</div>
<div id="ref-galland_normal_2012" class="csl-entry" role="listitem">
Galland, Barbara C., Barry J. Taylor, Dawn E. Elder, and Peter Herbison. 2012. <span>“Normal Sleep Patterns in Infants and Children: A Systematic Review of Observational Studies.”</span> <em>Sleep Medicine Reviews</em> 16 (3): 213–22. <a href="https://doi.org/10.1016/j.smrv.2011.06.001">https://doi.org/10.1016/j.smrv.2011.06.001</a>.
</div>
<div id="ref-girschik2012" class="csl-entry" role="listitem">
Girschik, Jennifer, Lin Fritschi, Jane Heyworth, and Flavie Waters. 2012. <span>“Validation of self-reported sleep against actigraphy.”</span> <em>Journal of Epidemiology</em> 22 (5): 462–68. <a href="https://doi.org/10.2188/jea.je20120012">https://doi.org/10.2188/jea.je20120012</a>.
</div>
<div id="ref-hees2015" class="csl-entry" role="listitem">
Hees, Vincent T. van, Séverine Sabia, Kirstie N. Anderson, Sarah J. Denton, James Oliver, Michael Catt, Jessica G. Abell, Mika Kivimäki, Michael I. Trenell, and Archana Singh-Manoux. 2015. <span>“A Novel, Open Access Method to Assess Sleep Duration Using a Wrist-Worn Accelerometer.”</span> <em>PLOS ONE</em> 10 (11): e0142533. <a href="https://doi.org/10.1371/journal.pone.0142533">https://doi.org/10.1371/journal.pone.0142533</a>.
</div>
<div id="ref-hjorth2012" class="csl-entry" role="listitem">
Hjorth, Mads F., Jean-Philippe Chaput, Camilla T. Damsgaard, Stine-Mathilde Dalskov, Kim F. Michaelsen, Inge Tetens, and Anders Sjödin. 2012. <span>“Measure of Sleep and Physical Activity by a Single Accelerometer: Can a Waist-Worn Actigraph Adequately Measure Sleep in Children?”</span> <em>Sleep and Biological Rhythms</em> 10 (4): 328–35. <a href="https://doi.org/10.1111/j.1479-8425.2012.00578.x">https://doi.org/10.1111/j.1479-8425.2012.00578.x</a>.
</div>
<div id="ref-hochreiter1997" class="csl-entry" role="listitem">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Computation</em> 9 (8): 1735–80. <a href="https://doi.org/10.1162/neco.1997.9.8.1735">https://doi.org/10.1162/neco.1997.9.8.1735</a>.
</div>
<div id="ref-themis" class="csl-entry" role="listitem">
Hvitfeldt, Emil. 2023. <em>Themis: Extra Recipes Steps for Dealing with Unbalanced Data</em>. <a href="https://CRAN.R-project.org/package=themis">https://CRAN.R-project.org/package=themis</a>.
</div>
<div id="ref-inan-eroglu2021" class="csl-entry" role="listitem">
Inan-Eroglu, Elif, Bo-Huei Huang, Leah Shepherd, Natalie Pearson, Annemarie Koster, Peter Palm, Peter A. Cistulli, Mark Hamer, and Emmanuel Stamatakis. 2021. <span>“Comparison of a Thigh-Worn Accelerometer Algorithm With Diary Estimates of Time in Bed and Time Asleep: The 1970 British Cohort Study.”</span> <em>Journal for the Measurement of Physical Behaviour</em> 4 (1): 60–67. <a href="https://doi.org/10.1123/jmpb.2020-0033">https://doi.org/10.1123/jmpb.2020-0033</a>.
</div>
<div id="ref-johansson_development_2023" class="csl-entry" role="listitem">
Johansson, Peter J., Patrick Crowley, John Axelsson, Karl Franklin, Anne Helene Garde, Pasan Hettiarachchi, Andreas Holtermann, et al. 2023. <span>“Development and Performance of a Sleep Estimation Algorithm Using a Single Accelerometer Placed on the Thigh: An Evaluation Against Polysomnography.”</span> <em>Journal of Sleep Research</em> 32 (2): e13725. <a href="https://doi.org/10.1111/jsr.13725">https://doi.org/10.1111/jsr.13725</a>.
</div>
<div id="ref-kpavlova2019" class="csl-entry" role="listitem">
K Pavlova, Milena, and Véronique Latreille. 2019. <span>“Sleep Disorders.”</span> <em>The American Journal of Medicine</em> 132 (3): 292–99. <a href="https://doi.org/10.1016/j.amjmed.2018.09.021">https://doi.org/10.1016/j.amjmed.2018.09.021</a>.
</div>
<div id="ref-kaplan2014" class="csl-entry" role="listitem">
Kaplan, Richard F, Ying Wang, Kenneth A Loparo, Monica R Kelly, and Richard R Bootzin. 2014. <span>“Performance Evaluation of an Automated Single-Channel Sleep<span></span>wake Detection Algorithm.”</span> <em>Nature and Science of Sleep</em> 6 (October): 113–22. <a href="https://doi.org/10.2147/NSS.S71159">https://doi.org/10.2147/NSS.S71159</a>.
</div>
<div id="ref-tidymodels" class="csl-entry" role="listitem">
Kuhn, Max, and Hadley Wickham. 2020. <em>Tidymodels: A Collection of Packages for Modeling and Machine Learning Using Tidyverse Principles.</em> <a href="https://www.tidymodels.org">https://www.tidymodels.org</a>.
</div>
<div id="ref-kushida2001" class="csl-entry" role="listitem">
Kushida, C. A., A. Chang, C. Gadkary, C. Guilleminault, O. Carrillo, and W. C. Dement. 2001. <span>“Comparison of actigraphic, polysomnographic, and subjective assessment of sleep parameters in sleep-disordered patients.”</span> <em>Sleep Medicine</em> 2 (5): 389–96. <a href="https://doi.org/10.1016/s1389-9457(00)00098-8">https://doi.org/10.1016/s1389-9457(00)00098-8</a>.
</div>
<div id="ref-lee2022" class="csl-entry" role="listitem">
Lee, Yun Ji, Jae Yong Lee, Jae Hoon Cho, and Ji Ho Choi. 2022. <span>“Interrater reliability of sleep stage scoring: a meta-analysis.”</span> <em>Journal of clinical sleep medicine: JCSM: official publication of the American Academy of Sleep Medicine</em> 18 (1): 193–202. <a href="https://doi.org/10.5664/jcsm.9538">https://doi.org/10.5664/jcsm.9538</a>.
</div>
<div id="ref-ma2017" class="csl-entry" role="listitem">
Ma, Grandner. 2017. <span>“Sleep, Health, and Society.”</span> <em>Sleep Medicine Clinics</em> 12 (1). <a href="https://doi.org/10.1016/j.jsmc.2016.10.012">https://doi.org/10.1016/j.jsmc.2016.10.012</a>.
</div>
<div id="ref-meyer2022" class="csl-entry" role="listitem">
Meyer, Nicholas, Allison G. Harvey, Steven W. Lockley, and Derk-Jan Dijk. 2022. <span>“Circadian Rhythms and Disorders of the Timing of Sleep.”</span> <em>The Lancet</em> 400 (10357): 1061–78. <a href="https://doi.org/10.1016/S0140-6736(22)00877-7">https://doi.org/10.1016/S0140-6736(22)00877-7</a>.
</div>
<div id="ref-moore2015" class="csl-entry" role="listitem">
Moore, Camille M., Sarah J. Schmiege, and Ellyn E. Matthews. 2015. <span>“Actigraphy and Sleep Diary Measurements in Breast Cancer Survivors: Discrepancy in Selected Sleep Parameters.”</span> <em>Behavioral Sleep Medicine</em> 13 (6): 472–90. <a href="https://doi.org/10.1080/15402002.2014.940108">https://doi.org/10.1080/15402002.2014.940108</a>.
</div>
<div id="ref-palotti2019" class="csl-entry" role="listitem">
Palotti, Joao, Raghvendra Mall, Michael Aupetit, Michael Rueschman, Meghna Singh, Aarti Sathyanarayana, Shahrad Taheri, and Luis Fernandez-Luque. 2019. <span>“Benchmark on a Large Cohort for Sleep-Wake Classification with Machine Learning Techniques.”</span> <em>Npj Digital Medicine</em> 2 (1): 1–9. <a href="https://doi.org/10.1038/s41746-019-0126-9">https://doi.org/10.1038/s41746-019-0126-9</a>.
</div>
<div id="ref-NEURIPS2019_9015" class="csl-entry" role="listitem">
Paszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, et al. 2019. <span>“PyTorch: An Imperative Style, High-Performance Deep Learning Library.”</span> In <em>Advances in Neural Information Processing Systems 32</em>, 8024–35. Curran Associates, Inc. <a href="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf">http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</a>.
</div>
<div id="ref-patterson_40_2023" class="csl-entry" role="listitem">
Patterson, Matthew R., Adonay A. S. Nunes, Dawid Gerstel, Rakesh Pilkar, Tyler Guthrie, Ali Neishabouri, and Christine C. Guo. 2023. <span>“40 Years of Actigraphy in Sleep Medicine and Current State of the Art Algorithms.”</span> <em>Npj Digital Medicine</em> 6 (1): 1–7. <a href="https://doi.org/10.1038/s41746-023-00802-1">https://doi.org/10.1038/s41746-023-00802-1</a>.
</div>
<div id="ref-pedersen2021" class="csl-entry" role="listitem">
Pedersen, Jesper, Martin Gillies Banke Rasmussen, Line Grønholt Olesen, Peter Lund Kristensen, and Anders Grøntved. 2021. <span>“Self-Administered Electroencephalography-Based Sleep Assessment: Compliance and Perceived Feasibility in Children and Adults.”</span> <em>Sleep Science and Practice</em> 5 (1): 8. <a href="https://doi.org/10.1186/s41606-021-00059-1">https://doi.org/10.1186/s41606-021-00059-1</a>.
</div>
<div id="ref-R-lang" class="csl-entry" role="listitem">
R Core Team. 2023. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-rasmussen2020" class="csl-entry" role="listitem">
Rasmussen, Martin Gillies Banke, Jesper Pedersen, Line Grønholt Olesen, Søren Brage, Heidi Klakk, Peter Lund Kristensen, Jan Christian Brønd, and Anders Grøntved. 2020. <span>“Short-Term Efficacy of Reducing Screen Media Use on Physical Activity, Sleep, and Physiological Stress in Families with Children Aged 4<span></span>14: Study Protocol for the SCREENS Randomized Controlled Trial.”</span> <em>BMC Public Health</em> 20 (1): 380. <a href="https://doi.org/10.1186/s12889-020-8458-6">https://doi.org/10.1186/s12889-020-8458-6</a>.
</div>
<div id="ref-sadeh1994" class="csl-entry" role="listitem">
Sadeh, A., K. M. Sharkey, and M. A. Carskadon. 1994. <span>“Activity-based sleep-wake identification: an empirical test of methodological issues.”</span> <em>Sleep</em> 17 (3): 201–7. <a href="https://doi.org/10.1093/sleep/17.3.201">https://doi.org/10.1093/sleep/17.3.201</a>.
</div>
<div id="ref-sano2019" class="csl-entry" role="listitem">
Sano, Akane, Weixuan Chen, Daniel Lopez-Martinez, Sara Taylor, and Rosalind W. Picard. 2019. <span>“Multimodal Ambulatory Sleep Detection Using LSTM Recurrent Neural Networks.”</span> <em>IEEE journal of biomedical and health informatics</em> 23 (4): 1607–17. <a href="https://doi.org/10.1109/JBHI.2018.2867619">https://doi.org/10.1109/JBHI.2018.2867619</a>.
</div>
<div id="ref-sazonov2004" class="csl-entry" role="listitem">
Sazonov, Edward, Nadezhda Sazonova, Stephanie Schuckers, Michael Neuman, and CHIME Study Group. 2004. <span>“Activity-based sleep-wake identification in infants.”</span> <em>Physiological Measurement</em> 25 (5): 1291–1304. <a href="https://doi.org/10.1088/0967-3334/25/5/018">https://doi.org/10.1088/0967-3334/25/5/018</a>.
</div>
<div id="ref-skotte_detection_2014" class="csl-entry" role="listitem">
Skotte, Jørgen, Mette Korshøj, Jesper Kristiansen, Christiana Hanisch, and Andreas Holtermann. 2014. <span>“Detection of <span>Physical</span> <span>Activity</span> <span>Types</span> <span>Using</span> <span>Triaxial</span> <span>Accelerometers</span>.”</span> <em>Journal of Physical Activity and Health</em> 11 (1): 76–84. <a href="https://doi.org/10.1123/jpah.2011-0347">https://doi.org/10.1123/jpah.2011-0347</a>.
</div>
<div id="ref-skovgaard2023" class="csl-entry" role="listitem">
Skovgaard, Esben Lykke, Malthe Andreas Roswall, Natascha Holbæk Pedersen, Kristian Traberg Larsen, Anders Grøntved, and Jan Christian Brønd. 2023. <span>“Generalizability and Performance of Methods to Detect Non-Wear with Free-Living Accelerometer Recordings.”</span> <em>Scientific Reports</em> 13 (1): 2496. <a href="https://doi.org/10.1038/s41598-023-29666-x">https://doi.org/10.1038/s41598-023-29666-x</a>.
</div>
<div id="ref-sundararajan2021" class="csl-entry" role="listitem">
Sundararajan, Kalaivani, Sonja Georgievska, Bart H. W. te Lindert, Philip R. Gehrman, Jennifer Ramautar, Diego R. Mazzotti, Séverine Sabia, et al. 2021. <span>“Sleep Classification from Wrist-Worn Accelerometer Data Using Random Forests.”</span> <em>Scientific Reports</em> 11 (1): 24. <a href="https://doi.org/10.1038/s41598-020-79217-x">https://doi.org/10.1038/s41598-020-79217-x</a>.
</div>
<div id="ref-vandewater2011" class="csl-entry" role="listitem">
Van De Water, Alexander T. M., Alison Holmes, and Deirdre A. Hurley. 2011. <span>“Objective Measurements of Sleep for Non-Laboratory Settings as Alternatives to Polysomnography <span></span> a Systematic Review.”</span> <em>Journal of Sleep Research</em> 20 (1pt2): 183–200. <a href="https://doi.org/10.1111/j.1365-2869.2009.00814.x">https://doi.org/10.1111/j.1365-2869.2009.00814.x</a>.
</div>
<div id="ref-10.5555/1593511" class="csl-entry" role="listitem">
Van Rossum, Guido, and Fred L. Drake. 2009. <em>Python 3 Reference Manual</em>. Scotts Valley, CA: CreateSpace.
</div>
<div id="ref-walch2019" class="csl-entry" role="listitem">
Walch, Olivia, Yitong Huang, Daniel Forger, and Cathy Goldstein. 2019. <span>“Sleep Stage Prediction with Raw Acceleration and Photoplethysmography Heart Rate Data Derived from a Consumer Wearable Device.”</span> <em>Sleep</em> 42 (12): zsz180. <a href="https://doi.org/10.1093/sleep/zsz180">https://doi.org/10.1093/sleep/zsz180</a>.
</div>
<div id="ref-wang2015" class="csl-entry" role="listitem">
Wang, Ying, Kenneth A Loparo, Monica R Kelly, and Richard F Kaplan. 2015. <span>“Evaluation of an Automated Single-Channel Sleep Staging Algorithm.”</span> <em>Nature and Science of Sleep</em> 7 (September): 101–11. <a href="https://doi.org/10.2147/NSS.S77888">https://doi.org/10.2147/NSS.S77888</a>.
</div>
<div id="ref-webster1982" class="csl-entry" role="listitem">
Webster, J. B., D. F. Kripke, S. Messin, D. J. Mullaney, and G. Wyborney. 1982. <span>“An activity-based sleep monitor system for ambulatory use.”</span> <em>Sleep</em> 5 (4): 389–99. <a href="https://doi.org/10.1093/sleep/5.4.389">https://doi.org/10.1093/sleep/5.4.389</a>.
</div>
<div id="ref-tidyverse" class="csl-entry" role="listitem">
Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. <span>“Welcome to the <span class="nocase">tidyverse</span>.”</span> <em>Journal of Open Source Software</em> 4 (43): 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div>
<div id="ref-winkler2016" class="csl-entry" role="listitem">
Winkler, Elisabeth A. H., Danielle H. Bodicoat, Genevieve N. Healy, Kishan Bakrania, Thomas Yates, Neville Owen, David W. Dunstan, and Charlotte L. Edwardson. 2016. <span>“Identifying Adults<span>’</span> Valid Waking Wear Time by Automated Estimation in activPAL Data Collected with a 24 h Wear Protocol.”</span> <em>Physiological Measurement</em> 37 (10): 1653. <a href="https://doi.org/10.1088/0967-3334/37/10/1653">https://doi.org/10.1088/0967-3334/37/10/1653</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>