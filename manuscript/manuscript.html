<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Esben Høegholm Lykke">
<meta name="author" content="Jan Christian Brønd">
<meta name="dcterms.date" content="2023-08-02">
<meta name="keywords" content="Sleep, Accelerometry, EEG, Machine learning, Sleep quality">

<title>Improving Sleep Quality Estimation: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="manuscript_files/libs/clipboard/clipboard.min.js"></script>
<script src="manuscript_files/libs/quarto-html/quarto.js"></script>
<script src="manuscript_files/libs/quarto-html/popper.min.js"></script>
<script src="manuscript_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="manuscript_files/libs/quarto-html/anchor.min.js"></script>
<link href="manuscript_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="manuscript_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="manuscript_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="manuscript_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="manuscript_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="manuscript.pdf"><i class="bi bi-file-pdf"></i>PDF (simple-article)</a></li><li><a href="manuscript.pdf"><i class="bi bi-file-pdf"></i>PDF (elsevier)</a></li><li><a href="manuscript.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Improving Sleep Quality Estimation: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Esben Høegholm Lykke </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Southern Denmark
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Jan Christian Brønd </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            University of Southern Denmark
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 2, 2023</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    Studying sleep is vital in health research, but the gold standard, polysomnography, is costly and impractical for large-scale studies. An affordable alternative is using wearable accelerometers. While wrist and hip-worn devices are commonly used in sleep research, thigh-worn accelerometers have been relatively unexplored. Our study evaluated machine learning and deep learning models utilizing data from thigh-worn accelerometers to estimate sleep and sleep quality metrics, comparing them with an EEG-based sleep monitor. The dataset consisted of data from 585 days and nights, comprising accelerometry and EEG-based sleep estimates from children aged 6-10. We employed both sequential and multiclass model strategies on both raw and filtered data. The most effective model was XGBoost, which performed well when applied to 5-minute median filtered data, exhibiting small biases in sleep period time (0.2 minutes), total sleep time (-7 minutes), sleep efficiency (-1.1%), and wake after sleep onset (-0.9 minutes). Furthermore, the XGBoost model showed a robust correlation (0.66, 95% CI: 0.61 - 0.7) with total sleep time, indicating its potential. However, despite these favorable results in bias, our study revealed large limits of agreements in accordance with previous research on hip- and wrist-worn devices. In conclusion, we present promising results in using machine learning technieques to estimate sleep quality metrics, however, accurately classifying awake periods during in-bed time remained challenging. Moreover, additional improvements are necessary to precisely assess individual sleep quality metrics due to the notable limits of agreement.
  </div>
</div>

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>A vast body of research highlights the critical role of sleep in maintaining both mental and physical health<span class="citation" data-cites="ma2017 meyer2022 kpavlova2019 difrancesco2019"><sup><a href="#ref-ma2017" role="doc-biblioref">1</a>–<a href="#ref-difrancesco2019" role="doc-biblioref">4</a></sup></span>. Consequently, accurate sleep assessment methods are crucial for tracking sleep patterns and improving our understanding of the sleep-health relationship. Furthermore, the ease of use and high acceptability of these methods are essential to facilitate large-scale, longitudinal studies.</p>
<p>The traditional gold standard for objective sleep measurement, laboratory-based polysomnography (PSG), has been found to be impractical in large-scale epidemiological studies due to its high cost, need for professional administration, and susceptibility to rater bias<span class="citation" data-cites="vandewater2011 lee2022"><sup><a href="#ref-vandewater2011" role="doc-biblioref">5</a>,<a href="#ref-lee2022" role="doc-biblioref">6</a></sup></span>. As an alternative, diaries have been used due to their cost-effectiveness and simplicity, although they are subject to recall bias and other limitations<span class="citation" data-cites="moore2015"><sup><a href="#ref-moore2015" role="doc-biblioref">7</a></sup></span>. An innovative approach involves device-based measurement methods. These tools, which estimate sleep duration, are advantageous due to their reduced participant burden and elimination of potential recall biases. A prominent example of such tools is body-worn accelerometers, which offer a practical and affordable means of objectively assessing sleep patterns at home for extended periods. Accelerometers collect continuous, high-resolution data for several weeks without requiring recharging, further minimizing participant burden. Their use in sleep and wake classification began with a wrist movement-based algorithm developed in 1982, and validated using PSG<span class="citation" data-cites="webster1982"><sup><a href="#ref-webster1982" role="doc-biblioref">8</a></sup></span>. This algorithm was refined in 1992<span class="citation" data-cites="cole1992"><sup><a href="#ref-cole1992" role="doc-biblioref">9</a></sup></span>, leading to the widely adopted Cole-Kripke model. With advancements in the field, a variety of techniques, including heuristic algorithms, machine learning models, regression, and deep learning, are now used to analyze data from hip and wrist-worn accelerometers<span class="citation" data-cites="palotti2019 cole1992 sazonov2004 sadeh1994 hees2015 sundararajan2021"><sup><a href="#ref-cole1992" role="doc-biblioref">9</a>–<a href="#ref-sundararajan2021" role="doc-biblioref">14</a></sup></span>.</p>
<p>While wrist and hip-worn devices have benefited from extensive methodological development, thigh-worn accelerometers have not seen the same level of advancement. Existing studies mainly focus on distinguishing sleep from wakefulness, with emphasis on defining ‘waking time’ and ‘bedtime’<span class="citation" data-cites="carlson2021 inan-eroglu2021 vanderberg2016 winkler2016"><sup><a href="#ref-carlson2021" role="doc-biblioref">15</a>–<a href="#ref-winkler2016" role="doc-biblioref">18</a></sup></span>. Recent strides in estimating sleep duration using these devices have been made, including the introduction of a promising algorithm and its comparison against PSG<span class="citation" data-cites="johansson_development_2023"><sup><a href="#ref-johansson_development_2023" role="doc-biblioref">19</a></sup></span>. Despite these advancements, the application of machine learning techniques in this area is still unexplored. Considering the potential of thigh-worn accelerometers for accurate physical behavior assessment<span class="citation" data-cites="skotte_detection_2014 arvidsson2019"><sup><a href="#ref-skotte_detection_2014" role="doc-biblioref">20</a>,<a href="#ref-arvidsson2019" role="doc-biblioref">21</a></sup></span>, there is a significant research gap. Therefore, future studies need to develop techniques similar to those used for wrist and hip-worn accelerometers, with the ultimate goal of establishing a more holistic, accurate, and user-friendly method of sleep and physical activity tracking.</p>
<p>The Zmachine®️ Insight+ (ZM) emerges as a valuable tool within this landscape. Favorably validated against PSG<span class="citation" data-cites="kaplan2014 wang2015"><sup><a href="#ref-kaplan2014" role="doc-biblioref">22</a>,<a href="#ref-wang2015" role="doc-biblioref">23</a></sup></span>, the ZM provides comparable data without the high costs or the need for professional monitoring typically associated with PSG. Crucially, the ZM facilitates multi-night analysis in free-living conditions due to its ease of use<span class="citation" data-cites="pedersen2021"><sup><a href="#ref-pedersen2021" role="doc-biblioref">24</a></sup></span>, capturing the natural variations in sleep patterns. This makes it advantageous over single-night PSG, particularly as a gold standard data source in machine learning tasks, as it provides multiple nights of measurements without inter-rater bias. Despite these benefits, the ZM, like PSG, still poses a significant participant burden and cost, reinforcing the need for more accessible alternatives like accelerometers.</p>
<p>Our primary objective in this study was to evaluate a range of machine learning and deep learning models, utilizing the raw data collected from a tri-axial thigh-worn accelerometer to estimate in-bed and sleep time. To ensure the reliability and effectiveness of our models, we compared their outputs with an EEG-based sleep tracking device, which we, in this current study, considered as the gold standard for measuring sleep. Furthermore, our secondary goal was to assess the developed models’ performance in evaluating important sleep quality metrics, including sleep period time (SPT), total sleep time (TST), sleep efficiency (SE), latency until persistent sleep (LPS), and wake after sleep onset (WASO).</p>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<section id="dataset-and-participants" class="level2">
<h2 class="anchored" data-anchor-id="dataset-and-participants">Dataset and participants</h2>
<p>The current study leverages data from the SCREENS project<span class="citation" data-cites="rasmussen2020"><sup><a href="#ref-rasmussen2020" role="doc-biblioref">25</a></sup></span>, a study conducted from October 2018 to March 2019 in Middelfart, Southern Denmark, that evaluated the impact of screen media usage on Danish families. For our analysis, we focused on data from child participants aged between 6 and 10 years within the SCREENS cohort. Our primary sources of data were accelerometer readings from Axivity AX3 devices attached to the children’s thighs, and electroencephalography data derived from the ZM device. The Axivity AX3, an unobtrusive 3-axis accelerometer, was positioned midway between the hip and knee on the right anterior thigh, recording participant movement data.</p>
<p>Sleep state information was extracted using the ZM, a product of General Sleep Corporation. The ZM, which utilizes advanced EEG hardware and signal processing algorithms, employs three self-adhesive, disposable sensors placed outside the hairline for reliable EEG signal acquisition. The participants of the SCREENS study were instructed to attach the device when they went to bed. The ZM uses two proprietary algorithms: Z-ALG and Z-PLUS. The Z-ALG is utilized for accurate sleep detection, showcasing its suitability for in-home monitoring<span class="citation" data-cites="kaplan2014"><sup><a href="#ref-kaplan2014" role="doc-biblioref">22</a></sup></span>, while the Z-PLUS effectively differentiates sleep stages, as evidenced by its alignment with expert evaluations using PSG data<span class="citation" data-cites="wang2015"><sup><a href="#ref-wang2015" role="doc-biblioref">23</a></sup></span>. In the current study, we treated all sleep stages as a single category effectively deducing the output of the ZM to “awake” and “asleep” as the ability to distinguish sleep stages are not a necessity to derive the sleep quality metrics of interest and to simplify the learning process of the models.</p>
<p><a href="#fig-flow">Figure&nbsp;1</a> illustrates the selection criteria applied to the children’s recordings from the SCREENS study. We included only ZM recordings that were accompanied by complete accelerometer data and lasted between 7 and 14 hours. Any night when the ZM reported sensor issues was excluded yielding 585 nights included in the study. The children whose recordings were considered had an average age of 9.4 years, with a standard deviation of 2.1. In their raw form, the ZM predictions encompassed 696,779 epochs, each 30 seconds long. Notably, approximately 84% of the total ZM recording duration was classified as sleep, resulting in an imbalance of the ZM dataset.</p>
<div id="fig-flow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/flowchart_of_elligible_nights.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Flowchart of eligible ZM recording nights included in the study</figcaption>
</figure>
</div>
<p>Finally, we affirm that the SCREENS study received approval from the Regional Scientific Committee of Southern Denmark, and all data handling processes complied with the General Data Protection Regulation (GDPR), ensuring the ethical and secure management of participant information.</p>
</section>
<section id="data-preprocessing-and-feature-extraction" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing-and-feature-extraction">Data Preprocessing and Feature Extraction</h2>
<p>In this study, data processing of the raw accelerometer data began with a low-pass filtration step using a 4th order Butterworth filter with a 5 Hz cut-off frequency to eliminate high-frequency noise. Following filtration, data were partitioned into overlapping 2-second intervals, each successive interval sharing a 50% overlap with the previous one similar to methods described by Skotte et al.<span class="citation" data-cites="skotte_detection_2014"><sup><a href="#ref-skotte_detection_2014" role="doc-biblioref">20</a></sup></span>. Any non-wear data was removed using previously described methods<span class="citation" data-cites="skovgaard2023"><sup><a href="#ref-skovgaard2023" role="doc-biblioref">26</a></sup></span> and data was resampled to 30-second epochs so every sample classified by the algorithms corresponds to a 30-second epoch scored during the ZM recordings. Subsequently, we performed a feature extraction process that yielded a set of 88 features, providing a robust characterization of the data. Extracted from accelerometer and temperature signals, these features include temporal elements that use both lag and lead values, capturing dynamic data trends by incorporating measurements from preceding and upcoming epochs. Furthermore, inspired by Walch et al.<span class="citation" data-cites="walch2019"><sup><a href="#ref-walch2019" role="doc-biblioref">27</a></sup></span>, we incorporated sensor-independent features to encapsulate circadian rhythms. These features offer unique insights not directly discernible from sensor outputs and are meant to approximate the changing drive of the circadian clock to sleep over the course of the night (see <a href="#fig-sensor-independent">Figure&nbsp;2</a>). Furthermore, the feature set was enriched by including signal characteristics, which encompass vector magnitude, mean crossing rate, skewness, and kurtosis for each of the x, y, and z dimensions. Subsequently, we merged the ZM and corresponding accelerometer recordings. Any overlapping time between the ZM and accelerometer data was treated as ‘in-bed’ time, with the remaining time considered ‘out-of-bed’. This process yielded a dataset providing a around the clock temporal view of each participant’s activity and sleep patterns.</p>
<div id="fig-sensor-independent" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/sensor_independent.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Sensor-independent features of circadian rhythms across two consecutive nights. A) cosinus feature, B) linear feature.</figcaption>
</figure>
</div>
<p>In addition to the engineered features, we chose to incorporate the median-filtered raw predictions from the ZM device into our modeling process. This decision stemmed from the understanding that children typically undergo around five to eight sleep cycles per night, with awakenings most likely occurring at the end of each cycle<span class="citation" data-cites="galland_normal_2012"><sup><a href="#ref-galland_normal_2012" role="doc-biblioref">28</a></sup></span>. Upon examining the raw ZM predictions, we noted a significant overestimation in the number of awakenings per night for the children in our study, exceeding what would be expected based on typical sleep cycle patterns (see <a href="#fig-zm-median">Figure&nbsp;3</a>). In particular, many of these brief awakenings could be considered as noise, which when present in the data, can potentially hinder the learning process of machine learning models by obscuring the underlying patterns that the models are trying to learn, leading to less accurate predictions. Consequently, we elected to train and evaluate our models using not only the raw ZM output, but also versions that were subjected to 5-minute and 10-minute median filters. This approach, by mitigating this noise, resulted in an anticipated, more age-appropriate count of awakenings per night, providing a more accurate depiction of children’s sleep patterns (see <a href="#tbl-zm_overview">Table&nbsp;1</a>).</p>
<div id="fig-zm-median" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/zm_raw_vs_filtered.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;3: The difference in number of awakenings between the raw ZM predictions vs.&nbsp;5-minute, and 10-minute median filtered predictions for a random night. Grey line is the raw predictions, black line is the median filtered predictions. A: 5-minute median filter on raw ZM predictions, B: 10-minute median filter on raw ZM predictions.</figcaption>
</figure>
</div>
</section>
<section id="algorithms" class="level2">
<h2 class="anchored" data-anchor-id="algorithms">Algorithms</h2>
<p>We employed two different model strategies to assess sleep patterns from thigh-mounted accelerometer data. The first model strategy was designed as a sequence of two models, each functioning as a binary classifier. This approach aimed to simplify the prediction task by decomposing the multiclass problem of classifying ‘out-of-bed-awake’, ‘in-bed-awake’, and ‘in-bed-asleep’ into two binary stages: first predicting ‘in-bed’ time, then ‘sleep’ time. The output from the first set of binary classifiers, which predicted in-bed time, was subjected to a 5-minute median filter to remove transient in-bed time blips. This process enabled us to establish a single continuous time interval that we identified as the sleep period time window (SPT). The SPT then served as the input for the second stage of binary classifiers in the sequence, further enhancing their predictive accuracy for sleep time.” We applied this sequential strategy using the following four machine learning algorithms:</p>
<ol type="1">
<li><p>Logistic Regression: Logistic regression served as a simple and fast baseline model. However, due to its linear nature, it may struggle with capturing complex relationships and non-linear patterns present in the accelerometer data.</p></li>
<li><p>Decision Tree: Decision trees are capable of handling non-linear patterns and are easily interpretable. However, they are prone to overfitting, particularly when dealing with complex patterns that require simultaneous consideration of multiple features. In the current study, we used a maximum tree depth of 8.</p></li>
<li><p>Single-layer Feed-forward Neural Network: Single-layer feed-forward neural networks can effectively capture non-linear relationships, even with their relatively simple structure. However, they tend to be more challenging to interpret compared to simpler models. Additionally, careful tuning of the network’s architecture and training process is required to mitigate the risk of overfitting.</p></li>
<li><p>XGBoost: XGBoost is a powerful algorithm known for its ability to provide highly accurate predictions and handle complex, non-linear patterns in the data. It also incorporates built-in methods to prevent overfitting. However, training XGBoost models can be computationally intensive, and interpreting the predictions it generates can pose challenges.</p></li>
</ol>
<p>In parallel, we also employed a multiclass algorithm as the second model strategy using a bidirectional Long Short-Term Memory (biLSTM)<span class="citation" data-cites="hochreiter1997"><sup><a href="#ref-hochreiter1997" role="doc-biblioref">29</a></sup></span> neural network which also incorporates temporal aspects of the data. This network, which was designed to predict three distinct classes: ‘out-of-bed-awake’, ‘in-bed-awake’, and ‘in-bed-asleep’, was configured with four layers and 128 hidden units per layer. This balance between model complexity and training efficiency was intended to facilitate learning of intricate patterns while ensuring feasible training times. The bidirectional nature of the LSTM enhanced data interpretation and reduced overfitting by doubling the hidden units at each time step. The LSTM model used sequences of tensors as input, with each sequence spanning 10 minutes and a step size of one. As demonstrated by previous studies such as those by Sano et al.<span class="citation" data-cites="sano2019"><sup><a href="#ref-sano2019" role="doc-biblioref">30</a></sup></span> and Chen et al.<span class="citation" data-cites="chen2021"><sup><a href="#ref-chen2021" role="doc-biblioref">31</a></sup></span>, LSTM models have shown great promise in sleep detection using accelerometer data, thanks to their ability to capture complex temporal patterns.</p>
</section>
<section id="model-training" class="level2">
<h2 class="anchored" data-anchor-id="model-training">Model Training</h2>
<p>We trained four pairs of models in sequence, with each pair distinguishing between in-bed/out-of-bed and asleep/awake states, respectively. We divided our dataset randomly into a training set and a testing set, with each containing roughly half of the subjects. The splitting of the data was ensured to not have samples from the same night simultaneously present in both sets. To optimize hyperparameters, we performed a 10-fold Monte Carlo cross-validation on a regular grid (i.e., for each hyperparameter, a range of values at evenly-spaced intervals was selected) comprising 20 different combinations of hyperparameters. The F1 score served as the optimization metric. The best-performing set of hyperparameters was then used to fit the models to the full training dataset. This approach allowed us to maximize performance by leveraging all available training data to estimate the model parameters. An imbalance was observed with the in-bed time determined in the initial step of the sequential model strategy which after extracting the in-bed time from the initial sequential models, the imbalance on the resulting dataset could cause biases during model training, as models may favor predicting the majority class. To account for this imbalance, we employed the Synthetic Minority Over-sampling Technique (SMOTE)<span class="citation" data-cites="chawla2002"><sup><a href="#ref-chawla2002" role="doc-biblioref">32</a></sup></span>. SMOTE generates new samples by interpolating random samples with their nearest neighbors. We utilized the themis R package<span class="citation" data-cites="themis"><sup><a href="#ref-themis" role="doc-biblioref">33</a></sup></span> to implement SMOTE, resulting in a balanced distribution of training samples across both classes.</p>
<p>The biLSTM model was trained to differentiate between three states: out-of-bed-awake, in-bed-awake, and in-bed-asleep. The data used for training the biLSTM was randomly divided into training, validation, and test sets, based on a 50/25/25 split. We ensured that data from the same night was not present across different sets. The model was trained using the Adam optimizer, selected for its computational efficiency and adaptability of the learning rate during training. Given the multiclass classification task with mutually exclusive classes, we employed the cross-entropy loss function. To obtain a probability distribution over the classes, the softmax activation function was applied at the output layer. We evaluated the model’s performance using the F1 score on both the training and validation sets. We implemented early stopping with a patience of 3 epochs, halting the training process if there was no improvement in the validation loss over three consecutive epochs.</p>
</section>
<section id="model-validation" class="level2">
<h2 class="anchored" data-anchor-id="model-validation">Model Validation</h2>
<p>In our study, we utilized standard evaluation metrics to assess the performance of each model on an epoch-to-epoch basis. These include <span class="math display">\[accuracy = \frac{TP+TN}{TP+TN+FP+FN}\]</span> <span class="math display">\[sensitivity = \frac{TP}{TP+FN}\]</span> <span class="math display">\[specificity = \frac{TN}{TN+FP}\]</span> <span class="math display">\[precision = \frac{TP}{TP+FP}\]</span> <span class="math display">\[NPV = \frac{TN}{TN + FN}\]</span> <span class="math display">\[F_1 = 2 \cdot \frac{precision \cdot sensitivity}{precision + sensitivity}\]</span></p>
<p>where NPV is negative predictive value, TP is true positives, FP is false positives, TN is true negatives, and FN is false negatives.</p>
<p>In the context of our sequential model strategy, the initial models were tasked with the binary classification of in-bed vs.&nbsp;out-of-bed. For this task, we assessed performance using the F1-score, accuracy, sensitivity, specificity, and precision metrics. The second models in our sequential model strategy focused on the binary classification of asleep vs.&nbsp;awake. For these models, we considered the same metrics, in addition to the negative predictive rate. The class imbalance in this case led us to compute the F1 score as an unweighted macro-average. Additionally, we evaluated the multiclass classifier, biLSTM, using the same metrics. To do this, we considered the multiclass output as to binary classifications, where the first was out-of-bed vs the rest and the second binary classification as in-bed-awake vs in-bed-asleep. To further illustrate model performance, we provide confusion matrices for the full dataset, encompassing both in-bed and out-of-bed data. These matrices report relative counts, column percentages (the proportion of the true class accurately predicted), and row percentages (the proportion of predictions correctly classified). We considered both the in-bed/out-of-bed and awake/asleep scoring tasks as binary classification problems, designating in-bed and asleep as the positive labels and out-of-bed and awake as the negative labels in accordance with previous research<span class="citation" data-cites="hjorth2012 kushida2001"><sup><a href="#ref-hjorth2012" role="doc-biblioref">34</a>,<a href="#ref-kushida2001" role="doc-biblioref">35</a></sup></span>.</p>
<p>To assess the performance of our models in deriving sleep quality metrics, we utilized Bland-Altman plots and Pearson correlations. The Bland-Altman method was employed specifically to determine the level of agreement between two measurement techniques. Given the nature of our dataset, which contains multiple observations per subject but necessarily equal number, we employed a bootstrap procedure to account for this added variability. We first calculated the mean difference (bias) and then defined the limits of agreement (LOA) as the mean difference plus or minus 1.96 times the standard deviation of these differences. Acknowledging the possibility of non-normality and potential skewness in our data, we chose to apply a bias-corrected and accelerated (BCa) bootstrap method<span class="citation" data-cites="diciccio_bootstrap_1996"><sup><a href="#ref-diciccio_bootstrap_1996" role="doc-biblioref">36</a></sup></span>. This approach allowed us to better address potential bias in our estimates and the inherent intra-subject variability. Utilizing 10,000 bootstrap replicates, we estimated the 95% confidence intervals for both the bias and the LOA, thus ensuring robustness in our measurements. The sleep quality metrics included are defined as follows in accordance with the ZM definitions:</p>
<ol type="1">
<li><p>Sleep Period Time (SPT) - This refers to the total duration of time in bed with the intention to sleep, which is defined as the time from the start to the end of the ZM recording.</p></li>
<li><p>Total Sleep Time (TST) - This is the time spent asleep within the SPT.</p></li>
<li><p>Sleep Efficiency (SE) - This is the ratio between TST and SPT, representing the proportion of the sleep period that was actually spent asleep.</p></li>
<li><p>Latency Until Persistent Sleep (LPS) - This metric represents the time it takes to transition from wakefulness to sustained sleep. It is calculated as the time from the beginning of the ZM recording until the first period when 10 out of 12 minutes are scored as sleep.</p></li>
<li><p>Wake After Sleep Onset (WASO) - This refers to the time spent awake after initially falling asleep and before the final awakening. In our analysis, a period is counted as ‘awake’ only if it consists of 3 or more contiguous 30-second epochs which is also how the ZM summarizes WASO.</p></li>
</ol>
<p>R version 4.3.0 (2023-04-21)<span class="citation" data-cites="R-lang"><sup><a href="#ref-R-lang" role="doc-biblioref">37</a></sup></span> and the Tidymodels<span class="citation" data-cites="tidymodels"><sup><a href="#ref-tidymodels" role="doc-biblioref">38</a></sup></span> and Tidyverse<span class="citation" data-cites="tidyverse"><sup><a href="#ref-tidyverse" role="doc-biblioref">39</a></sup></span> suite of packages were used as the core tools for model development and analyses. Python version 3.10.6<span class="citation" data-cites="10.5555/1593511"><sup><a href="#ref-10.5555/1593511" role="doc-biblioref">40</a></sup></span> and PyTorch<span class="citation" data-cites="NEURIPS2019_9015"><sup><a href="#ref-NEURIPS2019_9015" role="doc-biblioref">41</a></sup></span> were used to implement the biLSTM model. All code used to perform the analysis and generate the figures in this paper are available in <a href="https://github.com/esbenlykke/sleep_study">this repository</a>.</p>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>As reported in <a href="#tbl-zm_overview">Table&nbsp;1</a> the sleep quality metrics derived from ZM predictions were modified by the implementation of 5-minute and 10-minute median filters. SPT were consistent across raw and filtered datasets (mean: 9.2 ± 2.1 hours), corresponding to the length of the ZM recording. TST and SE increased in the filtered data, implying the filters categorize some wakefulness as sleep. Specifically, TST increased from a raw mean of 7.7 ± 1.9 hours to 8.1 ± 2.0 hours (5-minute filter) and 8.2 ± 2.1 hours (10-minute filter), while SE rose from 82.6 ± 12.0% to 86.4 ± 12.7% and 87.5 ± 12.9% respectively. LPS also increased, suggesting the filter removes brief awakenings at sleep onset, leading to a prolonged time to persistent sleep. A change was seen in WASO, which dropped from 39.0 ± 33.6 minutes in raw data to 30.6 ± 46.8 minutes and 22.3 ± 55.4 minutes in the 5-minute and 10-minute filtered data, respectively. The number of awakenings was also considerably reduced with the application of filters. In the raw data, the average number of awakenings was 34.46 ± 11.33 per night, which reduced to 4.43 ± 3.26 and 1.95 ± 2.01 for the 5-minute and 10-minute filtered data sets respectively.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-zm_overview" class="anchored">

<div id="zecebgevke" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#zecebgevke table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#zecebgevke thead, #zecebgevke tbody, #zecebgevke tfoot, #zecebgevke tr, #zecebgevke td, #zecebgevke th {
  border-style: none;
}

#zecebgevke p {
  margin: 0;
  padding: 0;
}

#zecebgevke .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#zecebgevke .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#zecebgevke .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#zecebgevke .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#zecebgevke .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#zecebgevke .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zecebgevke .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#zecebgevke .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#zecebgevke .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#zecebgevke .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#zecebgevke .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#zecebgevke .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#zecebgevke .gt_spanner_row {
  border-bottom-style: hidden;
}

#zecebgevke .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#zecebgevke .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#zecebgevke .gt_from_md > :first-child {
  margin-top: 0;
}

#zecebgevke .gt_from_md > :last-child {
  margin-bottom: 0;
}

#zecebgevke .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#zecebgevke .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#zecebgevke .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#zecebgevke .gt_row_group_first td {
  border-top-width: 2px;
}

#zecebgevke .gt_row_group_first th {
  border-top-width: 2px;
}

#zecebgevke .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#zecebgevke .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#zecebgevke .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#zecebgevke .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zecebgevke .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#zecebgevke .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#zecebgevke .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#zecebgevke .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#zecebgevke .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zecebgevke .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#zecebgevke .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#zecebgevke .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#zecebgevke .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#zecebgevke .gt_left {
  text-align: left;
}

#zecebgevke .gt_center {
  text-align: center;
}

#zecebgevke .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#zecebgevke .gt_font_normal {
  font-weight: normal;
}

#zecebgevke .gt_font_bold {
  font-weight: bold;
}

#zecebgevke .gt_font_italic {
  font-style: italic;
}

#zecebgevke .gt_super {
  font-size: 65%;
}

#zecebgevke .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#zecebgevke .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#zecebgevke .gt_indent_1 {
  text-indent: 5px;
}

#zecebgevke .gt_indent_2 {
  text-indent: 10px;
}

#zecebgevke .gt_indent_3 {
  text-indent: 15px;
}

#zecebgevke .gt_indent_4 {
  text-indent: 20px;
}

#zecebgevke .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;1:  <p>Overview of characteristics of the ZM sleep quality summaries per
night. Values are represented as mean (SD).</p> </caption>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="SPT (hrs)">SPT (hrs)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="TST (hrs)">TST (hrs)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="SE (%)">SE (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="LPS (min)">LPS (min)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="WASO (min)">WASO (min)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Awakenings (N)">Awakenings (N)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="name" class="gt_row gt_left">Raw ZM Predictions</td>
<td headers="spt" class="gt_row gt_right">9.2 (2.1)</td>
<td headers="tst" class="gt_row gt_right">7.7 (1.9)</td>
<td headers="se" class="gt_row gt_right">82.6 (12)</td>
<td headers="lps" class="gt_row gt_right">34.5 (27.9)</td>
<td headers="waso" class="gt_row gt_right">39 (33.6)</td>
<td headers="no" class="gt_row gt_right">34.5 (11.3)</td></tr>
    <tr><td headers="name" class="gt_row gt_left">5-Min Median</td>
<td headers="spt" class="gt_row gt_right">9.2 (2.1)</td>
<td headers="tst" class="gt_row gt_right">8.1 (2)</td>
<td headers="se" class="gt_row gt_right">86.4 (12.7)</td>
<td headers="lps" class="gt_row gt_right">36.3 (39.8)</td>
<td headers="waso" class="gt_row gt_right">30.6 (46.8)</td>
<td headers="no" class="gt_row gt_right">4.4 (3.3)</td></tr>
    <tr><td headers="name" class="gt_row gt_left">10-Min Median</td>
<td headers="spt" class="gt_row gt_right">9.2 (2.1)</td>
<td headers="tst" class="gt_row gt_right">8.2 (2.1)</td>
<td headers="se" class="gt_row gt_right">87.5 (12.9)</td>
<td headers="lps" class="gt_row gt_right">38 (48.7)</td>
<td headers="waso" class="gt_row gt_right">22.3 (55.4)</td>
<td headers="no" class="gt_row gt_right">1.9 (2)</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<section id="performance-on-epoch-to-epoch-basis" class="level2">
<h2 class="anchored" data-anchor-id="performance-on-epoch-to-epoch-basis">Performance on Epoch-to-Epoch Basis</h2>
<p>The epoch-to-epoch evaluation of predicting in-bed time is outlined in <a href="#tbl-in_bed_performance">Table&nbsp;2</a>, and demonstrates practically equivalent performance across all model types. The F1 score ranges from 94.4% (Decision Tree) to 95.4% (XGBoost), while accuracy ranges from 95.3% (Decision Tree) to 96.1% (XGBoost). Sensitivity, Precision, and Specificity also demonstrate consistent results across the different models. The XGBoost model provide the best performance with an F1 score of 95.4% and accuracy of 96.1%, although only outpacing the other models marginally.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-in_bed_performance" class="anchored">

<div id="kurcsclfbq" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#kurcsclfbq table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#kurcsclfbq thead, #kurcsclfbq tbody, #kurcsclfbq tfoot, #kurcsclfbq tr, #kurcsclfbq td, #kurcsclfbq th {
  border-style: none;
}

#kurcsclfbq p {
  margin: 0;
  padding: 0;
}

#kurcsclfbq .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#kurcsclfbq .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#kurcsclfbq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#kurcsclfbq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#kurcsclfbq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#kurcsclfbq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#kurcsclfbq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#kurcsclfbq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#kurcsclfbq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#kurcsclfbq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#kurcsclfbq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#kurcsclfbq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#kurcsclfbq .gt_spanner_row {
  border-bottom-style: hidden;
}

#kurcsclfbq .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#kurcsclfbq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#kurcsclfbq .gt_from_md > :first-child {
  margin-top: 0;
}

#kurcsclfbq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#kurcsclfbq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#kurcsclfbq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#kurcsclfbq .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#kurcsclfbq .gt_row_group_first td {
  border-top-width: 2px;
}

#kurcsclfbq .gt_row_group_first th {
  border-top-width: 2px;
}

#kurcsclfbq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#kurcsclfbq .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#kurcsclfbq .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#kurcsclfbq .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#kurcsclfbq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#kurcsclfbq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#kurcsclfbq .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#kurcsclfbq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#kurcsclfbq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#kurcsclfbq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#kurcsclfbq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#kurcsclfbq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#kurcsclfbq .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#kurcsclfbq .gt_left {
  text-align: left;
}

#kurcsclfbq .gt_center {
  text-align: center;
}

#kurcsclfbq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#kurcsclfbq .gt_font_normal {
  font-weight: normal;
}

#kurcsclfbq .gt_font_bold {
  font-weight: bold;
}

#kurcsclfbq .gt_font_italic {
  font-style: italic;
}

#kurcsclfbq .gt_super {
  font-size: 65%;
}

#kurcsclfbq .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#kurcsclfbq .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#kurcsclfbq .gt_indent_1 {
  text-indent: 5px;
}

#kurcsclfbq .gt_indent_2 {
  text-indent: 10px;
}

#kurcsclfbq .gt_indent_3 {
  text-indent: 15px;
}

#kurcsclfbq .gt_indent_4 {
  text-indent: 20px;
}

#kurcsclfbq .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;2:  <p>Performance metrics of the classification of in-bed/out-of-bed time
of the included models.</p> </caption>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="F1 Score (%)">F1 Score (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Accuracy (%)">Accuracy (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Sensitivity (%)">Sensitivity (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Precision (%)">Precision (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Specificity (%)">Specificity (%)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="model" class="gt_row gt_left">Decision Tree</td>
<td headers="F1 Score (%)" class="gt_row gt_right">94.4</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.3</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">93.1</td>
<td headers="Precision (%)" class="gt_row gt_right">95.6</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.9</td></tr>
    <tr><td headers="model" class="gt_row gt_left">Logistic Regression</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.0</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.7</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.0</td>
<td headers="Precision (%)" class="gt_row gt_right">94.9</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.3</td></tr>
    <tr><td headers="model" class="gt_row gt_left">Feed-Forward Neural Net</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.0</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.8</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.1</td>
<td headers="Precision (%)" class="gt_row gt_right">95.0</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.3</td></tr>
    <tr><td headers="model" class="gt_row gt_left">XGBoost</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.4</td>
<td headers="Accuracy (%)" class="gt_row gt_right">96.1</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.8</td>
<td headers="Precision (%)" class="gt_row gt_right">94.9</td>
<td headers="Specificity (%)" class="gt_row gt_right">96.2</td></tr>
    <tr><td headers="model" class="gt_row gt_left">biLSTM</td>
<td headers="F1 Score (%)" class="gt_row gt_right">95.2</td>
<td headers="Accuracy (%)" class="gt_row gt_right">95.3</td>
<td headers="Sensitivity (%)" class="gt_row gt_right">95.3</td>
<td headers="Precision (%)" class="gt_row gt_right">95.1</td>
<td headers="Specificity (%)" class="gt_row gt_right">95.3</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p><a href="#tbl-sleep_performance">Table&nbsp;3</a> details the performance of all sequential model types on raw and median-filtered (5 and 10 minute) ZM predictions for sleep/wake classification. For raw ZM predictions, the F1 scores, which are unweighted macro averages, range from 65.6% (biLSTM) to 76.2% (XGBoost). All models perform comparably, but the low specificity values (62.5% to 70.9%) suggest difficulty in correctly classifying awake epochs. Applying a 5-minute median filter improves the performance metrics. The XGBoost model tops the charts with an F1 score of 79.2% and NPV of 74.0%. However, specificity still remains low, with values between 54.7% (XGBoost) and 74.8% (Logistic Regression) across all models. With a 10-minute median filter, the metrics improve further. The XGBoost model still leads with an F1 score of 80.9% and an NPV of 75.9%. But, specificity remains low, ranging from 57.5% (Decision Tree) to 76.4% (Logistic Regression) across all models.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-sleep_performance" class="anchored">

<div id="xpidezlknz" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>@import url("https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
@import url("https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap");
#xpidezlknz table {
  font-family: Montserrat, 'Noto Sans', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji', ibm;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#xpidezlknz thead, #xpidezlknz tbody, #xpidezlknz tfoot, #xpidezlknz tr, #xpidezlknz td, #xpidezlknz th {
  border-style: none;
}

#xpidezlknz p {
  margin: 0;
  padding: 0;
}

#xpidezlknz .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 12px;
  font-weight: normal;
  font-style: normal;
  background-color: #F6F6F6;
  width: auto;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #40C5FF;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 3px;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#xpidezlknz .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#xpidezlknz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #F6F6F6;
  border-bottom-width: 0;
}

#xpidezlknz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #F6F6F6;
  border-top-width: 0;
}

#xpidezlknz .gt_heading {
  background-color: #F6F6F6;
  text-align: left;
  border-bottom-color: #F6F6F6;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#xpidezlknz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 0px;
  border-bottom-color: #D3D3D3;
}

#xpidezlknz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #40C5FF;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #ECECEC;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#xpidezlknz .gt_col_heading {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#xpidezlknz .gt_column_spanner_outer {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#xpidezlknz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#xpidezlknz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#xpidezlknz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #ECECEC;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#xpidezlknz .gt_spanner_row {
  border-bottom-style: hidden;
}

#xpidezlknz .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #BEBEBE;
  border-bottom-style: solid;
  border-bottom-width: 1px;
  border-bottom-color: #BEBEBE;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#xpidezlknz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: bold;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #BEBEBE;
  border-bottom-style: solid;
  border-bottom-width: 1px;
  border-bottom-color: #BEBEBE;
  vertical-align: middle;
}

#xpidezlknz .gt_from_md > :first-child {
  margin-top: 0;
}

#xpidezlknz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#xpidezlknz .gt_row {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: white;
  border-top-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#xpidezlknz .gt_stub {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#xpidezlknz .gt_stub_row_group {
  color: #333333;
  background-color: #F6F6F6;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#xpidezlknz .gt_row_group_first td {
  border-top-width: 1px;
}

#xpidezlknz .gt_row_group_first th {
  border-top-width: 1px;
}

#xpidezlknz .gt_summary_row {
  color: #333333;
  background-color: #F6F6F6;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#xpidezlknz .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#xpidezlknz .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#xpidezlknz .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#xpidezlknz .gt_grand_summary_row {
  color: #333333;
  background-color: #F6F6F6;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#xpidezlknz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#xpidezlknz .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#xpidezlknz .gt_striped {
  background-color: #ECECEC;
}

#xpidezlknz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 3px;
  border-bottom-color: #FFFFFF;
}

#xpidezlknz .gt_footnotes {
  color: #333333;
  background-color: #F6F6F6;
  border-bottom-style: none;
  border-bottom-width: 0px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#xpidezlknz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#xpidezlknz .gt_sourcenotes {
  color: #333333;
  background-color: #F6F6F6;
  border-bottom-style: none;
  border-bottom-width: 0px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#xpidezlknz .gt_sourcenote {
  font-size: 12px;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#xpidezlknz .gt_left {
  text-align: left;
}

#xpidezlknz .gt_center {
  text-align: center;
}

#xpidezlknz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#xpidezlknz .gt_font_normal {
  font-weight: normal;
}

#xpidezlknz .gt_font_bold {
  font-weight: bold;
}

#xpidezlknz .gt_font_italic {
  font-style: italic;
}

#xpidezlknz .gt_super {
  font-size: 65%;
}

#xpidezlknz .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#xpidezlknz .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#xpidezlknz .gt_indent_1 {
  text-indent: 5px;
}

#xpidezlknz .gt_indent_2 {
  text-indent: 10px;
}

#xpidezlknz .gt_indent_3 {
  text-indent: 15px;
}

#xpidezlknz .gt_indent_4 {
  text-indent: 20px;
}

#xpidezlknz .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" style="table-layout: fixed;; width: 0px" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;3:  <p>Performance metrics of the sleep/wake classification of the included
models.</p> </caption>
  <colgroup>
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
    <col style="width:140px;">
  </colgroup>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="F1 Score (%)">F1 Score (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Precision (%)">Precision (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="NPV (%)">NPV (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Sensitivity (%)">Sensitivity (%)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Specificity (%)">Specificity (%)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr class="gt_group_heading_row">
      <th colspan="6" class="gt_group_heading" scope="colgroup" id="Raw ZM Predictions">Raw ZM Predictions</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="Raw ZM Predictions  model" class="gt_row gt_left" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">Decision Tree</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">72.9</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">93.2</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">48.4</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">86.3</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right" style="border-top-width: 0px; border-top-style: solid; border-top-color: white;">67.1</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left gt_striped">Logistic Regression</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right gt_striped">71.0</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right gt_striped">93.7</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right gt_striped">43.9</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right gt_striped">82.7</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right gt_striped">70.9</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left">Neural Network</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right">71.8</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right">93.8</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right">45.1</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right">83.6</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right">70.8</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left gt_striped">XGBoost</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right gt_striped">76.2</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right gt_striped">92.8</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right gt_striped">58.0</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right gt_striped">91.3</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right gt_striped">62.8</td></tr>
    <tr><td headers="Raw ZM Predictions  model" class="gt_row gt_left">biLSTM</td>
<td headers="Raw ZM Predictions  F1 Score (%)" class="gt_row gt_right">65.6</td>
<td headers="Raw ZM Predictions  Precision (%)" class="gt_row gt_right">80.6</td>
<td headers="Raw ZM Predictions  NPV (%)" class="gt_row gt_right">80.6</td>
<td headers="Raw ZM Predictions  Sensitivity (%)" class="gt_row gt_right">62.5</td>
<td headers="Raw ZM Predictions  Specificity (%)" class="gt_row gt_right">62.5</td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="6" class="gt_group_heading" scope="colgroup" id="5-Min Median">5-Min Median</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median  model" class="gt_row gt_left gt_striped">Decision Tree</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">75.5</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right gt_striped">94.2</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right gt_striped">55.5</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">93.4</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">59.0</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left">Logistic Regression</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right">68.3</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right">95.8</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right">36.0</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right">81.4</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right">74.8</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left gt_striped">Neural Network</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">71.7</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right gt_striped">95.8</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right gt_striped">41.6</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">85.6</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">73.1</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left">XGBoost</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right">79.2</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right">93.9</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right">74.0</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right">97.3</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right">54.7</td></tr>
    <tr><td headers="5-Min Median  model" class="gt_row gt_left gt_striped">biLSTM</td>
<td headers="5-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">70.3</td>
<td headers="5-Min Median  Precision (%)" class="gt_row gt_right gt_striped">84.6</td>
<td headers="5-Min Median  NPV (%)" class="gt_row gt_right gt_striped">84.6</td>
<td headers="5-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">66.2</td>
<td headers="5-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">66.2</td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="6" class="gt_group_heading" scope="colgroup" id="10-Min Median">10-Min Median</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="10-Min Median  model" class="gt_row gt_left">Decision Tree</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right">76.3</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right">94.7</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right">58.1</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right">94.9</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right">57.5</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left gt_striped">Logistic Regression</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">68.0</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right gt_striped">96.5</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right gt_striped">34.3</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">81.9</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">76.4</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left">Neural Network</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right">71.0</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right">96.1</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right">39.5</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right">86.5</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right">71.4</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left gt_striped">XGBoost</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right gt_striped">80.9</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right gt_striped">94.9</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right gt_striped">75.8</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right gt_striped">97.7</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right gt_striped">57.6</td></tr>
    <tr><td headers="10-Min Median  model" class="gt_row gt_left">biLSTM</td>
<td headers="10-Min Median  F1 Score (%)" class="gt_row gt_right">70.9</td>
<td headers="10-Min Median  Precision (%)" class="gt_row gt_right">75.1</td>
<td headers="10-Min Median  NPV (%)" class="gt_row gt_right">75.1</td>
<td headers="10-Min Median  Sensitivity (%)" class="gt_row gt_right">68.5</td>
<td headers="10-Min Median  Specificity (%)" class="gt_row gt_right">68.5</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p>A complete set of confusion matrices generated from data both containing the out-of-bed and in-bed time are presented in <a href="#fig-conf_mat">Figure&nbsp;4</a>. These matrices showcase the epoch-to-epoch performance of all sequential models in distinguishing between ‘awake’ and ‘asleep’ states, regardless of whether the subject is ‘in-bed’ or ‘out-of-bed’. However, it’s important to note that the binary nature of these sequential models means they cannot provide direct information about the classification of the ‘in-bed-awake’ state. In contrast, the biLSTM model, which also categorizes the ‘in-bed-awake’ state as a distinct class, appears to have less success in classifying this particular state.</p>
<div id="fig-conf_mat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/all_conf_mats.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Confusion matrices for binary sleep prediction. The middle of each tile is the normalized count (overall percentage). The bottom number of each tile is the column percentage and the right side of each tile is the row percentage. i) decision tree, ii) logistic regression, iii) feed-forward neural net, iv) XGBoost, and v) biLSTM.</figcaption>
</figure>
</div>
</section>
<section id="evaluation-of-sleep-quality-metrics" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-of-sleep-quality-metrics">Evaluation of sleep quality metrics</h2>
<p><a href="#tbl-ba_cor">Table&nbsp;4</a> presents a comparative analysis of the included models used to predict various sleep quality metrics (SPT, TST, SE, LPS, WASO) using the 5-minute median filtered ZM predictions. To see the full table including models developed from raw ZM predictions and 10-minute median filtered ZM predictions, see table 1 in supplementary materials. In terms of bias, the decision tree model consistently underestimated SPT, TST, and SE, and overestimated LPS and WASO in comparison to ZM. The logistic regression model had similar trends, with more pronounced underestimation in TST and overestimation in LPS. The feed-forward neural network also exhibited similar bias as the decision tree and the logistic regression models, but with a higher overestimation in WASO. On the other hand, the XGBoost model showed least bias among all, especially in its 5-minute median predictions. Considering LOA, the decision tree had higher variability across different sleep quality metrics and filtering techniques, particularly for LPS and WASO, which indicates lower agreement with ZM. Other models had comparable LOA but with notable exceptions. For example, TST LOA for the logistic regression model was particularly wide in the 5-minute median predictions. Correlation-wise, the pearson coefficient, revealed that the XGBoost model consistently had the highest correlation with ZM across all sleep quality metrics and filtering methods Notably, the XGBoost’s 5-minute median predictions showed the strongest correlation (0.66) for TST among all models and filtering techniques.</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-ba_cor" class="anchored">

<div id="yapmakberq" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#yapmakberq table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#yapmakberq thead, #yapmakberq tbody, #yapmakberq tfoot, #yapmakberq tr, #yapmakberq td, #yapmakberq th {
  border-style: none;
}

#yapmakberq p {
  margin: 0;
  padding: 0;
}

#yapmakberq .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#yapmakberq .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#yapmakberq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#yapmakberq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#yapmakberq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#yapmakberq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#yapmakberq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#yapmakberq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#yapmakberq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#yapmakberq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#yapmakberq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#yapmakberq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#yapmakberq .gt_spanner_row {
  border-bottom-style: hidden;
}

#yapmakberq .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#yapmakberq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#yapmakberq .gt_from_md > :first-child {
  margin-top: 0;
}

#yapmakberq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#yapmakberq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#yapmakberq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#yapmakberq .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#yapmakberq .gt_row_group_first td {
  border-top-width: 2px;
}

#yapmakberq .gt_row_group_first th {
  border-top-width: 2px;
}

#yapmakberq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#yapmakberq .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#yapmakberq .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#yapmakberq .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#yapmakberq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#yapmakberq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#yapmakberq .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#yapmakberq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#yapmakberq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#yapmakberq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#yapmakberq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#yapmakberq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#yapmakberq .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#yapmakberq .gt_left {
  text-align: left;
}

#yapmakberq .gt_center {
  text-align: center;
}

#yapmakberq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#yapmakberq .gt_font_normal {
  font-weight: normal;
}

#yapmakberq .gt_font_bold {
  font-weight: bold;
}

#yapmakberq .gt_font_italic {
  font-style: italic;
}

#yapmakberq .gt_super {
  font-size: 65%;
}

#yapmakberq .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#yapmakberq .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#yapmakberq .gt_indent_1 {
  text-indent: 5px;
}

#yapmakberq .gt_indent_2 {
  text-indent: 10px;
}

#yapmakberq .gt_indent_3 {
  text-indent: 15px;
}

#yapmakberq .gt_indent_4 {
  text-indent: 20px;
}

#yapmakberq .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" style="table-layout: fixed;" data-quarto-disable-processing="false" data-quarto-bootstrap="false"><caption>Table&nbsp;4:  <p>Summary of bias, limits of agreement, and pearson correlation for
various sleep parameter predictions (SPT, TST,SE, LPS, WASO) using
different machine learning and deep learning models (decision tree,
logistic regression, feed-forward neural network, XGBoost) on raw ZM
predictions, 5-minute and 10-minute median predictions. Each value is
provided with its 95% confidence interval (CI).</p> </caption>
  <colgroup>
    <col style="width:200px;">
    <col>
    <col>
    <col>
    <col>
  </colgroup>
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id=""></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Bias (95% CI)">Bias (95% CI)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Lower LOA (95% CI)">Lower LOA (95% CI)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Upper LOA (95% CI)">Upper LOA (95% CI)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" scope="col" id="Pearson, <em>r</em> (95% CI)">Pearson, <em>r</em> (95% CI)</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - Decision Tree">5-Min Median - Decision Tree</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">-21.6 (-25.6;-17.6)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-117.5 (-125.6;-110.7)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">74.2 (63.9;85.9)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.54 (0.48;0.6)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">-50.5 (-55.2;-46)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-161.4 (-175.8;-151.3)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">60.4 (51.5;71.7)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.48 (0.42;0.54)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">-5.5 (-6.3;-4.7)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-23.9 (-26.4;-22.2)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">12.9 (11.6;14.6)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.22 (0.14;0.29)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">24.6 (19.7;29.1)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-88.8 (-115;-77.3)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">138 (126.2;156.7)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.06 (-0.02;0.14)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Decision Tree  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - Decision Tree  bias" class="gt_row gt_right">9.9 (6.5;14)</td>
<td headers="5-Min Median - Decision Tree  lower_loa" class="gt_row gt_right">-79.4 (-109;-63.1)</td>
<td headers="5-Min Median - Decision Tree  upper_loa" class="gt_row gt_right">99.2 (80;136.1)</td>
<td headers="5-Min Median - Decision Tree  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.15 (0.07;0.22)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - Logistic Regression">5-Min Median - Logistic Regression</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">-3.7 (-8;1)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-112.2 (-120.9;-105.2)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">104.8 (94;117.4)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.38 (0.3;0.44)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">-139.7 (-146.9;-133)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-305.6 (-323.6;-291.8)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">26.2 (16.1;38.6)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.09 (0.01;0.17)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">-23.2 (-24.3;-22.2)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-48.1 (-50.9;-46.1)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">1.7 (0.1;3.8)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.13 (0.05;0.21)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">58.1 (53.4;62.6)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-52.3 (-75;-40.1)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">168.6 (155.9;187.7)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.05 (-0.03;0.13)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Logistic Regression  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - Logistic Regression  bias" class="gt_row gt_right">45.4 (41.7;49.7)</td>
<td headers="5-Min Median - Logistic Regression  lower_loa" class="gt_row gt_right">-50.7 (-74.4;-38.4)</td>
<td headers="5-Min Median - Logistic Regression  upper_loa" class="gt_row gt_right">141.5 (126.8;173)</td>
<td headers="5-Min Median - Logistic Regression  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.19 (0.11;0.27)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - Feed-Forward Neural Net">5-Min Median - Feed-Forward Neural Net</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">-3.9 (-8.1;0.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-112.7 (-122;-105.2)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">104.9 (94.1;118.4)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.38 (0.3;0.44)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">-126.5 (-132.8;-120.3)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-276.8 (-291.3;-264.7)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">23.9 (14.8;33.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.25 (0.17;0.32)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">-20.9 (-21.9;-19.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-44.3 (-46.3;-42.5)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">2.5 (1.1;4)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.21 (0.13;0.29)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">35.3 (30.7;39.8)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-75.8 (-102.3;-63.4)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">146.5 (134.4;166.9)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.07 (-0.01;0.15)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - Feed-Forward Neural Net  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  bias" class="gt_row gt_right">45 (41.2;49.2)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  lower_loa" class="gt_row gt_right">-51.8 (-76.4;-39.1)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  upper_loa" class="gt_row gt_right">141.7 (125.8;174.1)</td>
<td headers="5-Min Median - Feed-Forward Neural Net  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.21 (0.14;0.29)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - XGboost">5-Min Median - XGboost</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">0.2 (-3.7;4.5)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-97.4 (-106.2;-90.3)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">97.8 (86.6;111)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.56 (0.5;0.61)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">-7 (-10.8;-3.3)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-95.5 (-105.2;-88)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">81.4 (72.4;92.5)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.66 (0.61;0.7)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">-1.1 (-1.7;-0.5)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-15.6 (-17;-14.4)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">13.3 (12.2;14.7)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.44 (0.38;0.51)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">28.5 (23.9;32.6)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-76.4 (-104.2;-63.3)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">133.4 (120.4;154.2)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.12 (0.04;0.2)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - XGboost  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - XGboost  bias" class="gt_row gt_right">-0.9 (-3.9;3)</td>
<td headers="5-Min Median - XGboost  lower_loa" class="gt_row gt_right">-83.4 (-113.1;-66)</td>
<td headers="5-Min Median - XGboost  upper_loa" class="gt_row gt_right">81.7 (62;119.6)</td>
<td headers="5-Min Median - XGboost  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.26 (0.18;0.33)</p>
</div></td></tr>
    <tr class="gt_group_heading_row">
      <th colspan="5" class="gt_group_heading" scope="colgroup" id="5-Min Median - biLSTM">5-Min Median - biLSTM</th>
    </tr>
    <tr class="gt_row_group_first"><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">SPT (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">-36.1 (-41.7;-30)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-136.1 (-146.3;-126.9)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">64 (51.1;78.6)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.54 (0.45;0.62)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">TST (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">12.8 (7.4;18.3)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-80.1 (-89.8;-72.3)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">105.8 (94.3;118.8)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.63 (0.55;0.69)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">SE (%)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">8 (7.2;8.8)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-5.1 (-6.8;-3.8)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">21.1 (19.5;23.1)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.16 (0.04;0.27)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">LPS (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">-15.7 (-25.9;-7.5)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-169 (-230.7;-127.9)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">137.6 (101.1;184.9)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.09 (-0.02;0.2)</p>
</div></td></tr>
    <tr><td headers="5-Min Median - biLSTM  variable" class="gt_row gt_left">WASO (min)</td>
<td headers="5-Min Median - biLSTM  bias" class="gt_row gt_right">-3 (-9.9;7.7)</td>
<td headers="5-Min Median - biLSTM  lower_loa" class="gt_row gt_right">-144.1 (-197.2;-107.2)</td>
<td headers="5-Min Median - biLSTM  upper_loa" class="gt_row gt_right">138.1 (90.8;211.4)</td>
<td headers="5-Min Median - biLSTM  pearson" class="gt_row gt_right"><div class="gt_from_md"><p>0.02 (-0.1;0.13)</p>
</div></td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
</div>
<p><a href="#fig-xgb_ba_cor">Figure&nbsp;5</a> shows the agreement between the XGBoost model, trained on 5-minute median filtered ZM predictions, and the 5-minute median-smoothed ZM-derived sleep quality metrics. The Bland-Altman plot for the SPT and TST reveals a good level of agreement with the ZM, as evidenced by a bias close to zero. Interestingly, a portion of the data points are located near the zero line indicating perfect agreement. The scatterplot for SPT also demonstrates a positive trend, indicating a moderate linear correlation between the XGBoost model and the ZM-derived sleep quality metrics. The bias and LOA for TST are comparable to those observed for SPT, indicating a consistent level of agreement between the two methods. The scatterplot for TST also shows a slightly higher correlation, primarily driven by the absence of extreme outliers.Furthermore, the remaining three sleep quality metrics, SE, LPS, and WASO, exhibit heteroscedasticity in contrast to SPT and TST. A moderate positive linear correlation is observed between the XGBoost model and ZM-derived sleep quality metrics for SE, however, a poor correlation is observed for LPS and WASO.</p>
<div id="fig-xgb_ba_cor" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><embed src="visuals/median_5_xgboost_ba_cor.pdf" class="img-fluid"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Comparison of sleep quality metrics derived from the XGBoost model trained on the 5-minute smoothed ZM predictions. The left column displays Bland-Altman plots. Dashed lines represent the bias (the average difference between the two measurements) and LOA, with the 95% confidence intervals represented as the grayed areas. The right column displays scatter plots of XGBoost-derived vs ZM-derived sleep quality metrics. The dashed line represents the identity line, while the full-drawn line represents the best linear fit. Pearson’s correlations are annotated in the upper left corner.</figcaption>
</figure>
</div>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>To select the most optimal method for estimating sleep from thigh-worn accelerometers, we evaluated various models for predicting in-bed and sleep time and their derived sleep quality metrics. We trained and evaluated the models using raw and median-filtered gold standard sleeå estimates from the ZM EEG-based sleep monitor. In general, all sequential models performed well at predicting in-bed time. More challenging was it to distinguish wake from sleep on the extracted in-bed time, and the performance of the sequential models were enhanced by the application of median filterings. Moreover, even though the multiclass biLSTM showed good performance across F1 score, precision and NPV, the derived sleep quality metrics were not on par with the XGBoost model which demonstrated the highest performance metrics across all evaluations, including epoch-to-epoch prediction and all sleep quality metrics. Despite this, all sequential models showed low specificity values, indicating difficulty in correctly classifying awake epochs during time in bed. The application of 5-minute and 10-minute median filters improved the performance metrics of all models. Median filterings increase total sleep time and sleep efficiency, while reducing wake after sleep onset and the number of awakenings. The XGBoost model provides the smallest bias and highest correlation with all ZM sleep quality metrics.</p>
<p>Limited research exists regarding the epoch-to-epoch effectiveness of classifying in-bed time based on data from thigh-worn accelerometers. Nevertheless, Carlson and colleagues provided compelling insights. They demonstrated that a third-party algorithm, “ProcessingPal,” and a proprietary one, “CREA,” achieved accuracies of 91% and 86% respectively. These algorithms, evaluated against self-reported measures<span class="citation" data-cites="carlson2021"><sup><a href="#ref-carlson2021" role="doc-biblioref">15</a></sup></span>, produced F1 scores as high as 95% and 96%. These figures are consistent with the performance of our sequential models, which also achieved F1 scores and accuracy scores exceeding 95% in identifying in-bed time. In our study, in-bed time is equated with SPT. All models, with the exception of XGBoost, underestimated SPT. The biLSTM model showed the greatest underestimation, with a bias of -36 minutes, reflecting trends observed in previous research. Winkler et al. developed an algorithm that, despite a strong correlation (Pearson correlation coefficient = .67) between their algorithmic results and diary-recorded waking times, overestimated waking wear time by more than 30 minutes, resulting in an underestimation of in-bed time<span class="citation" data-cites="winkler2016"><sup><a href="#ref-winkler2016" role="doc-biblioref">18</a></sup></span>. This trend was further confirmed when Inan-Eroglu et al.&nbsp;examined Winkler et al.’s algorithm, revealing a underestimation of 9.8 minutes in bed time compared to self-reported measures<span class="citation" data-cites="inan-eroglu2021"><sup><a href="#ref-inan-eroglu2021" role="doc-biblioref">16</a></sup></span>. In contrast, a study by van der Berg et al. reported a slight underestimation of in-bed time. They employed a unique approach with their algorithm, which relied on quantifying the number and duration of sedentary periods to determine time in bed, and active periods (standing or stepping) to identify wake times<span class="citation" data-cites="vanderberg2016"><sup><a href="#ref-vanderberg2016" role="doc-biblioref">17</a></sup></span>. Finally. it is important to note that high predictive performance in determining in-bed time does not necessarily translate to accurate predictions of broader sleep quality metrics. The crucial task of detecting awake periods during in-bed time, a key factor in assessing sleep quality, may not be effectively captured by in-bed time predictions alone. Indeed, underestimating in-bed time could result in overestimating waking time during in-bed time. Furthermore, the distinction between actual sleep and time spent in bed, often overlooked but vital in sleep research, is critical for a comprehensive understanding of sleep quality.</p>
<p>To the best of our knowledge, Johansson and colleagues<span class="citation" data-cites="johansson_development_2023"><sup><a href="#ref-johansson_development_2023" role="doc-biblioref">19</a></sup></span> are the only researchers who have reported epoch-to-epoch performance metrics for sleep scoring using thigh-worn accelerometers, beyond just “waking time” and “in-bed time.” They achieved a mean sensitivity of 0.84, specificity of 0.55, and accuracy of 0.80, using a single-night evaluation dataset of 71 subjects. Despite our models achieving a sensitivity above 97%, they, like Johansson et al.’s algorithm, struggled with detecting in-bed awake epochs. This is reflected in the low specificity scores, ranging from 54.7% to 76.4%, reported in our study. The challenge of low specificity is not unique to methods using data collected from thigh-worn devices. Conley et al.’s meta-analysis<span class="citation" data-cites="conley2019"><sup><a href="#ref-conley2019" role="doc-biblioref">42</a></sup></span> reported similar findings when estimating sleep using wrist-worn accelerometers among healthy adults, with a mean sensitivity, accuracy, and specificity of 0.89, 0.88, and 0.53, respectively. Furthermore, Patterson and colleagues<span class="citation" data-cites="patterson_40_2023"><sup><a href="#ref-patterson_40_2023" role="doc-biblioref">43</a></sup></span> recently summarized the performance of various heuristic algorithms, machine learning, and deep learning models used to predict sleep. They found the mean sensitivity and specificity to be 93% (SD = 2.8) and 60% (SD = 11.1) respectively. These findings underscore the challenge of automating the detection of in-bed awake periods. Interestingly, despite low specificity values for most of our models and configurations, we observed an overestimation of LPS and WASO, contrasting with most previous research<span class="citation" data-cites="conley2019 palotti2019"><sup><a href="#ref-palotti2019" role="doc-biblioref">10</a>,<a href="#ref-conley2019" role="doc-biblioref">42</a></sup></span>. This overestimation of wake epochs is evident from the low NPV scores, indicating that only a small proportion of the wake predictions are actually correct. This discrepancy may be driven by the SMOTE process used to balance the dataset. If the synthetic “wake” samples created by SMOTE are not representative of the true “wake” data, the models might learn to incorrectly classify certain “sleep” epochs as “wake”. This could lead to an overestimation of LPS and WASO, as the models are incorrectly identifying more periods of wakefulness during the sleep period.</p>
<p>The use of the SMOTE technique likely improved the performance of our models by addressing the class imbalance in our data. However, this technique also introduced synthetic”wake” samples that may not be fully representative of true wake data. This could potentially lead some models to overestimate the wake class. Interestingly, the biLSTM model, which was not trained on SMOTE-processed data, was the only one to overestimate TST and SE. On the other hand, the XGBoost model, which was trained on data subjected to the SMOTE process, was able to handle the synthetic “wake” samples better than the other models, and it did not overestimate TST to the same degree. The Bland-Altman statistics for the XGBoost model trained on the 5-minute median filtered ZM predictions showed a mean difference of -7 minutes for TST and -1.1% for SE, with limits of agreement ranging from -95.5 to 81.4 minutes and from -15.6% to 13.3% respectively. This suggests that the XGBoost model was able to maintain a balance between sensitivity and specificity, and it was not overly influenced by the synthetic “wake” samples. The XGBoost model’s success with the SMOTE dataset may be due to its ability to handle non-representative synthetic samples. XGBoost’s gradient boosting mechanism allows it to iteratively learn from the errors of previous models, which can help it to better distinguish between true wake data and synthetic wake samples created by SMOTE. This iterative learning process could make XGBoost more robust to the inaccuracies introduced by the synthetic samples, leading to better overall performance.</p>
<p>Typically, sleep detection methods are applied in two contexts: either to night recordings or to 24-hour recordings. In night recordings, it is possible to derive sleep quality metrics like SE and LPS because the SPT is already known because it is inferred from the length of the recording<span class="citation" data-cites="conley2019 patterson_40_2023"><sup><a href="#ref-conley2019" role="doc-biblioref">42</a>,<a href="#ref-patterson_40_2023" role="doc-biblioref">43</a></sup></span>. On the other hand, when sleep detection methods are applied to 24-hour recordings, most methods do not have the ability to infer the SPT with sleep diaries<span class="citation" data-cites="girschik2012"><sup><a href="#ref-girschik2012" role="doc-biblioref">44</a></sup></span>. Consequently, these methods are unable to generate certain sleep quality metrics that rely on the SPT<span class="citation" data-cites="doherty2017 anderson2014"><sup><a href="#ref-doherty2017" role="doc-biblioref">45</a>,<a href="#ref-anderson2014" role="doc-biblioref">46</a></sup></span>. To overcome this limitation, we have incorporated models that can differentiate between in-bed awake time and in-bed asleep from out-bed awake time over a 24-hour recording. This approach allows our models to estimate all commonly used sleep quality metrics. Van Hees et al.<span class="citation" data-cites="van_hees_estimating_2018"><sup><a href="#ref-van_hees_estimating_2018" role="doc-biblioref">47</a></sup></span> have proposed an algorithm to determine SPT from data collected by wrist-worn devices. This algorithm was recently validated by Plekhanova and her team<span class="citation" data-cites="plekhanova2023"><sup><a href="#ref-plekhanova2023" role="doc-biblioref">48</a></sup></span>. By combining this algorithm with other methods, further sleep quality metrics can be inferred based on the identified SPT. Van Hees et al.<span class="citation" data-cites="van_hees_estimating_2018"><sup><a href="#ref-van_hees_estimating_2018" role="doc-biblioref">47</a></sup></span> reported good agreements and low mean differences compared to self-report and PSG on SPT, findings later confirmed by Plekhanova and colleagues. However, they also observed poor agreement with LPS and Wake After Sleep Onset (WASO). They found low reliability with PSG, indicating difficulties in detecting wakefulness during in-bed time. These challenges parallel those we experienced in our study.</p>
<p>In our evaluation of sleep quality metrics, we found that LPS had the largest mean error relative to absolute time allocated to LPS. This suggests that the initial epochs of Sleep Period Time (SPT) are particularly challenging to classify correctly. This is also supported by the poor Pearson correlations between LPS derived from model predictions and the ZM. The XGBoost model, which was the best performer among all models, overestimated LPS by an average of 26.4 minutes for models trained on raw ZM predictions, 28.5 minutes for models trained on 5-minute filtered ZM predictions, and 34.5 minutes for models trained on 10-minute filtered ZM predictions. This level of discrepancy is comparable to the mean error of sleep latency of 23 minutes reported by Johansson et al.<span class="citation" data-cites="johansson_development_2023"><sup><a href="#ref-johansson_development_2023" role="doc-biblioref">19</a></sup></span>. Johansson et al.&nbsp;suggest that the discrepancy with the gold standard is likely due to the multifaceted nature of the sleep state, which is a complex physiological process. Short awakenings or sleep episodes may not necessarily correspond to noticeable changes in thigh movement, making them difficult to detect and accurately classify. These results align with several methods for wrist-worn devices reviewed by Conley and colleagues<span class="citation" data-cites="conley2019"><sup><a href="#ref-conley2019" role="doc-biblioref">42</a></sup></span>. They reported correlations between accelerometer and PSG sleep onset latency (equivalent to LPS) from 10 studies with a mean correlation of 0.2 (ranging from -0.69 to 0.69), indicating the inherent difficulty in estimating this parameter using accelerometry alone.</p>
<p>Our study’s XGBoost model demonstrated relatively narrower LOAs for TST, SE, and WASO, with ranges of -95.5 to 81.4 min, -15.6 to 13.3%, and -83.4 to 81.7 min, respectively when compared with other models such as the Van Hees algorithm<span class="citation" data-cites="hees2015"><sup><a href="#ref-hees2015" role="doc-biblioref">13</a></sup></span>, Oakley rsc (rescored)<span class="citation" data-cites="palotti2019"><sup><a href="#ref-palotti2019" role="doc-biblioref">10</a></sup></span>, and LSTM-50<span class="citation" data-cites="palotti2019"><sup><a href="#ref-palotti2019" role="doc-biblioref">10</a></sup></span> evaluated in the Patterson et al. study<span class="citation" data-cites="patterson_40_2023"><sup><a href="#ref-patterson_40_2023" role="doc-biblioref">43</a></sup></span>. Furthermore, comparing the LOAs between our XGBoost model and the algorithm developed for thigh-worn devices by Johansson et al.&nbsp;study<span class="citation" data-cites="johansson_development_2023"><sup><a href="#ref-johansson_development_2023" role="doc-biblioref">19</a></sup></span>, our XGBoost model showed narrower LOAs for TST , SE, LPS , and WASO, but not SPT. Generally, all methods, both from this study and from the reviewed literature, exibit wide LOAs sugesting that there is high variability in the derevide sleep quality metrics. In the current study, the presence of extreme outliers seem to drive the widening the LOAs. These findings imply that the current methods, are only reasonbly reliable for assessing sleep quality metrics at a group level. However, caution should be exercised when applying the models and methods to individual-level sleep assessments. Therefore, further improvements and refinements are needed to enhance the precision and reliability of these models for individual sleep assessments.</p>
<p>In this study, we used the ZM as the reference method, rather than PSG, which is considered the gold standard for sleep measurement. This choice may contribute to discrepancies between our models and the ZM, as without a true gold standard, it’s difficult to determine the source of disagreement. However, we believe that the use of ZM, which allows for multiple consecutive nights of recording, is valuable. This approach captures intra-individual variances in sleep, which is impractical with PSG. It also enabled us to include more nights in our study typically compared to those relying on PSG. For instance, the widely used Newcastle dataset<span class="citation" data-cites="hees2015"><sup><a href="#ref-hees2015" role="doc-biblioref">13</a></sup></span> only contains data from 28 participants. However, upon examining the ZM outputs, we found that the raw predictions were not optimal for developing machine learning models due to a seemingly low signal-to-noise ratio (see <a href="#fig-zm-median">Figure&nbsp;3</a>). The ZM itself mitigates this issue by applying certain filtering processes when generating sleep quality metrics. For example, epochs contributing to WASO must be in contiguous epochs of 3, and sleep only counts towards sleep quality metrics if 10 out of 12 minutes are scored as sleep. To improve the prospect of our machine learning algorithms, we applied median filters to the ZM raw predictions. This did in fact alter the derived sleep quality metrics. Notably, the mean WASO decreased from 39 minutes in the raw predictions to 30.6 minutes in the 5-minute median filtered predictions, and further decreased to 22.3 minutes in the 10-minute filtered predictions. The application of 5-minute and 10-minute median filters also led to increases in TST, SE, and LPS. This suggests that the filters may categorize some instances of wakefulness as sleep and smooth out brief awakenings. Despite these changes, the overall sleep quality profile derived from the median-filtered predictions is still comparable to that from the raw predictions, justifying our approach.</p>
<p>The study boasts several strengths, including the capacity to distinguish in-bed awake and asleep from out-of-bed, thereby allowing for the extraction of vital sleep quality metrics. Furthermore, the research benefits from evaluating multiple nights per subject, providing valuable information into intra-subject sleep variability. However, certain limitations exist. The use of ZM, which isn’t recognized as a gold standard, could potentially compromise our findings’ validity. Future research could consider using PSG as a reference for methods similar to ours, despite its limitations, for a more accurate comparison. Moreover, our models weren’t validated using an external dataset, a process that would have showcased their broader applicability. Hence, our conclusions remain confined primarily to children.</p>
<p>In conclusion, our study contributes to the ongoing efforts to improve sleep estimation methods using thigh-worn accelerometers. We evaluated different machine learning and deep learnng models for predicting in-bed and sleep times and their corresponding sleep quality metrics. While the sequential models generally demonstrated excellent performance in predicting in-bed time, they faced challenges in accurately distinguishing between sleep and wake epochs during in-bed time. Among all models and configurations evaluated, the XGBoost model exhibited the best performance, including epoch-to-epoch predictions and sleep quality metrics. Our research also highlighted the current limitations of sleep detection methods, such as challenges in effectively detecting wake periods during in-bed time and the need for further improvements to increase the precision of individual sleep assessments. We believe our work lays the groundwork for future research to further refine and improve the performance of these models, contributing to a more precise and accurate evaluation of sleep patterns and quality using thigh-worn accelerometers.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-line-spacing="2" role="list">
<div id="ref-ma2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Ma, G. <a href="https://doi.org/10.1016/j.jsmc.2016.10.012">Sleep, Health, and Society</a>. <em>Sleep medicine clinics</em> <strong>12</strong>, (2017).</div>
</div>
<div id="ref-meyer2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Meyer, N., Harvey, A. G., Lockley, S. W. &amp; Dijk, D.-J. <a href="https://doi.org/10.1016/S0140-6736(22)00877-7">Circadian rhythms and disorders of the timing of sleep</a>. <em>The Lancet</em> <strong>400</strong>, 1061–1078 (2022).</div>
</div>
<div id="ref-kpavlova2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">K Pavlova, M. &amp; Latreille, V. <a href="https://doi.org/10.1016/j.amjmed.2018.09.021">Sleep Disorders</a>. <em>The American Journal of Medicine</em> <strong>132</strong>, 292–299 (2019).</div>
</div>
<div id="ref-difrancesco2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Difrancesco, S. <em>et al.</em> <a href="https://doi.org/10.1002/da.22949">Sleep, circadian rhythm, and physical activity patterns in depressive and anxiety disorders: A 2-week ambulatory assessment study</a>. <em>Depression and Anxiety</em> <strong>36</strong>, 975–986 (2019).</div>
</div>
<div id="ref-vandewater2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Van De Water, A. T. M., Holmes, A. &amp; Hurley, D. A. <a href="https://doi.org/10.1111/j.1365-2869.2009.00814.x">Objective measurements of sleep for non-laboratory settings as alternatives to polysomnography <span></span> a systematic review</a>. <em>Journal of Sleep Research</em> <strong>20</strong>, 183–200 (2011).</div>
</div>
<div id="ref-lee2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Lee, Y. J., Lee, J. Y., Cho, J. H. &amp; Choi, J. H. <a href="https://doi.org/10.5664/jcsm.9538">Interrater reliability of sleep stage scoring: a meta-analysis</a>. <em>Journal of clinical sleep medicine: JCSM: official publication of the American Academy of Sleep Medicine</em> <strong>18</strong>, 193–202 (2022).</div>
</div>
<div id="ref-moore2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Moore, C. M., Schmiege, S. J. &amp; Matthews, E. E. <a href="https://doi.org/10.1080/15402002.2014.940108">Actigraphy and Sleep Diary Measurements in Breast Cancer Survivors: Discrepancy in Selected Sleep Parameters</a>. <em>Behavioral Sleep Medicine</em> <strong>13</strong>, 472–490 (2015).</div>
</div>
<div id="ref-webster1982" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Webster, J. B., Kripke, D. F., Messin, S., Mullaney, D. J. &amp; Wyborney, G. <a href="https://doi.org/10.1093/sleep/5.4.389">An activity-based sleep monitor system for ambulatory use</a>. <em>Sleep</em> <strong>5</strong>, 389–399 (1982).</div>
</div>
<div id="ref-cole1992" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Cole, R. J., Kripke, D. F., Gruen, W., Mullaney, D. J. &amp; Gillin, J. C. <a href="https://doi.org/10.1093/sleep/15.5.461">Automatic sleep/wake identification from wrist activity</a>. <em>Sleep</em> <strong>15</strong>, 461–469 (1992).</div>
</div>
<div id="ref-palotti2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Palotti, J. <em>et al.</em> <a href="https://doi.org/10.1038/s41746-019-0126-9">Benchmark on a large cohort for sleep-wake classification with machine learning techniques</a>. <em>npj Digital Medicine</em> <strong>2</strong>, 1–9 (2019).</div>
</div>
<div id="ref-sazonov2004" class="csl-entry" role="listitem">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Sazonov, E., Sazonova, N., Schuckers, S., Neuman, M. &amp; Group, C. S. <a href="https://doi.org/10.1088/0967-3334/25/5/018">Activity-based sleep-wake identification in infants</a>. <em>Physiological Measurement</em> <strong>25</strong>, 1291–1304 (2004).</div>
</div>
<div id="ref-sadeh1994" class="csl-entry" role="listitem">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Sadeh, A., Sharkey, K. M. &amp; Carskadon, M. A. <a href="https://doi.org/10.1093/sleep/17.3.201">Activity-based sleep-wake identification: an empirical test of methodological issues</a>. <em>Sleep</em> <strong>17</strong>, 201–207 (1994).</div>
</div>
<div id="ref-hees2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Hees, V. T. van <em>et al.</em> <a href="https://doi.org/10.1371/journal.pone.0142533">A Novel, Open Access Method to Assess Sleep Duration Using a Wrist-Worn Accelerometer</a>. <em>PLOS ONE</em> <strong>10</strong>, e0142533 (2015).</div>
</div>
<div id="ref-sundararajan2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Sundararajan, K. <em>et al.</em> <a href="https://doi.org/10.1038/s41598-020-79217-x">Sleep classification from wrist-worn accelerometer data using random forests</a>. <em>Scientific Reports</em> <strong>11</strong>, 24 (2021).</div>
</div>
<div id="ref-carlson2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Carlson, J. A. <em>et al.</em> <a href="https://doi.org/10.1123/jmpb.2020-0045">Validity of Two Awake Wear-Time Classification Algorithms for activPAL in Youth, Adults, and Older Adults</a>. <em>Journal for the Measurement of Physical Behaviour</em> <strong>4</strong>, 151–162 (2021).</div>
</div>
<div id="ref-inan-eroglu2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Inan-Eroglu, E. <em>et al.</em> <a href="https://doi.org/10.1123/jmpb.2020-0033">Comparison of a Thigh-Worn Accelerometer Algorithm With Diary Estimates of Time in Bed and Time Asleep: The 1970 British Cohort Study</a>. <em>Journal for the Measurement of Physical Behaviour</em> <strong>4</strong>, 60–67 (2021).</div>
</div>
<div id="ref-vanderberg2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Berg, J. D. van der <em>et al.</em> <a href="https://doi.org/10.1080/02640414.2016.1140908">Identifying waking time in 24-h accelerometry data in adults using an automated algorithm</a>. <em>Journal of Sports Sciences</em> <strong>34</strong>, 1867–1873 (2016).</div>
</div>
<div id="ref-winkler2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Winkler, E. A. H. <em>et al.</em> <a href="https://doi.org/10.1088/0967-3334/37/10/1653">Identifying adults<span>’</span> valid waking wear time by automated estimation in activPAL data collected with a 24 h wear protocol</a>. <em>Physiological Measurement</em> <strong>37</strong>, 1653 (2016).</div>
</div>
<div id="ref-johansson_development_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Johansson, P. J. <em>et al.</em> <a href="https://doi.org/10.1111/jsr.13725">Development and performance of a sleep estimation algorithm using a single accelerometer placed on the thigh: An evaluation against polysomnography</a>. <em>Journal of Sleep Research</em> <strong>32</strong>, e13725 (2023).</div>
</div>
<div id="ref-skotte_detection_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Skotte, J., Korshøj, M., Kristiansen, J., Hanisch, C. &amp; Holtermann, A. <a href="https://doi.org/10.1123/jpah.2011-0347">Detection of <span>Physical</span> <span>Activity</span> <span>Types</span> <span>Using</span> <span>Triaxial</span> <span>Accelerometers</span></a>. <em>Journal of Physical Activity and Health</em> <strong>11</strong>, 76–84 (2014).</div>
</div>
<div id="ref-arvidsson2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Arvidsson, D. <em>et al.</em> <a href="https://doi.org/10.1111/sms.13470">Re-examination of accelerometer data processing and calibration for the assessment of physical activity intensity</a>. <em>Scandinavian Journal of Medicine &amp; Science in Sports</em> <strong>29</strong>, 1442–1452 (2019).</div>
</div>
<div id="ref-kaplan2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Kaplan, R. F., Wang, Y., Loparo, K. A., Kelly, M. R. &amp; Bootzin, R. R. <a href="https://doi.org/10.2147/NSS.S71159">Performance evaluation of an automated single-channel sleep<span></span>wake detection algorithm</a>. <em>Nature and Science of Sleep</em> <strong>6</strong>, 113–122 (2014).</div>
</div>
<div id="ref-wang2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Wang, Y., Loparo, K. A., Kelly, M. R. &amp; Kaplan, R. F. <a href="https://doi.org/10.2147/NSS.S77888">Evaluation of an automated single-channel sleep staging algorithm</a>. <em>Nature and Science of Sleep</em> <strong>7</strong>, 101–111 (2015).</div>
</div>
<div id="ref-pedersen2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">Pedersen, J., Rasmussen, M. G. B., Olesen, L. G., Kristensen, P. L. &amp; Grøntved, A. <a href="https://doi.org/10.1186/s41606-021-00059-1">Self-administered electroencephalography-based sleep assessment: Compliance and perceived feasibility in children and adults</a>. <em>Sleep Science and Practice</em> <strong>5</strong>, 8 (2021).</div>
</div>
<div id="ref-rasmussen2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">Rasmussen, M. G. B. <em>et al.</em> <a href="https://doi.org/10.1186/s12889-020-8458-6">Short-term efficacy of reducing screen media use on physical activity, sleep, and physiological stress in families with children aged 4<span></span>14: Study protocol for the SCREENS randomized controlled trial</a>. <em>BMC Public Health</em> <strong>20</strong>, 380 (2020).</div>
</div>
<div id="ref-skovgaard2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Skovgaard, E. L. <em>et al.</em> <a href="https://doi.org/10.1038/s41598-023-29666-x">Generalizability and performance of methods to detect non-wear with free-living accelerometer recordings</a>. <em>Scientific Reports</em> <strong>13</strong>, 2496 (2023).</div>
</div>
<div id="ref-walch2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Walch, O., Huang, Y., Forger, D. &amp; Goldstein, C. <a href="https://doi.org/10.1093/sleep/zsz180">Sleep stage prediction with raw acceleration and photoplethysmography heart rate data derived from a consumer wearable device</a>. <em>Sleep</em> <strong>42</strong>, zsz180 (2019).</div>
</div>
<div id="ref-galland_normal_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Galland, B. C., Taylor, B. J., Elder, D. E. &amp; Herbison, P. <a href="https://doi.org/10.1016/j.smrv.2011.06.001">Normal sleep patterns in infants and children: A systematic review of observational studies</a>. <em>Sleep Medicine Reviews</em> <strong>16</strong>, 213–222 (2012).</div>
</div>
<div id="ref-hochreiter1997" class="csl-entry" role="listitem">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Hochreiter, S. &amp; Schmidhuber, J. <a href="https://doi.org/10.1162/neco.1997.9.8.1735">Long short-term memory</a>. <em>Neural Computation</em> <strong>9</strong>, 1735–1780 (1997).</div>
</div>
<div id="ref-sano2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Sano, A., Chen, W., Lopez-Martinez, D., Taylor, S. &amp; Picard, R. W. <a href="https://doi.org/10.1109/JBHI.2018.2867619">Multimodal Ambulatory Sleep Detection Using LSTM Recurrent Neural Networks</a>. <em>IEEE journal of biomedical and health informatics</em> <strong>23</strong>, 1607–1617 (2019).</div>
</div>
<div id="ref-chen2021" class="csl-entry" role="listitem">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">Chen, Z., Wu, M., Cui, W., Liu, C. &amp; Li, X. <a href="https://doi.org/10.1109/JBHI.2020.3006145">An Attention Based CNN-LSTM Approach for Sleep-Wake Detection With Heterogeneous Sensors</a>. <em>IEEE journal of biomedical and health informatics</em> <strong>25</strong>, 3270–3277 (2021).</div>
</div>
<div id="ref-chawla2002" class="csl-entry" role="listitem">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Chawla, N. V., Bowyer, K. W., Hall, L. O. &amp; Kegelmeyer, W. P. <a href="https://doi.org/10.1613/jair.953">SMOTE: Synthetic Minority Over-sampling Technique</a>. <em>Journal of Artificial Intelligence Research</em> <strong>16</strong>, 321–357 (2002).</div>
</div>
<div id="ref-themis" class="csl-entry" role="listitem">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Hvitfeldt, E. <em><a href="https://CRAN.R-project.org/package=themis">Themis: Extra recipes steps for dealing with unbalanced data</a></em>. (2023).</div>
</div>
<div id="ref-hjorth2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Hjorth, M. F. <em>et al.</em> <a href="https://doi.org/10.1111/j.1479-8425.2012.00578.x">Measure of sleep and physical activity by a single accelerometer: Can a waist-worn Actigraph adequately measure sleep in children?</a> <em>Sleep and Biological Rhythms</em> <strong>10</strong>, 328–335 (2012).</div>
</div>
<div id="ref-kushida2001" class="csl-entry" role="listitem">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">Kushida, C. A. <em>et al.</em> <a href="https://doi.org/10.1016/s1389-9457(00)00098-8">Comparison of actigraphic, polysomnographic, and subjective assessment of sleep parameters in sleep-disordered patients</a>. <em>Sleep Medicine</em> <strong>2</strong>, 389–396 (2001).</div>
</div>
<div id="ref-diciccio_bootstrap_1996" class="csl-entry" role="listitem">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">DiCiccio, T. J. &amp; Efron, B. <a href="https://doi.org/10.1214/ss/1032280214">Bootstrap confidence intervals</a>. <em>Statistical Science</em> <strong>11</strong>, 189–228 (1996).</div>
</div>
<div id="ref-R-lang" class="csl-entry" role="listitem">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">R Core Team. <em><a href="https://www.R-project.org/">R: A language and environment for statistical computing</a></em>. (R Foundation for Statistical Computing, 2023).</div>
</div>
<div id="ref-tidymodels" class="csl-entry" role="listitem">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">Kuhn, M. &amp; Wickham, H. <em><a href="https://www.tidymodels.org">Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles.</a></em> (2020).</div>
</div>
<div id="ref-tidyverse" class="csl-entry" role="listitem">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Wickham, H. <em>et al.</em> <a href="https://doi.org/10.21105/joss.01686">Welcome to the <span class="nocase">tidyverse</span></a>. <em>Journal of Open Source Software</em> <strong>4</strong>, 1686 (2019).</div>
</div>
<div id="ref-10.5555/1593511" class="csl-entry" role="listitem">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">Van Rossum, G. &amp; Drake, F. L. <em>Python 3 reference manual</em>. (CreateSpace, 2009).</div>
</div>
<div id="ref-NEURIPS2019_9015" class="csl-entry" role="listitem">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">Paszke, A. <em>et al.</em> <a href="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf">PyTorch: An imperative style, high-performance deep learning library</a>. in <em>Advances in neural information processing systems 32</em> 8024–8035 (Curran Associates, Inc., 2019).</div>
</div>
<div id="ref-conley2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">Conley, S. <em>et al.</em> <a href="https://doi.org/10.1016/j.smrv.2019.05.001">Agreement between actigraphic and polysomnographic measures of sleep in adults with and without chronic conditions: A systematic review and meta-analysis</a>. <em>Sleep Medicine Reviews</em> <strong>46</strong>, 151–160 (2019).</div>
</div>
<div id="ref-patterson_40_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Patterson, M. R. <em>et al.</em> <a href="https://doi.org/10.1038/s41746-023-00802-1">40 years of actigraphy in sleep medicine and current state of the art algorithms</a>. <em>npj Digital Medicine</em> <strong>6</strong>, 1–7 (2023).</div>
</div>
<div id="ref-girschik2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">44. </div><div class="csl-right-inline">Girschik, J., Fritschi, L., Heyworth, J. &amp; Waters, F. <a href="https://doi.org/10.2188/jea.je20120012">Validation of self-reported sleep against actigraphy</a>. <em>Journal of Epidemiology</em> <strong>22</strong>, 462–468 (2012).</div>
</div>
<div id="ref-doherty2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">45. </div><div class="csl-right-inline">Doherty, A. <em>et al.</em> <a href="https://doi.org/10.1371/journal.pone.0169649">Large Scale Population Assessment of Physical Activity Using Wrist Worn Accelerometers: The UK Biobank Study</a>. <em>PLOS ONE</em> <strong>12</strong>, e0169649 (2017).</div>
</div>
<div id="ref-anderson2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">46. </div><div class="csl-right-inline">Anderson, K. N. <em>et al.</em> <a href="https://doi.org/10.1093/ageing/aft153">Assessment of sleep and circadian rhythm disorders in the very old: The newcastle 85+ cohort study</a>. <em>Age and Ageing</em> <strong>43</strong>, 57–63 (2014).</div>
</div>
<div id="ref-van_hees_estimating_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">47. </div><div class="csl-right-inline">Van Hees, V. T. <em>et al.</em> <a href="https://doi.org/10.1038/s41598-018-31266-z">Estimating sleep parameters using an accelerometer without sleep diary</a>. <em>Scientific Reports</em> <strong>8</strong>, 12975 (2018).</div>
</div>
<div id="ref-plekhanova2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">48. </div><div class="csl-right-inline">Plekhanova, T. <em>et al.</em> <a href="https://doi.org/10.1111/jsr.13760">Validation of an automated sleep detection algorithm using data from multiple accelerometer brands</a>. <em>Journal of Sleep Research</em> <strong>32</strong>, e13760 (2023).</div>
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>