---
title: Estimating Sleep Quality Metrics Using Free-Living Accelerometer Data From Thigh-Worn Devices in Comparison to an EEG-Based Sleep Tracking Device
author:
  - name: Esben Høegholm Lykke
    email: eskovgaard@health.sdu.dk
    affiliations: 
        - id: some-tech
          name: University of Southern Denmark
          department: Department of Sports Science and Clinical Biomechanics
          address: Campusvej 55
          city: Odense
          state: Denmark
          postal-code: 5230
    attributes:
        corresponding: true
  - name: Jan Christian Brønd
    email: jbrond@health.sdu.dk
    affiliations:
        - id: another-u
          name: University of Southern Denmark
          department: Department of Sports Science and Clinical Biomechanics
          address: Campusvej 55
          city: Odense
          state: Denmark
          postal-code: 5230
abstract: "LÆS IKKE! Det er volapyk på latin. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse vitae dictum eros, ullamcorper elementum orci. Sed laoreet nulla neque, pulvinar fermentum mi iaculis at. Nulla ultricies nibh sit amet vestibulum rutrum. Nam pharetra nisl sed ipsum maximus suscipit. Duis metus nunc, ullamcorper eu mi rutrum, tempus ultricies ante. Nunc vitae lectus nisi. Aliquam efficitur ut eros ut pellentesque. Aenean blandit, nisl nec efficitur interdum, nisi ipsum fermentum dolor, at tempus sem turpis in lacus. Curabitur sollicitudin lectus sit amet velit pellentesque laoreet. Ut posuere diam lobortis nisi eleifend tincidunt. Ut at euismod sem, sed dignissim ligula. Aliquam lacinia massa libero, id eleifend velit pulvinar ac. Fusce volutpat elit eu nulla viverra, nec tempus orci pellentesque."
keywords: 
  - Sleep
  - Accelerometry
  - EEG
  - Machine learning
  - Sleep quality
date: last-modified
bibliography: bibliography.bib
format:
  elsevier-pdf:
    keep-tex: true
    journal:
      name: npj Digital Medicine
      formatting: preprint
      model: 3p
      cite-style: super
    include-in-header: 
      text: '\usepackage{lineno}\linenumbers'
    fig-pos: 'b'
  docx:
    number-sections: true
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: inline
---

# Introduction

An extensive array of research underlines the importance of sleep for
both mental and physical health[@ma2017; @meyer2022; @kpavlova2019;
@difrancesco2019]. Consequently, accurate sleep assessment methods are
essential for tracking sleep patterns, thereby enhancing our
comprehension of the sleep-health relationship. Furthermore, ensuring
high user-acceptability for these methods is essential in order to
conduct large-scale studies over prolonged periods.

While laboratory-based polysomnography is considered the gold standard
for objectively measuring sleep, its practicality in large-scale
epidemiological studies is limited due to its high cost, the need for
professional administration, and the substantial resources required for
specialized equipment[@vandewater2011]. As an alternative, diaries is
commonly used as low-cost and low-tech methods for sleep assessment in
population research. However, relying solely on diary-based methods may
introduce recall bias and other limitations[@moore2015]. A more feasible
approach in large-scale epidemiological studies is the use of
device-based measurement methods that can estimate sleep duration. This
method offers the advantage of being less burdensome for participants
and avoids potential biases associated with recall.

In this context, the Zmachine®️ Insight+ (ZM) emerges as a valuable
tool. Validated against polysomnography with favorable
results[@kaplan2014; @wang2015], the ZM provides comparable data without
the high costs or need for professional monitoring associated with
polysomnography. Furthermore, the ease of use of the ZM device makes it
compliant for free-living use[@pedersen2021]. This allows for the
analysis of multiple consecutive nights, as compared to single-night
recordings from PSG, thereby capturing the important variations in sleep
across multiple nights.

The introduction of body-worn accelerometers has provided an effective
and affordable alternative for objectively assessing sleep patterns in a
home environment over extended periods. These accelerometers collect
continuous, high-resolution data for several weeks without requiring
recharging, thus minimizing participant burden. Initial applications of
accelerometry for sleep and wake stage classification were based on
wrist movements. The original algorithm, developed in 1982 using simple
linear regression and validated with PSG [@webster1982], was later
refined in 1992 [@cole1992], leading to the widely used Cole-Kripke
model. Subsequent research on wrist-worn accelerometer data has employed
heuristic algorithms, advanced machine learning models, as well as
regression and deep learning techniques[@palotti2019; @cole1992;
@sazonov2004; @sadeh1994; @hees2015; @sundararajan2021].

Despite the well-developed field of accelerometer data analysis for
sleep detection from wrist and hip-worn devices, the same level of
advancement is not mirrored in studies utilizing thigh-worn
accelerometers. Methods for assessing sleep using wrist and hip-worn
accelerometers have greatly evolved over the years, employing an
extensive range of techniques. These include heuristic algorithms,
machine learning models, regression and deep learning techniques, all
tailored to the specific signal characteristics of wrist and hip-worn
devices [@palotti2019; @cole1992; @sazonov2004; @sadeh1994; @hees2015;
@sundararajan2021; @patterson_40_2023]. However, for thigh-worn
accelerometers, the landscape appears less mature, with only a handful
of studies investigating sleep detection algorithms. The majority of the
efforts are focused on delineating wakefulness from sleep, with
particular emphasis on the definition of 'waking time' and 'bedtime'
[@carlson2021; @inan-eroglu2021; @vanderberg2016; @winkler2016].
Furthermore, while strides have been made recently in estimating sleep
duration with these devices, with the introduction of a promising
algorithm and its comparison against PSG[@johansson_development_2023],
the field is still in its infancy when it comes to employing machine
learning techniques. Given the potential for accurate physical behavior
assessment that thigh-worn accelerometers
provide[@skotte_detection_2014; @arvidsson2019], a significant research
gap exists. Therefore, there is a pressing need for future studies to
develop techniques similar to those used for wrist and hip-worn
accelerometers, with the ultimate goal of establishing a more holistic,
accurate, and user-friendly method of sleep and physical activity
tracking.

Our primary objective in this study was to evaluate a range of machine
learning and deep learning models, utilizing the raw data collected from
a tri-axial thigh-worn accelerometer to estimate in-bed and sleep time.
To ensure the reliability and effectiveness of our models, we compared
their outputs with an EEG-based sleep tracking device, which we
considered the gold standard for measuring sleep. Furthermore, our
secondary goal was to assess the developed models' performance in
evaluating important sleep quality parameters, including sleep period
time (SPT), total sleep time (TST), sleep efficiency (SE), latency until
persistent sleep (LPS), and wake after sleep onset (WASO).

# Methods

## Dataset and participants

The current study leverages data from the SCREENS
project[@rasmussen2020], a study conducted from October 2018 to March
2019 in Middelfart, Southern Denmark, that evaluated the impact of
screen media usage on Danish families. For our analysis, we focused on
data from child participants aged between 6 and 10 years within the
SCREENS cohort. Our primary sources of data were accelerometer readings
from Axivity AX3 devices attached to the children's thighs, and
electroencephalography (EEG) data derived from the ZM device. The
Axivity AX3, an unobtrusive 3-axis accelerometer, was positioned midway
between the hip and knee on the right anterior thigh, recording
participant movement data.

Sleep state information was extracted using the ZM, a product of General
Sleep Corporation. The ZM, which utilizes advanced EEG hardware and
signal processing algorithms, employs three self-adhesive, disposable
sensors placed outside the hairline for reliable EEG signal acquisition.
The ZM uses two proprietary algorithms: Z-ALG and Z-PLUS. The Z-ALG is
utilized for accurate sleep detection, showcasing its suitability for
in-home monitoring[@kaplan2014], while the Z-PLUS effectively
differentiates sleep stages, as evidenced by its alignment with expert
evaluations using PSG data[@wang2015]. In the current study, we treated
all sleep stages as a single category effectively deducing the output of
the ZM to "awake" and "asleep" as the ability to distinguish sleep
stages are not a necessity to derive sleep quality parameters of
interest and to simplify the learning process of the models.

@fig-flow illustrates the selection criteria applied to the children's
recordings from the SCREENS study. We included only ZM recordings that
were accompanied by complete accelerometer data and lasted between 7 and
14 hours. Any night when the ZM reported sensor issues was excluded. The
children whose recordings were considered had an average age of 9.4
years, with a standard deviation of 2.1. In their raw form, the ZM
predictions encompassed 696,779 epochs, each 30 seconds long. Notably,
approximately 84% of the total ZM recording duration was classified as
sleep, resulting in an imbalance of the dataset.

![Flowchart of eligible ZM recording nights included in the
study](visuals/flowchart_of_elligible_nights.pdf){#fig-flow}

Finally, we affirm that the SCREENS study received approval from the
Regional Scientific Committee of Southern Denmark, and all data handling
processes complied with the General Data Protection Regulation (GDPR),
ensuring the ethical and secure management of participant information.

## Data Preprocessing and Feature Extraction

In this study, data processing of the raw accelerometer data began with
a low-pass filtration step using a 4th order Butterworth filter with a 5
Hz cut-off frequency to eliminate high-frequency noise. Following
filtration, data were partitioned into overlapping 2-second intervals,
each successive interval sharing a 50% overlap with the previous one
similar to methods described by Skotte et al.[@skotte_detection_2014].
Any non-wear data was remove using previously described
methods[@skovgaard2023] and data was resampled to 30-second epochs so
every sample classified by the algorithms corresponds to a 30-second
epoch scored during the ZM recordings. Subsequently, we performed a
feature extraction process that yielded a set of 88 features, providing
a robust characterization of the data. Extracted from accelerometer and
temperature signals, these features include temporal elements that use
both lag and lead values, capturing dynamic data trends by incorporating
measurements from preceding and upcoming intervals. Furthermore,
inspired by Walch et al.[@walch2019], we incorporated sensor-independent
features to encapsulate circadian rhythms. These features offer unique
insights not directly discernible from sensor outputs and are meant to
approximate the changing drive of the circadian clock to sleep over the
course of the night (see @fig-sensor-independent). Furthermore, the
feature set was enriched by including signal characteristics, which
encompass vector magnitude, mean crossing rate, skewness, and kurtosis
for each of the x, y, and z dimensions. All features are summarized in
table ??? **in the supplementary matrials**. Subsequently, we merged the
ZM and corresponding accelerometer recordings. Any overlapping time
between the ZM and accelerometer data was treated as 'in-bed' time, with
the remaining time considered 'out-of-bed'. This process yielded a
dataset providing a around the clock temporal view of each participant's
activity and sleep patterns.

![Sensor-independent features of circadian rhythms across two
consecutive nights. A) cosinus feature, B) linear
feature.](visuals/sensor_independent.pdf){#fig-sensor-independent}

In addition to the engineered features, we chose to incorporate the
median-filtered raw predictions from the ZM device into our modeling
process. This decision stemmed from the understanding that children
typically undergo around five to eight sleep cycles per night, with
awakenings most likely occurring at the end of each
cycle[@galland_normal_2012]. Upon examining the raw ZM predictions, we
noted a significant overestimation in the number of awakenings per night
for the children in our study, exceeding what would be expected based on
typical sleep cycle patterns. In particular, many of these brief
awakenings could be considered as noise, which when present in the data,
can potentially hinder the learning process of machine learning models
by obscuring the underlying patterns that the models are trying to
learn, leading to less accurate predictions. Consequently, we elected to
train and evaluate our models using not only the raw ZM output, but also
versions that were subjected to 5-minute and 10-minute median filters.
This approach, by mitigating this noise, resulted in an anticipated,
more age-appropriate count of awakenings per night, providing a more
accurate depiction of children's sleep patterns (see @fig-zm-median).

![The difference in number of awakenings between the raw ZM predictions
vs. 5-minute, and 10-minute median filtered predictions for a random
night. Grey line is the raw predictions, black line is the median
filtered predictions. A: 5-minute median filter on raw ZM predictions,
B: 10-minute median filter on raw ZM
predictions.](visuals/zm_raw_vs_filtered.pdf){#fig-zm-median}

## Algorithms, Training and Validation

In this study, we employed two distinct modeling strategies to analyze
sleep patterns from thigh-mounted accelerometer data. We used a
sequential strategy, comprising an ensemble of four pairs of models,
each pair featuring the same algorithm. This strategy aimed to make the
prediction task more manageable for the algorithms by breaking it down
into a sequence of two binary classifications: first predicting 'in-bed'
time, then 'sleep' time. Simultaneously, we also used a multiclass
approach utilizing a bidirectional Long Short-Term Memory
(biLSTM)[@hochreiter1997] neural network.

### Models in Sequence

To predict in-bed time and sleep time accurately, we employed an
ensemble learning strategy based on sequential binary classification
models. This approach involved constructing a sequence of models using
multiple machine learning algorithms to improve predictive accuracy. The
process began with an initial model predicting in-bed time, followed by
a second model that utilized the output of the initial model to predict
sleep time. This sequential approach was applied across all four
algorithms detailed below, with each subsequent model leveraging the
outputs of the previous models for improved predictions.

1.  Logistic Regression (LREG): Logistic regression served as a simple
    and fast baseline model. However, due to its linear nature, it may
    struggle with capturing complex relationships and non-linear
    patterns present in the accelerometer data.

2.  Decision Tree (TREE): Decision trees are capable of handling
    non-linear patterns and are easily interpretable. However, they are
    prone to overfitting, particularly when dealing with complex
    patterns that require simultaneous consideration of multiple
    features.

3.  Single-layer Feed-forward Neural Network (SNN): Single-layer
    feed-forward neural networks can effectively capture non-linear
    relationships, even with their relatively simple structure. However,
    they tend to be more challenging to interpret compared to simpler
    models. Additionally, careful tuning of the network's architecture
    and training process is required to mitigate the risk of
    overfitting.

4.  XGBoost (XGB): XGBoost is a powerful algorithm known for its ability
    to provide highly accurate predictions and handle complex,
    non-linear patterns in the data. It also incorporates built-in
    methods to prevent overfitting. However, training XGBoost models can
    be computationally intensive, and interpreting the predictions it
    generates can pose challenges.

### Multiclass Model

In this study, we employed a biLSTM, a multiclass classifier, to predict
three distinct states: out-of-bed-awake, in-bed-awake, and
in-bed-asleep. The architecture of the biLSTM was set up with four
layers, each equipped with 128 hidden units. This configuration was
intentionally chosen to balance between model complexity and training
efficiency: it provided the depth necessary for learning intricate
patterns while remaining feasible for timely training. The bidirectional
design of the LSTM served to enhance data interpretation and mitigate
overfitting by doubling the hidden units at each time step. For input,
we used tensors shaped as sequences, with each sequence spanning 10
minutes and a step size of one.This approach follows in the footsteps of
previous studies that utilized LSTM models for sleep detection. These
studies showcased the promising potential of LSTMs in capturing complex
temporal patterns. Particularly, the works of Sano et al. [@sano2019]
and Chen et al. [@chen2021] demonstrated the effectiveness of LSTM
models in improving sleep detection using accelerometer data,
underscoring the value of this modeling approach.

### Model Training

For the models in sequence, we trained four pairs of classification
models. Each pair was designed to distinguish between in-bed/out-of-bed
and asleep/awake states, respectively. The dataset was randomly split
into a training set and a testing set, each containing approximately 50%
of the subjects. This division ensured that samples from the same night
were never simultaneously present in both sets. To optimize
hyperparameters, we performed a 10-fold Monte Carlo cross-validation on
a regular grid, comprising 20 different combinations of hyperparameters.
The F1 score served as the optimization metric. The best-performing set
of hyperparameters was then used to fit the models to the full training
dataset. This approach allowed us to maximize performance by leveraging
all available data. Moreover, after extracting the in-bed time from the
initial sequential models, the imbalance on the resulting dataset could
cause biases during model training, as models may favor predicting the
majority class. To rectify this, we employed the Synthetic Minority
Over-sampling Technique (SMOTE)[@chawla2002]. SMOTE generates new
samples by interpolating random samples with their nearest neighbors. We
utilized the themis R package[@themis] to implement SMOTE, resulting in
a balanced distribution of training samples across both classes.

The biLSTM model was trained to differentiate between three states:
out-of-bed-awake, in-bed-awake, and in-bed-asleep. The data used for
training the biLSTM was randomly divided into training, validation, and
test sets, based on a 50/25/25 split. We ensured that data from the same
night was not present across different sets. The model was trained using
the Adam optimizer, selected for its computational efficiency and
adaptability of the learning rate during training. Given the multiclass
classification task with mutually exclusive classes, we employed the
cross-entropy loss function. To obtain a probability distribution over
the classes, the softmax activation function was applied at the output
layer. We evaluated the model's performance using the F1 score on both
the training and validation sets. We implemented early stopping with a
patience of 3 epochs, halting the training process if there was no
improvement in the validation loss over three consecutive epochs.

### Model Validation

In our study, we utilized standard evaluation metrics to assess the
performance of each model on an epoch-to-epoch basis. These include
accuracy ($accuracy = \frac{TP+TN}{TP+TN+FP+FN}$), sensitivity
($sensitivity = \frac{TP}{TP+FN}$), specificity
($specificity = \frac{TN}{TN+FP}$), precision
($precision = \frac{TP}{TP+FP}$), negative predictive value (NPV,
$NPV = \frac{TN}{TN + FN}$), and F1 score
($F_1 = 2 * \frac{precision * sensitivity}{precision + sensitivity}$).

In the context of our sequential learning strategy, the initial models
were tasked with the binary classification of in-bed vs. out-of-bed. For
this task, we assessed performance using the F1-score, accuracy,
sensitivity, specificity, and precision metrics. The second models in
our sequential learning strategy focused on the binary classification of
asleep vs. awake. For these models, we considered the same metrics, in
addition to the negative predictive rate. The class imbalance in this
case led us to compute the F1 score as an unweighted macro-average.
Additionally, we evaluated the multiclass classifier, biLSTM, using
macro-averaged F1-score, sensitivity, and precision. To further
illustrate model performance, we provide confusion matrices for the full
dataset, encompassing both in-bed and out-of-bed data. These matrices
report relative counts, column percentages (the proportion of the true
class accurately predicted), and row percentages (the proportion of
predictions correctly classified). We considered both the
in-bed/out-of-bed and awake/asleep scoring tasks as binary
classification problems, designating in-bed and asleep as the positive
labels and out-of-bed and awake as the negative labels in accordance
with previous research[@hjorth2012; @kushida2001].

To assess the performance of our models in deriving sleep quality
parameters, we utilized Bland-Altman plots and Pearson correlations. The
Bland-Altman method was employed specifically to determine the level of
agreement between two measurement techniques. Considering our dataset
contained multiple observations per subject, we integrated a bootstrap
procedure to address this extra source of variability. We calculated the
mean difference (bias) and defined the limits of agreement as the mean
difference plus or minus 1.96 times the standard deviation of these
differences. To ensure our measurements were robust and accounted for
intra-subject variability, we estimated the 95% confidence intervals for
both the bias and the limits of agreement using a bias-corrected and
accelerated bootstrap method, utilizing 10,000 bootstrap replicates. The
sleep quality parameteres included the following:

1.  Sleep Period Time (SPT) - This refers to the total duration of the
    sleep period, which is defined as the time from the start to the end
    of the ZM recording.

2.  Total Sleep Time (TST) - This is the time spent asleep within the
    SPT.

3.  Sleep Efficiency (SE) - This is the ratio between TST and SPT,
    representing the proportion of the sleep period that was actually
    spent asleep.

4.  Latency Until Persistent Sleep (LPS) - This metric represents the
    time it takes to transition from wakefulness to sustained sleep. It
    is calculated as the time from the beginning of the ZM recording
    until a period when 10 out of 12 minutes are scored as sleep.

5.  Wake After Sleep Onset (WASO) - This refers to the time spent awake
    after initially falling asleep and before the final awakening. In
    our analysis, a period is counted as 'awake' only if it consists of
    3 or more contiguous 30-second epochs which is also how the ZM
    summarizes WASO.

R version 4.3.0 (2023-04-21)[@R-lang] and the Tidymodels[@tidymodels]
and Tidyverse[@tidyverse] suite of packages were used as the core tools
for model development and analyses. Python version
3.10.6[@10.5555/1593511] and PyTorch[@NEURIPS2019_9015] were used to
implement the biLSTM model. All code used to perform the analysis and
generate the figures in this paper are available in [this
repository](https://github.com/esbenlykke/sleep_study).

# Results

As reported in @tbl-zm_overview the sleep quality parameters derived
from ZM predictions were modified by the implementation of 5-minute and
10-minute median filters. SPT were consistent across raw and filtered
datasets (mean: 9.2 ± 2.1 hours), corresponding to the length of the ZM
recording. TST and SE increased in the filtered data, implying the
filters categorize some wakefulness as sleep. Specifically, TST
increased from a raw mean of 7.7 ± 1.9 hours to 8.1 ± 2.0 hours
(5-minute filter) and 8.2 ± 2.1 hours (10-minute filter), while SE rose
from 82.6 ± 12.0% to 86.4 ± 12.7% and 87.5 ± 12.9% respectively. LPS
also elevated, suggesting the filter smooths out brief awakenings at
sleep onset, leading to a prolonged time to persistent sleep. A
significant change was seen in WASO, which dropped from 39.0 ± 33.6
minutes in raw data to 30.6 ± 46.8 minutes and 22.3 ± 55.4 minutes in
the 5-minute and 10-minute filtered data, respectively. The number of
awakenings was also considerably reduced with the application of
filters. In the raw data, the average number of awakenings was 34.46 ±
11.33 per night, which reduced to 4.43 ± 3.26 and 1.95 ± 2.01 for the
5-minute and 10-minute filtered data sets respectively.

```{r}
#| echo: false
#| message: false
#| label: tbl-zm_overview
#| tbl-cap: Overview of characteristics of the ZM sleep quality summaries per night. Values are represented as mean (SD).

source("code/table_overview_ZM_stats.R")

tbl_overview
```

## Performance on Epoch-to-Epoch Basis

The epoch-to-epoch evaluation of predicting in-bed time is outlined in
@tbl-in_bed_performance, and demonstrates practically equivalent
performance across all model types. The F1 score ranges from 94.4%
(Decision Tree) to 95.4% (XGBoost), while accuracy ranges from 95.3%
(Decision Tree) to 96.1% (XGBoost). Sensitivity, Precision, and
Specificity also demonstrate consistent results across the models. The
XGBoost model, despite recording the highest metrics with an F1 score of
95.4% and accuracy of 96.1%, outpaced the others only marginally.

```{r}
#| echo: false
#| message: false
#| label: tbl-in_bed_performance
#| tbl-cap: In-Bed Performance Metrics

source("code/table_in_bed_performance.R")

tbl_in_bed
```

@tbl-sleep_performance details the performance of the second sequential
models on raw and median-filtered (5 and 10 minute) ZM predictions.
These are the predictions of the sequential models' ability to predict
asleep/awake on only the extracted in-bed time. The F1 scores, which are
unweighted macro averages, for raw ZM predictions range from 71.05% to
76.18%. The models perform comparably, but the low specificity values
(62.84% to 70.93%) suggest difficulty in correctly classifying awake
epochs. Applying 5-minute median filtering improves the performance
metrics. The XGBoost model tops the charts with an F1 score of 79.22%
and NPV of 74.00%. However, specificity still remains low, with values
between 54.68% and 74.84% across all models. With 10-minute median
filtering, the metrics improve further. The XGBoost model still leads
with an F1 score of 80.87% and an NPV of 75.76%. But, specificity
remains low, ranging from 57.47% to 76.35% across all models.

```{r}
#| echo: false
#| message: false
#| tbl-colwidths: auto
#| label: tbl-sleep_performance
#| tbl-cap: Sleep Performance Metrics

source("code/table_sleep_performance.R")

tbl_sleep_performance
```

The complete set of confusion matrices generated from data both
containing the out-of-bed and in-bed time are presented in
@fig-conf_mat. The figure shows favorable epoch-to-epoch performance
across across all sequential models, however, it is evident that the
biLSTM is less successful in classifying the in-bed-awake class which
cannot be deduced from the confusion matrices from the sequential
models. **\[fejl i biLSTM confmat. Alle mats er ens\]**

![Confusion matrices for binary sleep prediction. The middle of each
tile is the normalized count (overall percentage) and, beneath it, the
count. The bottom number is the column percentage (target). At the right
side of each tile is the row percentage (prediction). i) decision tree,
ii) logistic regression, iii) feed-forward neural net, iv) xgboost, and
v) biLSTM.](visuals/all_conf_mats.pdf){#fig-conf_mat}

@tbl-biLSTM_performance presents the performance of the three-class
biLSTM multiclassifier on raw and median-filtered (5-minute and
10-minute) ZM predictions. Raw ZM predictions achieve F1 Scores ranging
from 71.36% to 76.04%, indicating overall good performance. Applying
5-minute median filtering improves the metrics further, resulting in F1
Scores ranging from 75.99% to 78.53%, demonstrating enhanced precision
and sensitivity. **\[Overvej flere metrics. Evt. per class... pt er det
lidt svært at sammenligne på tværs af lstm og andre modeller ud over
F1.\]** With 10-minute median filtering, F1 Scores range from 73.45% to
73.93%, maintaining good performance but with limited information on
Specificity. Further analysis is required to assess performance across
all classes.

```{r}
#| echo: false
#| message: false
#| tbl-colwidths: auto
#| label: tbl-biLSTM_performance
#| tbl-cap: Performance of the three-class biLSTM multicclassifier.
source("code/table_biLSTM_performance.R")

tbl_biLSTM_performance
```

## Evaluation of Sleep Quality Parameters

@tbl-ba_cor presents a comparative analysis of the included models used
to predict various sleep quality parameters (SPT, TST, SE, LPS, WASO)
using the 5-minute median filtered ZM predictions. To see the full table
including models developed from raw ZM predictions and 10-minute median
filtered ZM predictions, see **\[SUPP. MAT.\]**. In terms of bias, the
decision tree model consistently underestimated SPT, TST, and SE, and
overestimated LPS and WASO in comparison to ZM. The logistic regression
model had similar trends, with more pronounced underestimation in TST
and overestimation in LPS. The eed-forward neural network also exhibited
similar bias as the decision tree and the logistic regression models,
but with a higher overestimation in WASO. On the other hand, the XGboost
model showed least bias among all, especially in its 5-minute median
predictions. Considering LOA, the decision tree had higher variability
across different sleep quality parameters and filtering techniques,
particularly for LPS and WASO, which indicates lower agreement with ZM.
Other models had comparable LOA but with notable exceptions. For
example, TST LOA for the logistic regression model was particularly wide
in the 5-minute median predictions. Correlation-wise, the pearson
coefficient, revealed that the XGboost model consistently had the
highest correlation with ZM across all sleep qualityparameters and
filtering methods Notably, the XGboost's 5-minute median predictions
showed the strongest correlation (0.66) for TST among all models and
filtering techniques.

```{r}
#| echo: false
#| message: false
#| label: tbl-ba_cor
#| tbl-cap: Summary of Bias, Limits of Agreement (LOA), and Pearson Correlation for various Sleep Parameter Predictions (SPT, TST, SE, LPS, WASO) using different Machine Learning Models (Decision Tree, Logistic Regression, Feed-Forward Neural Net, XGBoost) with Raw ZM Predictions, 5-Min and 10-Min Median as predictors. Each value is provided with its 95% Confidence Interval (CI).

source("code/table_ba_cor_statistics.R")

short_tbl_ba_cor

```

@fig-xgb_ba_cor shows the agreement of the XGBoost model trained on the
5-minute median filtered ZM predictions in estimating sleep quality
parameters as evaluated 5-minute median-smoothed ZM derived sleep
quality parameter. As can be seen on from the Bland-Altman plots, a
large portion of the nights are in almost perfect agreement with the ZM
and also a portion that can be considered outliers. This is true for all
sleep quality parameters.

**\[Overvej at smide samtlige 75 plots i supp.mat.\]**

![Comparison of sleep quality parameters derived from the XGboost model
trained on the 5-minute smoothed ZM predictions. The left column
displays Bland-Altman plots. Dashed lines represent the bias (the
average difference between the two measurements) and limits of
agreement, with the 95% confidence intervals represented as the grayed
areas. The right column displays scatter plots of XGboost-derived vs
ZM-derived sleep quality parameters. The dashed line represents the
identity line, while the full-drawn line represents the best linear fit.
Pearson's correlations are annotated in the upper left
corner.](visuals/median_5_xgboost_ba_cor.pdf){#fig-xgb_ba_cor}

# Discussion

The present study embarked on an in-depth exploration of the utility and
comparative performance of different machine learning models in the
analysis of pediatric sleep data. The results offer promising insights
into the role of machine learning in enhancing the precision of sleep
quality metrics.

A significant finding was the impact of median filters on the sleep
metrics. Implementing 5-minute and 10-minute median filters led to
notable changes in key sleep parameters. In particular, the Total Sleep
Time (TST), Sleep Efficiency (SE), and Latency to Persistent Sleep (LPS)
increased, suggesting that the filters may categorize some instances of
wakefulness as sleep and smooth out brief awakenings. This underscores
the potential of median filters in refining sleep data and mitigating
the potential misclassification of sleep states.

Interestingly, the most marked change was observed in Wake After Sleep
Onset (WASO), with a substantial reduction in the filtered data. This
reduction, coupled with the decrease in the number of awakenings,
implies a significant role of median filters in sleep-wake cycle
characterization, potentially enhancing the reliability of sleep
assessment.

The machine learning models demonstrated high overall performance on an
epoch-to-epoch basis, with the XGBoost model marginally outperforming
the others. However, the models had more varied performance in
classifying sleep conditions, as evidenced by the sleep performance
metrics. The relatively lower Specificity values across all models
suggest a common challenge in correctly classifying negative instances.

In the precision-recall and ROC curve analyses, the Decision Tree model
showed superior precision-recall AUC, indicating strong predictive
accuracy. In contrast, the XGBoost model consistently demonstrated a
high ROC AUC, indicating a robust ability to differentiate between
classes. However, it's worth noting that the Neural Network model
generally showed weaker performance in these areas.

The three-class biLSTM multiclassifier showed overall good performance,
further supporting the potential of machine learning in sleep study.
However, the absence of Specificity values limits a complete assessment
of its performance, calling for further exploration in future studies.

It is unclear whether Johansson et al.[@johansson_development_2023]\]
provide a method for detecting the in-bed time...

In conclusion, this study provides compelling evidence of the utility of
machine learning models and median filters in enhancing the precision
and reliability of pediatric sleep assessment. However, more research is
needed to overcome the challenge of correctly classifying negative
instances and to fully understand the performance of these models across
all classes and conditions. The findings underscore the potential of
machine learning in advancing sleep medicine, paving the way for more
accurate, reliable, and personalized sleep assessment in pediatric
populations.

\newpage

# References
